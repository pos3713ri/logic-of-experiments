[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Logic of Experiments",
    "section": "",
    "text": "Introduction\nThese are notes on the logic of experiments.\nUnderstanding the logic of experiments helps one clearly understand:\n\nwhy randomization is powerful and\nwhat randomization does and does not get you.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "ch/ate.html",
    "href": "ch/ate.html",
    "title": "1  ATE",
    "section": "",
    "text": "1.1 Potential Outcomes\nIn this chapter, we define the average treatment effect or the ATE. This is the key quantity of interest that we want to estimate with an experiment. But to define (and understand) the ATE, we need to define several preliminary concepts.\nThe fundamental problem of causal inference is that we can never observe what would have happened to the same individual if we had instead assigned them to a different condition. We can observe the outcome under—at most—one condition.\nTo formalize this, we use the potential outcomes framework.\nFor each individual \\(i\\) in our study, we define two potential outcomes:\nThese are called “potential” outcomes because we can observe no more than one of them for any given individual. If individual \\(i\\) receives treatment, we observe \\(Y_i(1)\\) but not \\(Y_i(0)\\). If individual \\(i\\) is in control, we observe \\(Y_i(0)\\) but not \\(Y_i(1)\\).\nThe unobserved potential outcome for each individual is called the counterfactual. The counterfactual represents what would have happened in the hypothetical scenario in which the individual was assigned to a different condition.\nTo make this concrete, consider a hypothetical experiment with 10 respondents. The table below shows both potential outcomes for each respondent—something we could never actually observe in reality, but which helps us understand the framework:\nImportantly, though, we cannot observe both potential outcomes. But for now, let’s ignore that difficulty.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#potential-outcomes",
    "href": "ch/ate.html#potential-outcomes",
    "title": "1  ATE",
    "section": "",
    "text": "\\(Y_i(1)\\): the outcome individual \\(i\\) would experience if assigned to treatment (\\(D_i = 1\\))\n\\(Y_i(0)\\): the outcome individual \\(i\\) would experience if assigned to control (\\(D_i = 0\\))\n\n\n\n\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n4\n7\n\n\n2\n6\n5\n\n\n3\n5\n5\n\n\n4\n3\n9\n\n\n5\n7\n10\n\n\n6\n5\n4\n\n\n7\n4\n8\n\n\n8\n6\n7\n\n\n9\n5\n3\n\n\n10\n4\n6",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#the-individual-level-treatment-effect",
    "href": "ch/ate.html#the-individual-level-treatment-effect",
    "title": "1  ATE",
    "section": "1.2 The Individual-Level Treatment Effect",
    "text": "1.2 The Individual-Level Treatment Effect\nOnce we have defined potential outcomes, we can define the individual-level treatment effect for individual \\(i\\) as \\(\\tau_i = Y_i(1) - Y_i(0)\\).\nThis represents the causal effect of treatment for that specific individual. It’s simply the difference between what would happen if they were assigned to treatment versus what would happen if they were assigned to control.\nIf we knew all the potential outcomes, then we could compute the individual-level treatment effect for each respondent.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n4\n7\n7 - 4 = 3\n\n\n2\n6\n5\n5 - 6 = -1\n\n\n3\n5\n5\n5 - 5 = 0\n\n\n4\n3\n9\n9 - 3 = 6\n\n\n5\n7\n10\n10 - 7 = 3\n\n\n6\n5\n4\n4 - 5 = -1\n\n\n7\n4\n8\n8 - 4 = 4\n\n\n8\n6\n7\n7 - 6 = 1\n\n\n9\n5\n3\n3 - 5 = -2\n\n\n10\n4\n6\n6 - 4 = 2\n\n\n\nAgain, there’s a fundamental problem: we can never observe \\(\\tau_i\\) directly because we never observe both potential outcomes for the same individual. This is sometimes called the fundamental problem of causal inference. We observe either \\(Y_i(1)\\) or \\(Y_i(0)\\), but never both. But again, let’s continue to ignore this pesky problem.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#the-average-treatment-effect",
    "href": "ch/ate.html#the-average-treatment-effect",
    "title": "1  ATE",
    "section": "1.3 The Average Treatment Effect",
    "text": "1.3 The Average Treatment Effect\nWe already know that we cannot observe the individual-level treatment effects. So instead, let’s cleverly sidestep the problem. Let’s define the average treatment effect or ATE, defined as\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} [Y_i(1) - Y_i(0)] \\\\\n&= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\text{avg} \\left( Y_i(1) \\right) - \\text{avg} \\left( Y_i(0) \\right) \\\\\n&= \\text{avg. of ALL p.o. under treatment } - \\text{avg. of ALL p.o. under control}\n\\end{align}\n\\]\nThe ATE represents the average causal effect of treatment across all individuals in the population. It tells us: on average, how much does treatment change outcomes?\nHere’s another way to think about. Suppose we assigned everyone to treatment and computed the average outcome. Suppose we also assigned everyone to control and computed the average outcome. (We can’t assign everyone to treatment and everyone to control, but suppose we could). The ATE is the difference between this two average.\nAgain, we cannot observe the ATE, but it turns out that this quantity can be estimated. In later sections, we’ll show how we can use randomized experiments to estimate the ATE. But for now, let’s focus on the meaning of the concept.\nTo make this concrete, we can compute the ATE for the potential outcomes above.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n4\n7\n\n\n2\n6\n5\n\n\n3\n5\n5\n\n\n4\n3\n9\n\n\n5\n7\n10\n\n\n6\n5\n4\n\n\n7\n4\n8\n\n\n8\n6\n7\n\n\n9\n5\n3\n\n\n10\n4\n6\n\n\n\nUsing this table, we can compute the ATE by finding the average of all potential outcomes under control and the average of all potential outcomes under treatment:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\frac{1}{10}(7 + 5 + 5 + 9 + 10 + 4 + 8 + 7 + 3 + 6) - \\frac{1}{10}(4 + 6 + 5 + 3 + 7 + 5 + 4 + 6 + 5 + 4) \\\\\n&= \\frac{64}{10} - \\frac{49}{10} \\\\\n&= 6.4 - 4.9 \\\\\n&= 1.5\n\\end{align}\n\\] The ATE is 1.5, meaning that on average, treatment increases outcomes by 1.5 units. (We could average the \\(\\tau_i\\) in the table above to obtain the identical value.)\n\n\n\n\n\n\nTip\n\n\n\nWhen we write about the “average treatment effect,” it should be understood as something very specific. It should be understood as the difference between two quantities: the hypothetical difference between (1) the average value of the outcome if we assigned everyone to treatment and (2) the average value of the outcome if we assigned everyone to control.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#special-cases",
    "href": "ch/ate.html#special-cases",
    "title": "1  ATE",
    "section": "1.4 Special Cases",
    "text": "1.4 Special Cases\n\n1.4.1 The Sharp Null Hypothesis\nThe sharp null hypothesis is a particularly strong claim about individual treatment effects. The sharp null hypothesis states that\n\\[\\text{sharp null hypothesis}: Y_i(1) = Y_i(0) \\text{ for all } i.\\]\nThis hypothesis states that treatment has exactly zero effect for every single individual in the study. That is, for each individual in the experiment, the outcome is identical regardless of whether it is assigned to treatment or control. Under the sharp null, the treatment effect \\(\\tau_i = 0\\) for all \\(i\\).\nThis hypothesis is helpful because it completely specifies all potential outcomes. If we assume the sharp null hypothesis holds, then we can compute the counterfactual outcome from the observed outcome.\n\nSuppose we observe \\(Y_i(0)\\) for a control individual, we know that \\(Y_i(1) = Y_i(0)\\).\nSimilarly, suppose we observe \\(Y_i(1)\\) for a treated individual, we know that \\(Y_i(0) = Y_i(1)\\).\n\nWhile we never know whether the sharp null hypothesis holds—and it seems implausible that it ever would hold—it can sometimes be convenient to check what would happen if it did hold.\nThe table below shows a set of potential outcomes where the sharp null holds.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n4\n4\n4 - 4 = 0\n\n\n2\n6\n6\n6 - 6 = 0\n\n\n3\n5\n5\n5 - 5 = 0\n\n\n4\n3\n3\n3 - 3 = 0\n\n\n5\n7\n7\n7 - 7 = 0\n\n\n6\n5\n5\n5 - 5 = 0\n\n\n7\n4\n4\n4 - 4 = 0\n\n\n8\n6\n6\n6 - 6 = 0\n\n\n9\n5\n5\n5 - 5 = 0\n\n\n10\n4\n4\n4 - 4 = 0\n\n\n\nUnder the sharp null hypothesis, \\(Y_i(1) = Y_i(0)\\) for all individuals \\(i\\), which means \\(\\tau_i = 0\\) for all individuals. We can verify this by computing the ATE:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\frac{1}{10}(4 + 6 + 5 + 3 + 7 + 5 + 4 + 6 + 5 + 4) - \\frac{1}{10}(4 + 6 + 5 + 3 + 7 + 5 + 4 + 6 + 5 + 4) \\\\\n&= \\frac{49}{10} - \\frac{49}{10} \\\\\n&= 4.9 - 4.9 \\\\\n&= 0\n\\end{align}\n\\]\nThe ATE is exactly 0. This follows from the fact that all of the individual-level effects are exactly zero as well.\n\n\n1.4.2 Constant Treatment Effects\nAnother implausible but sometimes-helpful hypothesis is the constant treatment effects assumption that\n\\[\\tau_i = \\tau \\text{ for all individuals } i\\]\nThis assumes that while the individual-level treatment effect may be different from zero, that effect is exactly the same for every individual so that \\[Y_i(1) - Y_i(0) = \\tau \\text{ for all } i\\]. Here, \\(\\tau\\) is a fixed number like 2 or -4.2 that is the same for all the individuals.\nAs before, we never know whether individual-level treatment effects are constant—and it seems implausible they ever would be. But it can sometimes be convenient to check what would happen if they were constant.\nSimilar to the sharp null hypothesis, the constant effects hypothesis is helpful because it completely specifies all potential outcomes. It allows us to compute the counterfactual outcome from the observed outcome.\n\nSuppose we observe \\(Y_i(0)\\) for a control individual, we know that \\(Y_i(1)\\) is 2 points larger than that so that \\(Y_i(1) = Y_i(0) + 2\\).\nSimilarly, suppose we observe \\(Y_i(1)\\) for a treated individual, we know that \\(Y_i(0)\\) is 2 points less than that so that \\(Y_i(0) = Y_i(1) - 2\\).\n\nThe table below shows a set of potential outcomes where treatment effects are constant at \\(\\tau = 2\\) for all individuals.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n4\n6\n6 - 4 = 2\n\n\n2\n6\n8\n8 - 6 = 2\n\n\n3\n5\n7\n7 - 5 = 2\n\n\n4\n3\n5\n5 - 3 = 2\n\n\n5\n7\n9\n9 - 7 = 2\n\n\n6\n5\n7\n7 - 5 = 2\n\n\n7\n4\n6\n6 - 4 = 2\n\n\n8\n6\n8\n8 - 6 = 2\n\n\n9\n5\n7\n7 - 5 = 2\n\n\n10\n4\n6\n6 - 4 = 2\n\n\n\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\frac{1}{10}(6 + 8 + 7 + 5 + 9 + 7 + 6 + 8 + 7 + 6) - \\frac{1}{10}(4 + 6 + 5 + 3 + 7 + 5 + 4 + 6 + 5 + 4) \\\\\n&= \\frac{69}{10} - \\frac{49}{10} \\\\\n&= 6.9 - 4.9 \\\\\n&= 2\n\\end{align}\n\\]\nThe ATE is exactly 2. This follows from the fact that all of the individual-level effects are exactly 2 as well. When treatment effects are constant, the ATE perfectly captures the treatment effect for every individual.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#rasinskis-question-wording-experiment",
    "href": "ch/ate.html#rasinskis-question-wording-experiment",
    "title": "1  ATE",
    "section": "1.5 Rasinski’s Question-Wording Experiment",
    "text": "1.5 Rasinski’s Question-Wording Experiment\nIn a famous survey experiment, Rasinski (1989) was curious about how question wording affects public support for government spending.1\n\nRasinski, Kenneth A. 1989. “The Effect of Question Wording on Public Support for Government Spending.” Public Opinion Quarterly 53 (3): 388–94.\n1 Respondents were randomly assigned to one of two conditions that asked about spending on programs for low-income individuals, but used different labels to describe these programs. The experiment was conducted across three years (1984, 1985, and 1986) and consistently found that far more respondents said the government was spending “too little” when the program was described as “assistance to the poor” (around 63-65%) compared to when it was described as “welfare” (around 20-25%). This represents a dramatic difference of approximately 40 percentage points due solely to the choice of label used to describe the same underlying government program.Respondents could be assigned to one of two conditions: treatment or control. The two conditions featured an identical question stem, but varied in how they describe the spending.\nQuestion stem (identical for both conditions): “Are we spending too much, too little, or about the right amount on…”\nTreatment condition: “…assistance to the poor?”\nControl condition: “…welfare?”\nResponse options:\n\nToo little = 1\nAbout right = 2\nToo much = 3\n\nThus each respondent had two potential outcomes:\n\n\\(Y_i(1)\\): the response respondent \\(i\\) would give if assigned to the treatment condition (“assistance to the poor”)\n\\(Y_i(0)\\): the response respondent \\(i\\) would give if assigned to the control condition (“welfare”)\n\nAs before, we can never observe both potential outcomes for the same respondent. We can observe their response if the program is described as “assistance to the poor” or as “welfare”, but not both.\n\n1.5.1 Hypothetical Potential Outcomes\nTo illustrate the concepts, suppose we could magically observe both potential outcomes for a sample of 10 respondents. The table below shows what each respondent would answer under each condition:\n\n\n\n\n\n\n\n\n\nRespondent\n\\(Y_i(0)\\) (“welfare”)\n\\(Y_i(1)\\) (“assistance”)\n\\(\\tau_i\\)\n\n\n\n\n1\n3 (Too much)\n1 (Too little)\n1 - 3 = -2\n\n\n2\n3 (Too much)\n2 (About right)\n2 - 3 = -1\n\n\n3\n2 (About right)\n1 (Too little)\n1 - 2 = -1\n\n\n4\n3 (Too much)\n1 (Too little)\n1 - 3 = -2\n\n\n5\n2 (About right)\n1 (Too little)\n1 - 2 = -1\n\n\n6\n3 (Too much)\n2 (About right)\n2 - 3 = -1\n\n\n7\n2 (About right)\n1 (Too little)\n1 - 2 = -1\n\n\n8\n3 (Too much)\n1 (Too little)\n1 - 3 = -2\n\n\n9\n2 (About right)\n2 (About right)\n2 - 2 = 0\n\n\n10\n3 (Too much)\n1 (Too little)\n1 - 3 = -2\n\n\n\nNotice that for most respondents, the treatment effect \\(\\tau_i\\) is negative. This means that asking about “assistance to the poor” produces lower numeric responses than asking about “welfare.” In this case, lower numbers indicate more support for spending (“too little” = 1), these negative treatment effects actually represent increased support for spending when using the “assistance to the poor” wording.\n\n\n1.5.2 Computing the ATE\nWe can compute the ATE for this hypothetical data:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\frac{1}{10}(1 + 2 + 1 + 1 + 1 + 2 + 1 + 1 + 2 + 1) - \\frac{1}{10}(3 + 3 + 2 + 3 + 2 + 3 + 2 + 3 + 2 + 3) \\\\\n&= \\frac{13}{10} - \\frac{26}{10} \\\\\n&= 1.3 - 2.6 \\\\\n&= -1.3\n\\end{align}\n\\]\nThe ATE is -1.3. Since lower values on our 1-2-3 scale indicate more support for spending, this negative ATE means that the “assistance to the poor” wording increases support for spending by an average of 1.3 scale points compared to the “welfare” wording.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#key-terms",
    "href": "ch/ate.html#key-terms",
    "title": "1  ATE",
    "section": "1.6 Key Terms",
    "text": "1.6 Key Terms\n\nPotential outcomes\nPotential outcomes framework\nCounterfactual\nIndividual-level treatment effect\nFundamental problem of causal inference\nAverage treatment effect (ATE)\nSharp null hypothesis\nConstant treatment effects",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#exercises",
    "href": "ch/ate.html#exercises",
    "title": "1  ATE",
    "section": "1.7 Exercises",
    "text": "1.7 Exercises\n\n1.7.1 Conceptual Understanding\n\nDefining Potential Outcomes: In your own words, explain what \\(Y_i(1)\\) and \\(Y_i(0)\\) represent in the context of Rasinski’s question-wording experiment. Why can we never observe both potential outcomes for the same respondent?\n\n\n\nSolution\n\nIn Rasinski’s question-wording experiment, each respondent has two potential outcomes:\n\n\\(Y_i(1)\\) is the response that respondent \\(i\\) would give if asked about spending on “assistance to the poor.” This is the potential outcome under the treatment condition.\n\\(Y_i(0)\\) is the response that respondent \\(i\\) would give if asked about spending on “welfare.” This is the potential outcome under the control condition.\n\nWe can never observe both potential outcomes for the same respondent because each respondent can only answer one version of the question. Once respondent \\(i\\) sees the question with “welfare” and gives their answer, we cannot rewind time and show them the “assistance to the poor” version as if they had never seen the first one. At most, we observe one potential outcome per respondent—either \\(Y_i(1)\\) or \\(Y_i(0)\\), but never both.\nThis is the fundamental problem of causal inference.\n\n\nThe Fundamental Problem: Explain why we call it the “fundamental problem of causal inference.” What makes this problem “fundamental” rather than just “difficult”?\n\n\n\nSolution\n\nWe call it the “fundamental” problem of causal inference—rather than just a “difficult” problem—because it cannot be solved, even in principle.\nA “difficult” problem is one we might overcome with better technology, more data, or cleverer methods. The fundamental problem is different: it is a logical impossibility. At any given moment, an individual either receives treatment or does not. We cannot observe the same person in two different states of the world at the same time. No amount of resources or ingenuity can change this fact.\nThis is why we need research designs—like randomized experiments—that allow us to estimate causal effects at the group level, even though we can never directly observe individual-level causal effects.\n\n\nATE Interpretation: A researcher finds an ATE of 3.2 in an experiment testing the effect of a new study technique on exam scores (measured 0-100). Write two sentences explaining what this means in plain language that a non-statistician could understand.\n\n\n\nSolution\n\nAn ATE of 3.2 means that, on average, students who use the new study technique score about 3.2 points higher on the exam compared to what they would have scored without using the technique.\nAnother way to say this: if we could magically give the study technique to all students and then also observe what would have happened if none of them used it, the average difference between these two scenarios would be 3.2 points.\n\n\nSharp Null vs. Zero ATE: Is it possible to have an ATE of zero even when the sharp null hypothesis does not hold? Explain your answer and provide an example using a simple table of potential outcomes for 4 individuals.\n\n\n\nSolution\n\nYes, it is possible to have an ATE of zero even when the sharp null hypothesis does not hold.\nThe sharp null hypothesis is a strong claim: it requires that \\(\\tau_i = 0\\) for every single individual. That is, \\(Y_i(1) = Y_i(0)\\) for all \\(i\\).\nThe ATE, on the other hand, is just the average of the individual treatment effects:\n\\[\\text{ATE} = \\frac{1}{N} \\sum_{i=1}^{N} \\tau_i\\]\nIf some individuals have positive treatment effects and others have negative treatment effects, these can cancel out, producing an ATE of zero even though the treatment affected every individual.\nHere is a concrete example with 4 individuals:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i = Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n5\n8\n\\(8 - 5 = 3\\)\n\n\n2\n7\n4\n\\(4 - 7 = -3\\)\n\n\n3\n6\n8\n\\(8 - 6 = 2\\)\n\n\n4\n8\n6\n\\(6 - 8 = -2\\)\n\n\n\nComputing the ATE:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{4} \\sum_{i=1}^{4} \\tau_i \\\\\n&= \\frac{1}{4}(3 + (-3) + 2 + (-2)) \\\\\n&= \\frac{0}{4} \\\\\n&= 0\n\\end{align}\n\\]\nThe ATE equals zero, but the sharp null does not hold. The treatment affected every single individual—individuals 1 and 3 experienced positive effects of 3 and 2, while individuals 2 and 4 experienced negative effects of -3 and -2. The effects simply cancel out when we average them.\n\n\n\n1.7.2 Computational Practice\n\nComputing Individual Treatment Effects: Consider the following potential outcomes for 6 respondents in a hypothetical experiment:\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n5\n8\n\n\n2\n7\n6\n\n\n3\n4\n7\n\n\n4\n6\n9\n\n\n5\n5\n5\n\n\n6\n8\n7\n\n\n\n\nCalculate the individual-level treatment effect (\\(\\tau_i\\)) for each respondent.\nCalculate the ATE.\nWhich respondents experienced a positive treatment effect? A negative treatment effect? No treatment effect?\n\n\n\n\nSolution\n\nPart a. To find each individual treatment effect, we compute \\(\\tau_i = Y_i(1) - Y_i(0)\\):\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i = Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n5\n8\n\\(8 - 5 = 3\\)\n\n\n2\n7\n6\n\\(6 - 7 = -1\\)\n\n\n3\n4\n7\n\\(7 - 4 = 3\\)\n\n\n4\n6\n9\n\\(9 - 6 = 3\\)\n\n\n5\n5\n5\n\\(5 - 5 = 0\\)\n\n\n6\n8\n7\n\\(7 - 8 = -1\\)\n\n\n\nPart b. We can compute the ATE by averaging the individual treatment effects:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{6} \\sum_{i=1}^{6} \\tau_i \\\\\n&= \\frac{1}{6}(3 + (-1) + 3 + 3 + 0 + (-1)) \\\\\n&= \\frac{7}{6} \\\\\n&\\approx 1.167\n\\end{align}\n\\]\nWe can verify this by computing the ATE as the difference between the average potential outcome under treatment and the average potential outcome under control:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{6}\\sum_{i=1}^{6} Y_i(1) - \\frac{1}{6}\\sum_{i=1}^{6} Y_i(0) \\\\\n&= \\frac{1}{6}(8 + 6 + 7 + 9 + 5 + 7) - \\frac{1}{6}(5 + 7 + 4 + 6 + 5 + 8) \\\\\n&= \\frac{42}{6} - \\frac{35}{6} \\\\\n&= 7 - 5.833 \\\\\n&\\approx 1.167\n\\end{align}\n\\]\nBoth methods give the same answer.\nPart c. Classifying the treatment effects:\n\nPositive treatment effect (\\(\\tau_i &gt; 0\\)): Respondents 1, 3, and 4 (with effects of 3, 3, and 3)\nNegative treatment effect (\\(\\tau_i &lt; 0\\)): Respondents 2 and 6 (with effects of -1 and -1)\nNo treatment effect (\\(\\tau_i = 0\\)): Respondent 5\n\n\n\nVerifying the Sharp Null: Consider the following potential outcomes:\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n12\n12\n\n\n2\n8\n8\n\n\n3\n15\n15\n\n\n4\n10\n10\n\n\n\n\nDoes this satisfy the sharp null hypothesis? How do you know?\nCalculate the ATE.\nUnder the sharp null hypothesis, what can you always say about the ATE?\n\n\n\n\nSolution\n\nPart a. Yes, this satisfies the sharp null hypothesis.\nThe sharp null hypothesis requires that \\(Y_i(1) = Y_i(0)\\) for all individuals. We can check each respondent:\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(Y_i(1) = Y_i(0)\\)?\n\n\n\n\n1\n12\n12\nYes\n\n\n2\n8\n8\nYes\n\n\n3\n15\n15\nYes\n\n\n4\n10\n10\nYes\n\n\n\nFor every individual, the potential outcome under treatment equals the potential outcome under control. The sharp null hypothesis holds.\nPart b. Computing the ATE:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{4}\\sum_{i=1}^{4} Y_i(1) - \\frac{1}{4}\\sum_{i=1}^{4} Y_i(0) \\\\\n&= \\frac{1}{4}(12 + 8 + 15 + 10) - \\frac{1}{4}(12 + 8 + 15 + 10) \\\\\n&= \\frac{45}{4} - \\frac{45}{4} \\\\\n&= 11.25 - 11.25 \\\\\n&= 0\n\\end{align}\n\\]\nPart c. Under the sharp null hypothesis, the ATE is always exactly zero.\nThis follows directly from the definitions. If \\(Y_i(1) = Y_i(0)\\) for all \\(i\\), then:\n\\[\\tau_i = Y_i(1) - Y_i(0) = 0 \\text{ for all } i\\]\nThe ATE is the average of the individual treatment effects:\n\\[\\text{ATE} = \\frac{1}{N} \\sum_{i=1}^{N} \\tau_i = \\frac{1}{N} \\sum_{i=1}^{N} 0 = 0\\]\nThe average of zeros is always zero.\n\n\nConstant Treatment Effects: Create a table of potential outcomes for 5 individuals where the constant treatment effects assumption holds with \\(\\tau = -2.5\\) for all individuals. Show that the ATE equals -2.5.\n\n\n\nSolution\n\nThe constant treatment effects assumption requires that \\(\\tau_i = \\tau\\) for all individuals. With \\(\\tau = -2.5\\), we need \\(Y_i(1) - Y_i(0) = -2.5\\) for every individual.\nWe can choose any values for \\(Y_i(0)\\) and then compute \\(Y_i(1) = Y_i(0) + (-2.5) = Y_i(0) - 2.5\\):\n\n\n\n\n\n\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1) = Y_i(0) - 2.5\\)\n\\(\\tau_i = Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n10\n7.5\n\\(7.5 - 10 = -2.5\\)\n\n\n2\n8\n5.5\n\\(5.5 - 8 = -2.5\\)\n\n\n3\n12\n9.5\n\\(9.5 - 12 = -2.5\\)\n\n\n4\n6\n3.5\n\\(3.5 - 6 = -2.5\\)\n\n\n5\n9\n6.5\n\\(6.5 - 9 = -2.5\\)\n\n\n\nNow we verify that the ATE equals -2.5:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{5}\\sum_{i=1}^{5} Y_i(1) - \\frac{1}{5}\\sum_{i=1}^{5} Y_i(0) \\\\\n&= \\frac{1}{5}(7.5 + 5.5 + 9.5 + 3.5 + 6.5) - \\frac{1}{5}(10 + 8 + 12 + 6 + 9) \\\\\n&= \\frac{32.5}{5} - \\frac{45}{5} \\\\\n&= 6.5 - 9 \\\\\n&= -2.5\n\\end{align}\n\\]\nWhen treatment effects are constant at \\(\\tau\\) for all individuals, the ATE equals \\(\\tau\\). This makes sense: the ATE is the average of the individual treatment effects, and the average of a constant is just that constant.\n\n\n\n1.7.3 Application to Rasinski’s Experiment\n\nUnderstanding the Conditions:\n\nIn Rasinski’s experiment, what exactly differs between the treatment and control conditions? What stays the same?\nWhy might the word “welfare” produce different responses than “assistance to the poor” even though both refer to the same government programs?\n\n\n\n\nSolution\n\nPart a.\nWhat differs between the conditions: Only the label used to describe the government programs. The treatment condition uses “assistance to the poor” while the control condition uses “welfare.”\nWhat stays the same: Everything else is identical:\n\nThe question stem: “Are we spending too much, too little, or about the right amount on…”\nThe response options: Too little, About right, Too much\nThe numeric coding: 1, 2, 3\nThe underlying concept being asked about (government spending on programs for low-income people)\n\nPart b. The words “welfare” and “assistance to the poor” may produce different responses because they carry different connotations, even though they refer to the same government programs.\n“Welfare” has acquired negative associations in American political discourse. It is often linked to stereotypes about dependency, fraud, or undeserving recipients. Many people have strong negative reactions to the word itself.\n“Assistance to the poor” is more neutral and descriptive. It focuses attention on the humanitarian purpose of helping people in need, without triggering the same negative associations.\nThese different framings can activate different considerations in respondents’ minds, leading them to express different levels of support even though the underlying programs are identical. This is exactly what Rasinski’s experiment was designed to detect.\n\n\nInterpreting Rasinski’s Results: In the hypothetical Rasinski data presented in the notes, the ATE was -1.3.\n\nExplain what this negative ATE means substantively. Does it indicate increased or decreased support for spending?\nWhy is the sign (positive or negative) of the ATE potentially confusing in this example?\nIf we had instead coded responses as: Too little = 3, About right = 2, Too much = 1, what would the ATE have been? Would your substantive interpretation change?\n\n\n\n\nSolution\n\nPart a. The ATE of -1.3 means that, on average, respondents gave responses that were 1.3 points lower on the 1-2-3 scale when asked about “assistance to the poor” compared to when asked about “welfare.”\nBut what does “lower” mean substantively? Recall the coding:\n\nToo little = 1 (more support for spending)\nAbout right = 2\nToo much = 3 (less support for spending)\n\nLower numbers indicate more support for spending. So a negative ATE indicates increased support for spending when using the “assistance to the poor” wording. The treatment (changing “welfare” to “assistance to the poor”) made people more supportive of government spending.\nPart b. The sign is potentially confusing because the coding scheme runs in the opposite direction from what we might intuitively expect. We often associate “positive” with “more” and “negative” with “less.” But here, a negative ATE means more support for spending.\nThis is an artifact of how the response options were numbered. The researcher could have coded the responses differently.\nPart c. If we reversed the coding:\n\nToo little = 3 (more support for spending)\nAbout right = 2\nToo much = 1 (less support for spending)\n\nThen each potential outcome would transform:\n\nOriginal values of 1 become 3\nOriginal values of 2 stay 2\nOriginal values of 3 become 1\n\nUsing the hypothetical data from the chapter, the new ATE would be:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{10}(3 + 2 + 3 + 3 + 3 + 2 + 3 + 3 + 2 + 3) - \\frac{1}{10}(1 + 1 + 2 + 1 + 2 + 1 + 2 + 1 + 2 + 1) \\\\\n&= \\frac{27}{10} - \\frac{14}{10} \\\\\n&= 2.7 - 1.4 \\\\\n&= +1.3\n\\end{align}\n\\]\nThe ATE becomes \\(+1.3\\) instead of \\(-1.3\\).\nThe substantive interpretation does not change: the “assistance to the poor” wording still increases support for spending compared to “welfare.” The sign of the ATE simply reflects our arbitrary choice of how to code the responses.\n\n\nRasinski’s Potential Outcomes: Consider respondent 9 in the hypothetical Rasinski data, who answered “About right” (2) under both conditions.\n\nWhat is this respondent’s individual treatment effect (\\(\\tau_9\\))?\nDoes this mean the question wording had no effect on this respondent? Explain.\nCan you construct an example with different potential outcomes where the treatment has a large effect for every individual, but the ATE is still zero?\n\n\n\n\nSolution\n\nPart a. Respondent 9 answered “About right” (coded as 2) under both conditions:\n\n\\(Y_9(1) = 2\\) (response if asked about “assistance to the poor”)\n\\(Y_9(0) = 2\\) (response if asked about “welfare”)\n\nThe individual treatment effect is:\n\\[\\tau_9 = Y_9(1) - Y_9(0) = 2 - 2 = 0\\]\nPart b. For this particular respondent, the question wording had no effect on their observed categorical response. They gave the same answer—“About right”—regardless of which version of the question they received.\nHowever, this does not necessarily mean the wording had no psychological effect whatsoever. It could be that:\n\nThe respondent holds consistent, moderate views on this issue that are not affected by framing\nThe two framings activated different considerations, but those considerations happened to produce the same response category\nThe respondent gave a default “middle” response without processing the question carefully\n\nAll we can conclude is that the treatment did not change this respondent’s response on this particular three-category scale.\nPart c. Yes. Here is an example where treatment has a large effect (\\(|\\tau_i| = 3\\)) for every individual, but the ATE is zero:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n2\n5\n\\(5 - 2 = 3\\)\n\n\n2\n6\n3\n\\(3 - 6 = -3\\)\n\n\n3\n4\n7\n\\(7 - 4 = 3\\)\n\n\n4\n8\n5\n\\(5 - 8 = -3\\)\n\n\n\nEvery individual experiences a treatment effect of either \\(+3\\) or \\(-3\\). The treatment clearly matters for each person. But the ATE is:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{4}(3 + (-3) + 3 + (-3)) \\\\\n&= \\frac{0}{4} \\\\\n&= 0\n\\end{align}\n\\]\nThe positive and negative effects cancel perfectly, producing an ATE of zero despite large individual effects.\n\n\n\n1.7.4 Critical Thinking\n\nBeyond the Average: In the original hypothetical example (with 10 respondents and ATE = 1.5), we saw that treatment effects varied across individuals, with some positive, some negative, and some zero.\n\nWhy might this variation in individual treatment effects matter for policy or practical decisions?\nWhat are the limitations of focusing only on the ATE when individual treatment effects vary substantially?\n\n\n\n\nSolution\n\nPart a. Variation in individual treatment effects matters for policy and practical decisions because:\nTargeting interventions: If treatment helps some people but harms others, we might want to identify who benefits and offer the treatment only to them. A positive ATE could mask the fact that a substantial group is being harmed.\nEquity concerns: Even if the average effect is positive, we might care about who benefits. If benefits are concentrated among people who are already well-off, while disadvantaged groups see little improvement, this raises fairness concerns that the ATE alone cannot reveal.\nIndividual decision-making: A person deciding whether to undergo a treatment cares about the effect on them, not the average effect across all people. If effects are highly variable, the ATE may be a poor guide for any particular individual.\nUnderstanding mechanisms: Variation in effects can help us understand why a treatment works. If effects are larger for certain subgroups, this may point to underlying mechanisms or suggest how to improve the treatment.\nPart b. The ATE has several limitations when individual treatment effects vary substantially:\n\nThe ATE can hide important heterogeneity. An ATE of zero could mean “the treatment has no effect on anyone” or “the treatment has large positive effects for half the population and large negative effects for the other half.” These are very different situations with very different policy implications.\nThe ATE does not tell us who benefits and who is harmed.\nThe ATE treats all individuals equally. But we might care more about effects on certain groups, such as those who are most disadvantaged or most at risk.\nThe ATE is a single summary number. Like any average, it can be misleading if the underlying distribution is skewed or bimodal.\nFor individual decision-making, knowing the ATE does not tell any specific person whether the treatment will help or harm them.\n\n\n\nAssumption Plausibility:\n\nFor what kinds of treatments or contexts—if any—might the constant treatment effects assumption be approximately reasonable?\nFor what kinds of treatments would this assumption be clearly implausible? Provide a specific example and explain why treatment effects would likely vary across individuals.\n\n\n\n\nSolution\n\nPart a. The constant treatment effects assumption might be approximately reasonable in some contexts:\nSimple, additive interventions: A treatment that mechanically adds a fixed amount might have roughly constant effects. For example, if a government program gives every recipient exactly $500, the effect on “dollars received” is constant at $500 for everyone.\nHighly standardized settings with homogeneous units: In carefully controlled laboratory experiments with nearly identical subjects (such as certain agricultural experiments with genetically identical plants), treatment effects might be relatively uniform.\nVery small effects: When treatment effects are small relative to natural variation in outcomes, the assumption of constant effects might not matter much practically, even if it’s technically false.\nEven in these cases, truly constant effects are unlikely. But the assumption might be close enough to be useful for certain purposes.\nPart b. Constant treatment effects would be clearly implausible for treatments where individual circumstances strongly influence how people respond.\nExample: A job training program’s effect on earnings\nTreatment effects would likely vary substantially across individuals because:\n\nBaseline skills: Someone with no prior job skills might benefit enormously from training, while someone who already has strong skills might gain little or nothing.\nLocal labor markets: The value of new skills depends on whether employers in the person’s area are hiring for jobs that use those skills. A person in a booming job market might see large earnings gains; a person in a depressed area might see none.\nPersonal circumstances: People differ in their ability to apply what they learn, their job search networks, the discrimination they face, their health, their family responsibilities, and countless other factors that affect how training translates into earnings.\nMotivation and engagement: Some participants engage deeply with training while others do not, leading to different outcomes.\n\nFor a job training program, we would expect some participants to see large earnings gains, others to see modest gains, and some to see no gain or even losses (if, say, the time spent in training caused them to miss other opportunities). Assuming constant effects would ignore this important variation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html",
    "href": "ch/ate-hat.html",
    "title": "2  Estimating the ATE",
    "section": "",
    "text": "2.1 The Problem; A Solution?\nIn the previous chapter, we defined the average treatment effect (ATE) as the difference in average potential outcomes under treatment and control. This is simply the hypothetical difference between the average outcome if we assigned everyone to treatment and the average outcome if we assigned everyone to contrl.\nBut we also acknowledged a fundamental problem: we can never observe both potential outcomes for the same individual. So how can we design a procedure to estimate the ATE from data?\nIn this chapter, we develop a a simple and intuitive procedure and estimator.\nWe show that this is a good procedure because it is an unbiased estimator of the ATE. Importantly, this result relies only on the design of the experiment (the random assignment), not on any assumptions about how outcomes are generated.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#the-problem-a-solution",
    "href": "ch/ate-hat.html#the-problem-a-solution",
    "title": "2  Estimating the ATE",
    "section": "",
    "text": "2.1.1 Problem: We Can’t Observe the ATE\nRecall from the previous chapter that we define the ATE as the difference between two averages: the average outcome if we assigned everyone to treatment minus the average outcome if we assigned everyone to control.\nBut here’s the problem: we can’t assign everyone to treatment and everyone to control. Each individual can only be in one condition. If we assign someone to treatment, we see their outcome under treatment (but not their outcome under control). If we assign someone to control, we see their outcome under control (but not their outcome under treatment).\nThis means we can never directly compute the ATE. So how do we get around this?\n\n\n2.1.2 Solution?: Random Assignment\nThe key insight is that we don’t need to observe everyone’s outcome under treatment to learn about the average outcome under treatment. If we randomly assign individuals to treatment, then the individuals who happen to be assigned to treatment are—on average—just like the individuals who happen to be assigned to control. They are a simple random sample from the same population.\nThis is the logic of a completely randomized experiment. We take our group of individuals and randomly divide them into two groups: some go to treatment, some go to control.\n\nThe treated individuals are a random sample of the full group. So the average outcome we observe among treated individuals should be a good estimate of what the average outcome would have been if we had assigned everyone to treatment.\nSimilarly, the average outcome among control individuals should be a good estimate of what the average outcome would have been if we had assigned everyone to control.\n\nIn other words, random assignment lets us estimate the two quantities we need—the average outcome under treatment and the average outcome under control—even though we can’t observe them directly for everyone.\nThe difference between these two estimates gives us an estimate of the ATE. It won’t be perfect. Any particular randomization might, by chance, put more higher-outcome individuals in one group than the other. But on average, across all possible randomizations, this approach gets it exactly right.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#the-observed-data",
    "href": "ch/ate-hat.html#the-observed-data",
    "title": "2  Estimating the ATE",
    "section": "2.2 The Observed Data",
    "text": "2.2 The Observed Data\nIn a completely randomized experiment, we have \\(N\\) individuals. We randomly assign \\(N_t\\) individuals to treatment and the remaining \\(N_c = N - N_t\\) individuals to control, where \\(1 &lt; N_t &lt; N\\) (so at least one individual is in each group).\n\n\nIn practice, we tend to use a balanced design where \\(N_t = N_c = \\dfrac{N}{2}\\), so that half of the respondents go into the treatment group and an equal number go into the control group.\nWe use the indicator variable \\(D_i\\) to denote the treatment assignment for individual \\(i\\).\n\n\\(D_i = 1\\) if individual \\(i\\) is assigned to treatment\n\\(D_i = 0\\) if individual \\(i\\) is assigned to control\n\nThus we can write that\n\\[\nN_t = \\sum_{i=1}^{N} D_i \\quad \\text{and} \\quad N_c = \\sum_{i=1}^{N} (1 - D_i).\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThe big sigma (\\(\\sum\\)) just means “add up.” The expression \\(\\sum_{i=1}^{N} D_i\\) says this: start with individual 1, then individual 2, then individual 3, and so on up to individual \\(N\\), and add up all their \\(D_i\\) values.\nSince each \\(D_i\\) is either 0 (control) or 1 (treatment), adding them up counts how many 1’s there are—that is, how many individuals are in the treatment group. That’s \\(N_t\\).\nThe expression \\((1 - D_i)\\) just flips the indicator. If \\(D_i = 1\\), then \\(1 - D_i = 0\\). If \\(D_i = 0\\), then \\(1 - D_i = 1\\). So adding up all the \\((1 - D_i)\\) values counts how many 0’s there are in the original \\(D_i\\)’s—that is, how many individuals are in the control group. That’s \\(N_c\\).\nExample. Suppose we have \\(N = 5\\) individuals with the following treatment assignments:\n\n\n\nIndividual \\(i\\)\n\\(D_i\\)\n\\(1 - D_i\\)\n\n\n\n\n1\n1\n0\n\n\n2\n0\n1\n\n\n3\n1\n0\n\n\n4\n0\n1\n\n\n5\n1\n0\n\n\n\nTo count the treated individuals, we add up the \\(D_i\\) column: \\(N_t = 1 + 0 + 1 + 0 + 1 = 3\\).\nTo count the control individuals, we add up the \\(1 - D_i\\) column: \\(N_c = 0 + 1 + 0 + 1 + 0 = 2\\).\nThree individuals are treated; two are in control.\n\n\n\nFor each individual, we observe only one potential outcome. We call this the observed outcome, denoted \\(Y_i^{\\text{obs}}\\), so that\n\\[\nY_i^{\\text{obs}} = Y_i(D_i) =\n\\begin{cases}\nY_i(0) & \\text{if } D_i = 0 \\\\\nY_i(1) & \\text{if } D_i = 1\n\\end{cases}.\n\\]\nThe other potential outcome—the one we don’t observe—is the missing outcome, denoted \\(Y_i^{\\text{mis}}\\), so that\n\\[\nY_i^{\\text{mis}} = Y_i(1 - D_i) =\n\\begin{cases}\nY_i(1) & \\text{if } D_i = 0 \\\\\nY_i(0) & \\text{if } D_i = 1\n\\end{cases}.\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThe notation \\(Y_i(D_i)\\) means “plug the value of \\(D_i\\) into the potential outcome function.” Since \\(D_i\\) is either 0 or 1, this gives us either \\(Y_i(0)\\) or \\(Y_i(1)\\)—whichever one actually happened.\nThe curly brace notation is just a compact way of writing “if-then” rules. It says: look at \\(D_i\\), and depending on its value, pick the corresponding potential outcome.\nFor the observed outcome \\(Y_i^{\\text{obs}}\\), we get the potential outcome that matches the treatment the individual actually received. For the missing outcome \\(Y_i^{\\text{mis}}\\), we get the other potential outcome—the one we can’t see.\nExample. Suppose we have \\(N = 5\\) individuals with the following potential outcomes and treatment assignments:\n\n\n\n\n\n\n\n\n\n\n\nIndividual \\(i\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\\(Y_i^{\\text{mis}}\\)\n\n\n\n\n1\n4\n7\n1\n7\n4\n\n\n2\n6\n5\n0\n6\n5\n\n\n3\n5\n8\n1\n8\n5\n\n\n4\n3\n6\n0\n3\n6\n\n\n5\n7\n9\n1\n9\n7\n\n\n\nFor individual 1, \\(D_1 = 1\\) (treated), so we observe \\(Y_1^{\\text{obs}} = Y_1(1) = 7\\) and the missing outcome is \\(Y_1^{\\text{mis}} = Y_1(0) = 4\\).\nFor individual 2, \\(D_2 = 0\\) (control), so we observe \\(Y_2^{\\text{obs}} = Y_2(0) = 6\\) and the missing outcome is \\(Y_2^{\\text{mis}} = Y_2(1) = 5\\).\n\n\n\n\n2.2.1 What the Data Look Like\nTo make this concrete, consider again our hypothetical experiment with 10 respondents. Suppose we know all the potential outcomes:\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n4\n7\n3\n\n\n2\n6\n5\n-1\n\n\n3\n5\n5\n0\n\n\n4\n3\n9\n6\n\n\n5\n7\n10\n3\n\n\n6\n5\n4\n-1\n\n\n7\n4\n8\n4\n\n\n8\n6\n7\n1\n\n\n9\n5\n3\n-2\n\n\n10\n4\n6\n2\n\n\n\nWe computed in the previous chapter that \\(\\text{ATE} = 1.5\\) for these data.\nNow suppose we run an experiment with \\(N_t = 5\\) and \\(N_c = 5\\). After randomization, respondents 1, 4, 5, 7, and 10 are assigned to treatment, while respondents 2, 3, 6, 8, and 9 are assigned to control. What do we actually observe?\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n?\n7\n1\n7\n\n\n2\n6\n?\n0\n6\n\n\n3\n5\n?\n0\n5\n\n\n4\n?\n9\n1\n9\n\n\n5\n?\n10\n1\n10\n\n\n6\n5\n?\n0\n5\n\n\n7\n?\n8\n1\n8\n\n\n8\n6\n?\n0\n6\n\n\n9\n5\n?\n0\n5\n\n\n10\n?\n6\n1\n6\n\n\n\nNotice that for each respondent, we observe exactly one potential outcome. The question marks represent the counterfactual outcomes we can never observe. We cannot compute \\(\\tau_i = Y_i(1) - Y_i(0)\\) for any individual because we never have both values.\nBut here’s the key insight: even though we can’t compute individual treatment effects, we can compute averages within the treatment and control groups.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#the-difference-in-means-estimator",
    "href": "ch/ate-hat.html#the-difference-in-means-estimator",
    "title": "2  Estimating the ATE",
    "section": "2.3 The Difference-in-Means Estimator",
    "text": "2.3 The Difference-in-Means Estimator\nA natural approach is to estimate the ATE by comparing the average outcome among treated individuals to the average outcome among control individuals. We define \\(\\overline{Y}^{\\text{obs}}_{t}\\) and \\(\\overline{Y}^{\\text{obs}}_{c}\\) as\n\\[\n\\overline{Y}^{\\text{obs}}_{t} = \\frac{1}{N_t} \\sum_{i:D_i=1} Y^{\\text{obs}}_{i} \\quad \\text{and} \\quad \\overline{Y}^{\\text{obs}}_{c} = \\frac{1}{N_c} \\sum_{i:D_i=0} Y^{\\text{obs}}_{i}.\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThe bar over \\(Y\\) (as in \\(\\overline{Y}\\)) means “average.” So \\(\\overline{Y}^{\\text{obs}}_{t}\\) is the average observed outcome in the treatment group, and \\(\\overline{Y}^{\\text{obs}}_{c}\\) is the average observed outcome in the control group.\nThe subscript \\(i:D_i=1\\) under the summation sign means “only add up the individuals where \\(D_i = 1\\)”—that is, only the treated individuals. Similarly, \\(i:D_i=0\\) means “only the control individuals.”\nSo the formula says this: add up the observed outcomes for all treated individuals, then divide by \\(N_t\\) (the number of treated individuals) to get the average. Do the same for control individuals, dividing by \\(N_c\\).\nExample. Suppose we have \\(N = 5\\) individuals:\n\n\n\nIndividual \\(i\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n1\n7\n\n\n2\n0\n6\n\n\n3\n1\n8\n\n\n4\n0\n3\n\n\n5\n1\n9\n\n\n\nThere are \\(N_t = 3\\) treated individuals (individuals 1, 3, and 5) and \\(N_c = 2\\) control individuals (individuals 2 and 4).\nFor the treatment group, we add up only the outcomes where \\(D_i = 1\\), so that\n\\[\n\\overline{Y}^{\\text{obs}}_{t} = \\frac{1}{3}(7 + 8 + 9) = \\frac{24}{3} = 8.\n\\]\nFor the control group, we add up only the outcomes where \\(D_i = 0\\), so that\n\\[\n\\overline{Y}^{\\text{obs}}_{c} = \\frac{1}{2}(6 + 3) = \\frac{9}{2} = 4.5.\n\\]\n\n\n\nThese are the average observed outcomes in the treatment group and the control group, respectively.\nThe difference-in-means estimator for the ATE is\n\\[\n\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}.\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThe “hat” over ATE (as in \\(\\widehat{\\text{ATE}}\\)) means “estimate of.” We can’t compute the true ATE because we don’t observe all potential outcomes, so we estimate it using the data we have.\nThe formula says: take the average outcome among treated individuals and subtract the average outcome among control individuals. That’s it—just a difference of two averages.\nExample. Using the same 5 individuals from before:\n\n\n\nIndividual \\(i\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n1\n7\n\n\n2\n0\n6\n\n\n3\n1\n8\n\n\n4\n0\n3\n\n\n5\n1\n9\n\n\n\nWe already computed \\(\\overline{Y}^{\\text{obs}}_{t} = 8\\) and \\(\\overline{Y}^{\\text{obs}}_{c} = 4.5\\).\nThus \\(\\widehat{\\text{ATE}} = 8 - 4.5 = 3.5\\). Our estimate is that the treatment increases outcomes by 3.5 units on average.\n\n\n\n\n2.3.1 Computing the Estimate\nUsing our example data, we can compute\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{5}(7 + 9 + 10 + 8 + 6) = \\frac{40}{5} = 8\n\\end{align}\n\\]\nand\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{5}(6 + 5 + 5 + 6 + 5) = \\frac{27}{5} = 5.4\n\\end{align}.\n\\]\nTherefore \\(\\widehat{\\text{ATE}} = 8 - 5.4 = 2.6\\). But recall that the true ATE (which we computed using all potential outcomes) is 1.5. So our estimate is off by 1.1 units.\nIs this a problem? Not necessarily. Any particular estimate will differ from the true ATE due to the randomness in treatment assignment. The question is whether, on average across all possible randomizations, our estimator gets it right.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#why-this-estimator",
    "href": "ch/ate-hat.html#why-this-estimator",
    "title": "2  Estimating the ATE",
    "section": "2.4 Why This Estimator?",
    "text": "2.4 Why This Estimator?\nWhy is \\(\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\) a sensible estimator of the ATE?\nRecall that we define the ATE as\n\\[\n\\text{ATE} = \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) = \\overline{Y}(1) - \\overline{Y}(0).\n\\]\nThe ATE is the difference between two population averages: the average of all potential outcomes under treatment and the average of all potential outcomes under control.\nOur estimator replaces these population averages with sample averages:\n\nInstead of averaging \\(Y_i(1)\\) over all individuals, we average \\(Y_i^{\\text{obs}}\\) over individuals assigned to treatment\nInstead of averaging \\(Y_i(0)\\) over all individuals, we average \\(Y_i^{\\text{obs}}\\) over individuals assigned to control\n\n\n\nThis “plug-in” approach—replacing population quantities with their sample counterparts—is a fundamental strategy in statistics. Under random assignment, the treated individuals are a random sample from the population, so \\(\\overline{Y}^{\\text{obs}}_{t}\\) should be a good estimate of \\(\\overline{Y}(1)\\). Similarly, the control individuals are a random sample, so \\(\\overline{Y}^{\\text{obs}}_{c}\\) should be a good estimate of \\(\\overline{Y}(0)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#design-based-inference",
    "href": "ch/ate-hat.html#design-based-inference",
    "title": "2  Estimating the ATE",
    "section": "2.5 Design-Based Inference",
    "text": "2.5 Design-Based Inference\nBefore proving that the estimator \\(\\widehat{\\text{ATE}}\\) is unbiased, we need to understand\n\nthat the estimate $ is a noisy and random estimate and\n\nwhat makes this estimate random in the first place.\n\nIn typical statistical settings, we imagine that data are drawn from some distribution \\(Y_i \\sim f(\\theta)\\). The randomness comes from imagining that the data could have been different if we had drawn a different sample from the population.\nBut in the potential outcomes framework for randomized experiments, we take a different view. The potential outcomes \\(Y_i(0)\\) and \\(Y_i(1)\\) are treated as fixed values, not random variables. They are simply the outcomes each individual would experience under each condition—there’s nothing random about the potential outcomes.\nThe only randomness in the experiment comes from the treatment assignment \\(D_i\\). And because we designed the randomization mechanism, we know exactly how this randomness works.\nThis is important: because we designed the randomization mechanism, we know exactly how this randomness works.\nThis is called design-based inference in which all uncertainty comes from the design of the experiment (i.e., the random assignment in this case), not from any model of how outcomes are generated.\nTo make this explicit, we can rewrite the estimator to highlight what is random and what is fixed, so that\n\\[\n\\widehat{\\text{ATE}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{D_i \\cdot Y_i(1)}{N_t/N} - \\frac{(1 - D_i) \\cdot Y_i(0)}{N_c/N} \\right).\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThis formula looks intimidating, but it’s just a clever rewriting of the difference-in-means estimator that separates the random part (\\(D_i\\)) from the fixed parts (potential outcomes).\nLet’s break it down piece by piece:\n\n\\(D_i \\cdot Y_i(1)\\): This equals \\(Y_i(1)\\) when individual \\(i\\) is treated (\\(D_i = 1\\)) and equals 0 when individual \\(i\\) is in control (\\(D_i = 0\\)). So it “turns on” the treated potential outcome only for treated individuals.\n\\((1 - D_i) \\cdot Y_i(0)\\): This does the opposite—it equals \\(Y_i(0)\\) when \\(D_i = 0\\) and equals 0 when \\(D_i = 1\\). It “turns on” the control potential outcome only for control individuals.\n\\(N_t/N\\): This is the fraction of individuals assigned to treatment (the treatment probability).\nDividing by \\(N_t/N\\) in the first term and \\(N_c/N\\) in the second term rescales each contribution so that the formula averages correctly over each group.\n\nThe key insight is that when you work through the algebra, this formula gives exactly the same answer as \\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\). But writing it this way makes clear that \\(D_i\\) is the only random quantity—the potential outcomes \\(Y_i(1)\\) and \\(Y_i(0)\\) are fixed numbers.\nExample. Suppose \\(N = 4\\) with \\(N_t = 2\\) and \\(N_c = 2\\) and the following potential outcomes and randomization:\n\n\n\nIndividual \\(i\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\n\n\n\n1\n4\n7\n1\n\n\n2\n6\n5\n0\n\n\n3\n3\n8\n1\n\n\n4\n5\n6\n0\n\n\n\nFor individual 1 (\\(D_1 = 1\\)): the contribution is \\(\\frac{1 \\cdot 7}{2/4} - \\frac{0 \\cdot 4}{2/4} = \\frac{7}{0.5} - 0 = 14\\).\nFor individual 2 (\\(D_2 = 0\\)): the contribution is \\(\\frac{0 \\cdot 5}{2/4} - \\frac{1 \\cdot 6}{2/4} = 0 - \\frac{6}{0.5} = -12\\).\nFor individual 3 (\\(D_3 = 1\\)): the contribution is \\(\\frac{1 \\cdot 8}{0.5} - 0 = 16\\).\nFor individual 4 (\\(D_4 = 0\\)): the contribution is \\(0 - \\frac{5}{0.5} = -10\\).\nAdding these and dividing by \\(N = 4\\): \\(\\widehat{\\text{ATE}} = \\frac{1}{4}(14 - 12 + 16 - 10) = \\frac{8}{4} = 2\\).\nYou can verify this equals the simple difference in means: \\(\\overline{Y}^{\\text{obs}}_{t} = \\frac{7 + 8}{2} = 7.5\\) and \\(\\overline{Y}^{\\text{obs}}_{c} = \\frac{6 + 5}{2} = 5.5\\), so \\(\\widehat{\\text{ATE}} = 7.5 - 5.5 = 2\\).\n\n\n\nIn this expression\n\n\\(Y_i(1)\\) and \\(Y_i(0)\\) are fixed (the potential outcomes)\n\\(N\\), \\(N_t\\), and \\(N_c\\) are fixed (determined by design)\n\\(D_i\\) is random (the only source of uncertainty)\n\nThe subscript notation \\(E_D[\\cdot]\\) indicates that we are taking expectations with respect to the randomization distribution—the distribution induced by the random assignment of individuals to treatment and control.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#unbiasedness-of-widehattextate",
    "href": "ch/ate-hat.html#unbiasedness-of-widehattextate",
    "title": "2  Estimating the ATE",
    "section": "2.6 Unbiasedness of \\(\\widehat{\\text{ATE}}\\)",
    "text": "2.6 Unbiasedness of \\(\\widehat{\\text{ATE}}\\)\nWe now prove the key result: \\(\\widehat{\\text{ATE}}\\) is an unbiased estimator of \\(\\text{ATE}\\). Informally, this means that our estimator “gets it right on average”. It means that if we could repeat the randomization many times, our estimates would exactly equal the ATE in the long-run.\nTo state this result precisely, we need to introduce some notation. The notation is tedious, but the underlying idea is straightforward, important, and powerful.\n\n2.6.1 The Expectation Operator \\(E[\\cdot]\\)\nThe expectation operator \\(E[\\cdot]\\) is just a way of writing “long-run average.”\n\n\nThe expectation of a random variable is its average value across all possible outcomes, weighted by how likely each outcome is. You can think of \\(E[X]\\) as asking: “If I could repeat this random process infinitely many times, what would \\(X\\) average out to?”\nFor our purposes, we need four simple rules about expectations.\nRule 1: The expectation of a constant is that constant.\nIf \\(c\\) is a fixed number (not random), then \\(E[c] = c\\).\nIf something never changes, its “average” is just itself. For example, \\(E[5] = 5\\).\nRule 2: Constants can be pulled outside the expectation.\nIf \\(c\\) is a constant and \\(X\\) is random, then \\(E[c \\cdot X] = c \\cdot E[X]\\).\nThe average of “5 times something random” equals 5 times the average of that random thing. If on average you earn $100 per day, then on average you earn $500 per five-day week.\nRule 3: The expectation of a sum is the sum of the expectations.\nIf \\(X\\) and \\(Y\\) are random variables, then\n\\[\nE[X + Y] = E[X] + E[Y].\n\\]\nThe average of “two random things added together” equals the sum of their averages. If on average you earn $100 per day from your job and $20 per day from side work, then on average you earn $120 per day total. You do not need \\(X\\) and \\(Y\\) to be independent for this rule to hold.\nRule 4: The expectation of a binary (0/1) random variable equals its probability of being 1.\nIf \\(X\\) can only be 0 or 1, then \\(E[X] = \\Pr(X = 1)\\).\nThis is the key rule for our proof. And it’s intuitive. If you flip a fair coin and let \\(X = 1\\) for heads and \\(X = 0\\) for tails, what’s the average value of \\(X\\)? Half the time you get 1, half the time you get 0, so the average is \\(\\frac{1}{2}(1) + \\frac{1}{2}(0) = 0.5\\). And \\(\\Pr(X = 1) = 0.5\\). They match!\nMore generally, if you repeat the process many times, the fraction of 1’s you observe will approach the probability of getting a 1. So the average value equals the probability.\n\n\nWhy does Rule 4 work? Well, remember that the expectation of a random variable is defined as the sum of each possible value times its probability, so that\n\\[\nE[X] = \\sum_{\\text{all values } x} x \\cdot \\Pr(X = x).\n\\]\nFor a binary variable that can only be 0 or 1, then we have\n\\[\nE[X] = 0 \\cdot \\Pr(X = 0) + 1 \\cdot \\Pr(X = 1) = \\Pr(X = 1).\n\\]\nThe zero term disappears, and we’re left with just the probability that \\(X\\) equals 1.\nExample. Suppose you roll a die and let \\(X = 1\\) if you roll a 6, and \\(X = 0\\) otherwise. Then \\(\\Pr(X = 1) = 1/6\\), so \\(E[X] = 1/6 \\approx 0.167\\). If you rolled the die 600 times, you’d expect about 100 sixes, and your average value of \\(X\\) would be about \\(100/600 = 0.167\\).\n\n\n2.6.2 The Theorem\nNow we can state the key result precisely. When we write \\(E_D[\\widehat{\\text{ATE}}]\\), we mean “the average value of our estimate across all possible random assignments.” (The subscript \\(D\\) reminds us that the only randomness comes from treatment assignment.)\n\n\n\n\n\n\nTheorem\n\n\n\nUnder random assignment, \\(\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\) is an unbiased estimator of the ATE. This mean that \\[\nE_D[\\widehat{\\text{ATE}}] = \\text{ATE}.\n\\]\n\n\nIf we average our estimate over all the different ways we could have randomly assigned individuals to treatment and control, we get exactly the true ATE.\n\n\n2.6.3 The Proof\nProof. We want to show that \\(E_D[\\widehat{\\text{ATE}}] = \\text{ATE}\\).\nStep 1: Write the estimator to separate random from fixed.\nFirst, we write \\(\\widehat{\\text{ATE}}\\) in a form that clearly separates the random part (\\(D_i\\)) from the fixed parts (the potential outcomes \\(Y_i(1)\\) and \\(Y_i(0)\\)). We borrow the representation above, where\n\\[\n\\widehat{\\text{ATE}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{D_i \\cdot Y_i(1)}{N_t/N} - \\frac{(1 - D_i) \\cdot Y_i(0)}{N_c/N} \\right).\n\\]\nThis formula looks complicated, but it has two important features:\n\nIt equals the difference in the observed means (though this is only apparent after studying it carefully).\nIt highlights that \\(D_i\\) is the only random thing.\nIt will be easy to use with the rules for expectations.\n\nStep 2: Take the expectation.\nNow we ask: what is the average value of \\(\\widehat{\\text{ATE}}\\) across all possible randomizations?\n\\[\nE_D[\\widehat{\\text{ATE}}] = E_D\\left[ \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{D_i \\cdot Y_i(1)}{N_t/N} - \\frac{(1 - D_i) \\cdot Y_i(0)}{N_c/N} \\right) \\right]\n\\]\nStep 3: Move the expectation inside.\nHere’s where the magic happens. Because the potential outcomes are fixed numbers and only \\(D_i\\) is random, we can move the expectation operator inside the formula until it includes only \\(D_i\\) and \\(1 - D_i\\). Rule 2 above allows us to do this.\n\n\nThink of it this way: if you’re computing the average of “5 times something random,” you can compute it as “5 times the average of that random thing” (that’s Rule 2). The \\(\\frac{1}{N}\\), the \\(\\sum\\), the potential outcomes \\(Y_i(1)\\) and \\(Y_i(0)\\), the fractions \\(N_t/N\\) and \\(N_c/N\\) are all fixed numbers that pass right through the expectation. The expectation only “grabs onto” the random part, \\(D_i\\).\n\\[\nE_D[\\widehat{\\text{ATE}}] = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{E_D[D_i] \\cdot Y_i(1)}{N_t/N} - \\frac{E_D[1 - D_i] \\cdot Y_i(0)}{N_c/N} \\right)\n\\]\n\\[\\begin{align}\nE_D[\\widehat{\\text{ATE}}]\n&= E_D\\!\\left[\n\\frac{1}{N} \\sum_{i=1}^{N}\n\\left(\n\\frac{D_i\\, Y_i(1)}{N_t/N}\n-\n\\frac{(1 - D_i)\\, Y_i(0)}{N_c/N}\n\\right)\n\\right]\n\\qquad \\text{(definition of the estimator)} \\\\[6pt]\n\n&= \\frac{1}{N}\nE_D\\!\\left[\n\\sum_{i=1}^{N}\n\\left(\n\\frac{D_i\\, Y_i(1)}{N_t/N}\n-\n\\frac{(1 - D_i)\\, Y_i(0)}{N_c/N}\n\\right)\n\\right]\n\\qquad \\text{($\\tfrac{1}{N}$ is constant; Rule 2)} \\\\[6pt]\n\n&= \\frac{1}{N}\n\\sum_{i=1}^{N}\nE_D\\!\\left[\n\\frac{D_i\\, Y_i(1)}{N_t/N}\n-\n\\frac{(1 - D_i)\\, Y_i(0)}{N_c/N}\n\\right]\n\\qquad \\text{(expectation of asum; Rule 3)} \\\\[6pt]\n\n&= \\frac{1}{N}\n\\sum_{i=1}^{N}\n\\left(\n\\frac{Y_i(1)}{N_t/N} \\, E_D[D_i]\n-\n\\frac{Y_i(0)}{N_c/N} \\, E_D[1 - D_i]\n\\right)\n\\qquad \\text{(only $D_i$ is random; Rule 2)}.\n\\end{align}\\] }\nStep 4: Compute the expectation of \\(D_i\\).\nNow we need to find \\(E_D[D_i]\\). Remember that \\(D_i\\) is a binary variable that equals 1 if individual \\(i\\) is assigned to treatment, and 0 if individual \\(i\\) is assigned to control. By Rule 4, the expectation of a binary variable equals its probability of being 1, so that\n\\[\nE_D[D_i] = \\Pr(D_i = 1).\n\\]\nUnder completely randomized assignment, every individual has the same chance of being assigned to treatment. If we’re assigning \\(N_t\\) individuals to treatment out of \\(N\\) total individuals, then each individual has probability \\(N_t/N\\) of being treated so that\n\\[\nE_D[D_i] = \\Pr(D_i = 1) = \\frac{N_t}{N}.\n\\]\nStep 5: Compute the expectation of \\(1 - D_i\\).\nSimilarly, \\(1 - D_i\\) is also binary. It equals 1 when \\(D_i = 0\\) (individual in control) and equals 0 when \\(D_i = 1\\) (individual in treatment). Then we have\n\\[\nE_D[1 - D_i] = \\Pr(D_i = 0) = \\frac{N_c}{N}.\n\\]\nStep 6: Substitute and simplify.\nNow we plug these values back in, we obtain\n\\[\n\\begin{align}\nE_D[\\widehat{\\text{ATE}}] &= \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{(N_t/N) \\cdot Y_i(1)}{N_t/N} - \\frac{(N_c/N) \\cdot Y_i(0)}{N_c/N} \\right).\n\\end{align}\n\\] Then something magical happens. In the first term, we have \\(N_t/N\\) in both the numerator and denominator, so they cancel out.\nThe same thing happens with \\(N_c/N\\) in the second term, so that\n\\[\n\\begin{align}\nE_D[\\widehat{\\text{ATE}}] &= \\frac{1}{N} \\sum_{i=1}^{N} \\left( Y_i(1) - Y_i(0) \\right).\n\\end{align}\n\\]\nThis is just the average of individual treatment effects across all individuals. This is exactly the definition of the ATE, so that\n\\[\nE_D[\\widehat{\\text{ATE}}] = \\text{ATE}.\n\\]\nThis completes the proof and shows that \\(\\widehat{\\text{ATE}}\\) is an unbiased estimator of \\(\\widehat{\\text{ATE}}\\). \\(\\square\\)\n\n\n\n\n\n\nTip\n\n\n\nThe key insight is that the fractions \\(N_t/N\\) and \\(N_c/N\\) cancel perfectly. This happens because (1) the probability of assignment to treatment equals \\(N_t/N\\), and (2) we divide by \\(N_t\\) when averaging over treated individuals. The “selection” into treatment is perfectly balanced by the “weighting” in our estimator.\n\n\n\n\n2.6.4 What Does Unbiasedness Mean?\nUnbiasedness means that on average, across all possible randomizations, our estimator equals the true ATE. Any particular estimate might be too high or too low, but there’s no systematic tendency to over- or under-estimate.\nIn our example, we got \\(\\widehat{\\text{ATE}} = 2.6\\) when the true ATE is 1.5. This particular randomization overestimated. But if we had assigned different individuals to treatment, we might have gotten a different estimate. Some randomizations would overestimate, some would underestimate, and on average we would get it right.\n\n\n2.6.5 No Model Required\nNotice what we did not assume in this proof:\n\nWe did not assume any particular distribution for the outcomes\nWe did not assume the treatment effects are constant\nWe did not assume the outcomes are normally distributed\nWe did not assume any functional form for how treatment affects outcomes\nWe did not assume a “large” sample\n\nThe only assumption is that treatment was randomly assigned. This is why randomized experiments are so powerful. Randomization provides unbiased estimates (and other good things to be discussed later) without requiring strong modeling assumptions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#a-different-randomization",
    "href": "ch/ate-hat.html#a-different-randomization",
    "title": "2  Estimating the ATE",
    "section": "2.7 A Different Randomization",
    "text": "2.7 A Different Randomization\nTo reinforce that \\(\\widehat{\\text{ATE}}\\) depends on the randomization, consider what happens with a different random assignment. Suppose instead that individuals 2, 3, 6, 8, and 9 are assigned to treatment, while individuals 1, 4, 5, 7, and 10 are assigned to control.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n4\n?\n0\n4\n\n\n2\n?\n5\n1\n5\n\n\n3\n?\n5\n1\n5\n\n\n4\n3\n?\n0\n3\n\n\n5\n7\n?\n0\n7\n\n\n6\n?\n4\n1\n4\n\n\n7\n4\n?\n0\n4\n\n\n8\n?\n7\n1\n7\n\n\n9\n?\n3\n1\n3\n\n\n10\n4\n?\n0\n4\n\n\n\nNow we compute\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{5}(5 + 5 + 4 + 7 + 3) = \\frac{24}{5} = 4.8\n\\end{align}\n\\]\nand\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{5}(4 + 3 + 7 + 4 + 4) = \\frac{22}{5} = 4.4.\n\\end{align}\n\\]\nThus \\(\\widehat{\\text{ATE}} = 4.8 - 4.4 = 0.4\\).\nThis randomization gives us \\(\\widehat{\\text{ATE}} = 0.4\\), which underestimates the true ATE of 1.5. The first randomization overestimated (2.6), this one underestimates (0.4). Unbiasedness tells us that if we averaged over all possible randomizations, we would get exactly 1.5.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#computing-widehattextate-in-r",
    "href": "ch/ate-hat.html#computing-widehattextate-in-r",
    "title": "2  Estimating the ATE",
    "section": "2.8 Computing \\(\\widehat{\\text{ATE}}\\) in R",
    "text": "2.8 Computing \\(\\widehat{\\text{ATE}}\\) in R\nSo far, we have computed \\(\\widehat{\\text{ATE}}\\) by hand. In practice, we use software. In this section, we walk through two approaches in R: (1) using mean() to compute the difference in means directly, and (2) using lm() to fit a linear regression. Both approaches give the same answer, but mean() is a little more intuitive and lm() is more useful in the practice.\n\n2.8.1 The Mock Rasinski Data\nWe collected data that mimics Rasinski’s experiment. Each respondent was randomly assigned to see either the “welfare” wording or the “assistance to the poor” wording. The respondent then indicated whether they thought government spending on this program was “Too little,” “About right,” or “Too much.”\nFirst, let’s load the data and prepare it for analysis. For convenience, I’ve written a little tribble() as a convenient way to hold the data (rather than loading from a CSV).\n\n# load packages\nlibrary(tidyverse)\nlibrary(tibble)\nlibrary(forcats)\n\n# load the mock rasinski data\nrasinski &lt;- tribble(\n  ~desc,                     ~response,\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"About right\",\n  \"welfare\",                \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"About right\",\n  \"welfare\",                \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"welfare\",                \"Too much\",\n  \"welfare\",                \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too much\",\n  \"welfare\",                \"Too little\",\n  \"welfare\",                \"About right\",\n  \"welfare\",                \"About right\",\n  \"welfare\",                \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\"\n)\n\n# take a quick look\nglimpse(rasinski)\n\nRows: 39\nColumns: 2\n$ desc     &lt;chr&gt; \"assistance to the poor\", \"welfare\", \"assistance to the poor\"…\n$ response &lt;chr&gt; \"Too little\", \"Too little\", \"Too little\", \"Too little\", \"Too …\n\n\nThe desc variable contains the experimental condition. It takes on the value \"welfare\" (control) or \"assistance to the poor\" (treatment). The response variable contains the respondent’s answer.\nFollowing Rasinski’s coding scheme from the previous chapter, we code the outcome numerically:\n\nToo little = 1\nAbout right = 2\nToo much = 3\n\n\n# code the outcome variable numerically\nrasinski &lt;- rasinski |&gt;\n  mutate(\n    outcome = case_when(\n      response == \"Too little\" ~ 1,\n      response == \"About right\" ~ 2,\n      response == \"Too much\" ~ 3\n    )\n  ) |&gt;\n  glimpse()\n\nRows: 39\nColumns: 3\n$ desc     &lt;chr&gt; \"assistance to the poor\", \"welfare\", \"assistance to the poor\"…\n$ response &lt;chr&gt; \"Too little\", \"Too little\", \"Too little\", \"Too little\", \"Too …\n$ outcome  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 3…\n\n\nWe also need to create a treatment indicator variable. Following our convention, treatment (\\(D_i = 1\\)) is the “assistance to the poor” wording and control (\\(D_i = 0\\)) is the “welfare” wording.\n\n# create treatment indicator\nrasinski &lt;- rasinski |&gt;\n  mutate(\n    treatment = if_else(desc == \"assistance to the poor\", 1, 0)\n  ) |&gt;\n  glimpse()\n\nRows: 39\nColumns: 4\n$ desc      &lt;chr&gt; \"assistance to the poor\", \"welfare\", \"assistance to the poor…\n$ response  &lt;chr&gt; \"Too little\", \"Too little\", \"Too little\", \"Too little\", \"Too…\n$ outcome   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, …\n$ treatment &lt;dbl&gt; 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, …\n\n\n\n\n2.8.2 Approach 1: Using mean()\nThe difference-in-means estimator is\n\\[\n\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}.\n\\]\nWe can compute this directly using R’s mean() function. The key is to subset the data to get the outcomes for each group separately.\nStep 1: Identify the treated and control observations.\nWe use logical indexing to select rows where the treatment indicator equals 1 (treated) or 0 (control).\nWe can write compactly in a single line.\n\n# direct computation of difference in means\nate_hat &lt;- mean(rasinski$outcome[rasinski$treatment == 1]) -\n  mean(rasinski$outcome[rasinski$treatment == 0])\n\nate_hat\n\n[1] -0.2210526\n\n\nThe estimated ATE is -0.221. Since lower values indicate more support for spending (“Too little” = 1), a negative estimate means the “assistance to the poor” wording increases support for spending compared to the “welfare” wording.\n\n\n\n\n\n\nThis Is Only an Estimate\n\n\n\n\n\nRemember that \\(\\widehat{\\text{ATE}}\\) is an estimate of the true \\(\\text{ATE}\\), not the \\(\\text{ATE}\\) itself. If we had randomized respondents differently—assigning different people to treatment and control—we would have observed different outcomes and computed a different estimate. Perhaps it would have been a bit larger, perhaps a bit smaller, or perhaps even the opposite sign.\nThis is a fundamental feature of randomized experiments: the estimate we get depends on the particular randomization we happened to draw. The true \\(\\text{ATE}\\) is fixed (it’s determined by the potential outcomes in the population), but our estimate of it varies with the randomization.\nIn future chapters, we will address this uncertainty head-on. Our framework allows us to say a great deal about how good our estimate is—that is, how close \\(\\widehat{\\text{ATE}}\\) is likely to be to the true \\(\\text{ATE}\\). For now, just keep in mind that the number we computed is our best guess, but it comes with uncertainty that we haven’t yet quantified.\n\n\n\n\n\n2.8.3 Approach 2: Using lm()\nSetting Up the Model\nLinear regression with lm() provides another way to compute the same estimate. This might seem surprising at first. After all, regression is usually taught as a way to model relationships between variables. But it turns out that a simple regression of the outcome on a treatment indicator gives us exactly the difference in means.\nWhen can fit the model\n\\[\nY_i = \\beta_0 + \\beta_1 D_i + \\epsilon_i,\n\\]\nwhere \\(D_i\\) is the treatment indicator (1 = treated, 0 = control).\nThe estimated coefficients have a direct interpretation:\n\n\\(\\hat{\\beta}_0\\) is the mean outcome in the control group (\\(\\overline{Y}^{\\text{obs}}_{c}\\))\n\\(\\hat{\\beta}_1\\) is the difference in means (\\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\))\n\nFitting the Model\nFirst, we need to ensure that “welfare” (control) is the reference category for our treatment variable. When lm() encounters a factor variable, it creates a dummy variable using the first level as the reference. By default, R orders factor levels alphabetically, which would make “assistance to the poor” the reference—the opposite of what we want.\nWe use fct_relevel() from the forcats package to set “welfare” as the reference category.\n\n# create a factor with \"welfare\" as the reference category\nrasinski &lt;- rasinski |&gt;\n  mutate(\n    condition = fct_relevel(desc, \"welfare\")\n  )\n\n# verify: \"welfare\" should be first\nlevels(rasinski$condition)\n\n[1] \"welfare\"                \"assistance to the poor\"\n\n\nNow we fit the linear model.\n\n# fit the model\nfit &lt;- lm(outcome ~ condition, data = rasinski)\n\n# extract the coefficients\ncoef(fit)\n\n                    (Intercept) conditionassistance to the poor \n                      1.4210526                      -0.2210526 \n\n\nLet’s verify that these coefficients match our manual calculations.\n\n# the slope should equal the ATE estimate\ncoef(fit)[2]\n\nconditionassistance to the poor \n                     -0.2210526 \n\nate_hat\n\n[1] -0.2210526\n\n\nThe values match exactly. Using mean() makes the calculation transparent. You can see exactly what quantities are being computed: the mean in each group and their difference. This is valuable for understanding and teaching the concept. Using lm() will be more valuable in applied work. We’ll use lm() moving forward.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#key-terms",
    "href": "ch/ate-hat.html#key-terms",
    "title": "2  Estimating the ATE",
    "section": "2.9 Key Terms",
    "text": "2.9 Key Terms\n\nCompletely randomized experiment\nObserved outcome\nMissing outcome\nDifference-in-means estimator\nDesign-based inference\nUnbiasedness",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#exercises",
    "href": "ch/ate-hat.html#exercises",
    "title": "2  Estimating the ATE",
    "section": "2.10 Exercises",
    "text": "2.10 Exercises\n\n2.10.1 Conceptual Understanding\n\nObserved vs. Missing Outcomes: In your own words, explain the difference between \\(Y_i^{\\text{obs}}\\) and \\(Y_i^{\\text{mis}}\\). Why is one observable and the other not?\n\n\n\nSolution\n\n\\(Y_i^{\\text{obs}}\\) is the observed outcome—the potential outcome that corresponds to the treatment condition the individual actually received. If individual \\(i\\) was assigned to treatment (\\(D_i = 1\\)), then \\(Y_i^{\\text{obs}} = Y_i(1)\\). If individual \\(i\\) was assigned to control (\\(D_i = 0\\)), then \\(Y_i^{\\text{obs}} = Y_i(0)\\).\n\\(Y_i^{\\text{mis}}\\) is the missing outcome—the potential outcome that corresponds to the treatment condition the individual did not receive. It is the counterfactual: what would have happened if the individual had been assigned to the other condition.\nWe can observe \\(Y_i^{\\text{obs}}\\) because it is the outcome that actually occurred. Once we assign individual \\(i\\) to treatment, we see how they respond to treatment. But we cannot observe \\(Y_i^{\\text{mis}}\\) because we cannot simultaneously assign the same individual to both treatment and control. The individual can only be in one condition at a time, so we only ever see one of the two potential outcomes.\nThis is the fundamental problem of causal inference applied to the observed data.\n\n\nDesign-Based Inference: Explain what it means to say that inference in randomized experiments is “design-based” rather than “model-based.” What is the source of randomness in each approach?\n\n\n\nSolution\n\nIn design-based inference, the potential outcomes \\(Y_i(0)\\) and \\(Y_i(1)\\) are treated as fixed values—they are simply the outcomes each individual would experience under each condition. The only source of randomness comes from the treatment assignment \\(D_i\\). Because we designed the randomization mechanism, we know exactly how this randomness works.\nIn model-based inference, the outcomes themselves are treated as random draws from some probability distribution. The randomness comes from imagining that the data could have been different if we had drawn a different sample from the population, or from random variation in how outcomes are generated.\nThe key difference is where the uncertainty comes from:\n\nDesign-based: Uncertainty comes from the random assignment. The potential outcomes are fixed; we just don’t know which ones we’ll observe because we don’t know the randomization in advance.\nModel-based: Uncertainty comes from the data-generating process. The outcomes themselves are random, drawn from some distribution with unknown parameters.\n\nDesign-based inference is powerful because we don’t need to make assumptions about how outcomes are generated. We only rely on the randomization we controlled.\n\n\nThe Meaning of Unbiasedness: A student says, “Since \\(\\widehat{\\text{ATE}}\\) is unbiased, my estimate must equal the true ATE.” Explain why this is incorrect. What does unbiasedness actually guarantee?\n\n\n\nSolution\n\nThe student’s statement is incorrect. Unbiasedness does not mean that any single estimate equals the true ATE.\nUnbiasedness is a property about averages over repeated randomizations. Specifically, \\(\\widehat{\\text{ATE}}\\) is unbiased means:\n\\[E_D[\\widehat{\\text{ATE}}] = \\text{ATE}\\]\nIn plain language: if we could repeat the randomization infinitely many times and compute \\(\\widehat{\\text{ATE}}\\) each time, the average of all those estimates would equal the true ATE.\nAny particular estimate will almost certainly differ from the true ATE. Some randomizations will, by chance, put more high-outcome individuals in the treatment group, leading to overestimates. Other randomizations will put more high-outcome individuals in control, leading to underestimates. Unbiasedness tells us that these over- and under-estimates balance out on average—there is no systematic tendency to err in one direction.\nThe chapter example illustrates this: one randomization gave \\(\\widehat{\\text{ATE}} = 2.6\\) (overestimate), another gave \\(\\widehat{\\text{ATE}} = 0.4\\) (underestimate), but the true ATE was 1.5. Neither estimate equaled the truth, but they averaged out correctly.\n\n\nWhy Randomization Matters: Suppose instead of randomly assigning treatment, we let participants choose whether to receive treatment. Why would \\(\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\) no longer be unbiased for the ATE?\n\n\n\nSolution\n\nIf participants choose whether to receive treatment, the people who select into treatment may be systematically different from those who select into control. This is called self-selection bias.\nFor example, in a job training program where participants choose whether to enroll:\n\nPeople who are more motivated, more confident, or have better prospects might be more likely to enroll\nThese same characteristics might also lead to better outcomes regardless of training\n\nIn this case, the treatment group would have higher average outcomes than the control group even if the training itself had no effect. The difference in means would reflect both (1) any true effect of training and (2) pre-existing differences between the groups.\nMathematically, the proof of unbiasedness relies on the fact that \\(E_D[D_i] = N_t/N\\) for all individuals \\(i\\)—every individual has the same probability of being treated. With self-selection, this no longer holds. Individuals with higher potential outcomes might have higher probabilities of selecting treatment, which means \\(E_D[D_i]\\) would vary across individuals and would be correlated with potential outcomes.\nWhen treatment assignment is correlated with potential outcomes, the difference-in-means estimator captures both the treatment effect and the selection effect, making it biased for the ATE.\n\n\n\n2.10.2 Computational Practice\n\nComputing the Estimate: Consider the following observed data from a randomized experiment:\n\n\n\nIndividual\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n1\n12\n\n\n2\n0\n8\n\n\n3\n1\n15\n\n\n4\n0\n7\n\n\n5\n0\n9\n\n\n6\n1\n11\n\n\n\n\nWhat are \\(N_t\\) and \\(N_c\\)?\nCompute \\(\\overline{Y}^{\\text{obs}}_{t}\\) and \\(\\overline{Y}^{\\text{obs}}_{c}\\).\nCompute \\(\\widehat{\\text{ATE}}\\).\n\n\n\n\nSolution\n\nPart a. Count the individuals in each group by looking at the \\(D_i\\) column:\n\nIndividuals with \\(D_i = 1\\) (treatment): Individuals 1, 3, and 6\nIndividuals with \\(D_i = 0\\) (control): Individuals 2, 4, and 5\n\nSo \\(N_t = 3\\) and \\(N_c = 3\\).\nPart b. Compute the mean outcome in each group.\nFor the treatment group (individuals where \\(D_i = 1\\)):\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{N_t} \\sum_{i:D_i=1} Y_i^{\\text{obs}} \\\\\n&= \\frac{1}{3}(12 + 15 + 11) \\\\\n&= \\frac{38}{3} \\\\\n&\\approx 12.67\n\\end{align}\n\\]\nFor the control group (individuals where \\(D_i = 0\\)):\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{N_c} \\sum_{i:D_i=0} Y_i^{\\text{obs}} \\\\\n&= \\frac{1}{3}(8 + 7 + 9) \\\\\n&= \\frac{24}{3} \\\\\n&= 8\n\\end{align}\n\\]\nPart c. The difference-in-means estimator is:\n\\[\n\\begin{align}\n\\widehat{\\text{ATE}} &= \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c} \\\\\n&= 12.67 - 8 \\\\\n&= 4.67\n\\end{align}\n\\]\nOur estimate is that treatment increases outcomes by about 4.67 units on average.\n\n\nDifferent Randomizations: Suppose the true potential outcomes for 4 individuals are:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n2\n5\n\n\n2\n4\n6\n\n\n3\n3\n4\n\n\n4\n5\n7\n\n\n\n\nCompute the true ATE.\nIf individuals 1 and 3 are assigned to treatment (\\(D_1 = D_3 = 1\\)) and individuals 2 and 4 are assigned to control (\\(D_2 = D_4 = 0\\)), compute \\(\\widehat{\\text{ATE}}\\).\nIf individuals 2 and 4 are assigned to treatment and individuals 1 and 3 are assigned to control, compute \\(\\widehat{\\text{ATE}}\\).\nAverage your two estimates from (b) and (c). How does this compare to the true ATE?\n\n\n\n\nSolution\n\nPart a. First, compute the individual treatment effects:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i = Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n2\n5\n\\(5 - 2 = 3\\)\n\n\n2\n4\n6\n\\(6 - 4 = 2\\)\n\n\n3\n3\n4\n\\(4 - 3 = 1\\)\n\n\n4\n5\n7\n\\(7 - 5 = 2\\)\n\n\n\nThe true ATE is:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{4} \\sum_{i=1}^{4} \\tau_i \\\\\n&= \\frac{1}{4}(3 + 2 + 1 + 2) \\\\\n&= \\frac{8}{4} \\\\\n&= 2\n\\end{align}\n\\]\nPart b. With individuals 1 and 3 treated, and individuals 2 and 4 in control:\n\nTreatment group observes: \\(Y_1(1) = 5\\) and \\(Y_3(1) = 4\\)\nControl group observes: \\(Y_2(0) = 4\\) and \\(Y_4(0) = 5\\)\n\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(5 + 4) = \\frac{9}{2} = 4.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(4 + 5) = \\frac{9}{2} = 4.5 \\\\\n\\widehat{\\text{ATE}} &= 4.5 - 4.5 = 0\n\\end{align}\n\\]\nPart c. With individuals 2 and 4 treated, and individuals 1 and 3 in control:\n\nTreatment group observes: \\(Y_2(1) = 6\\) and \\(Y_4(1) = 7\\)\nControl group observes: \\(Y_1(0) = 2\\) and \\(Y_3(0) = 3\\)\n\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(6 + 7) = \\frac{13}{2} = 6.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(2 + 3) = \\frac{5}{2} = 2.5 \\\\\n\\widehat{\\text{ATE}} &= 6.5 - 2.5 = 4\n\\end{align}\n\\]\nPart d. The average of the two estimates:\n\\[\n\\frac{0 + 4}{2} = 2\n\\]\nThis equals the true ATE exactly! The first randomization underestimated (0 vs. 2), and the second overestimated (4 vs. 2), but they balanced out. This illustrates unbiasedness: on average, the estimator gets it right.\n\n\nVerifying Unbiasedness: Using the same potential outcomes from Exercise 6, list all possible ways to assign exactly 2 individuals to treatment and 2 to control. For each, compute \\(\\widehat{\\text{ATE}}\\). Then compute the average of all these estimates and verify that it equals the true ATE.\n\n\n\nSolution\n\nWith 4 individuals and 2 assigned to treatment, there are \\(\\binom{4}{2} = 6\\) possible randomizations. Let’s list each one and compute \\(\\widehat{\\text{ATE}}\\).\nRecall the potential outcomes:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n2\n5\n\n\n2\n4\n6\n\n\n3\n3\n4\n\n\n4\n5\n7\n\n\n\nRandomization 1: Individuals 1, 2 treated; Individuals 3, 4 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(5 + 6) = 5.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(3 + 5) = 4 \\\\\n\\widehat{\\text{ATE}} &= 5.5 - 4 = 1.5\n\\end{align}\n\\]\nRandomization 2: Individuals 1, 3 treated; Individuals 2, 4 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(5 + 4) = 4.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(4 + 5) = 4.5 \\\\\n\\widehat{\\text{ATE}} &= 4.5 - 4.5 = 0\n\\end{align}\n\\]\nRandomization 3: Individuals 1, 4 treated; Individuals 2, 3 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(5 + 7) = 6 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(4 + 3) = 3.5 \\\\\n\\widehat{\\text{ATE}} &= 6 - 3.5 = 2.5\n\\end{align}\n\\]\nRandomization 4: Individuals 2, 3 treated; Individuals 1, 4 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(6 + 4) = 5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(2 + 5) = 3.5 \\\\\n\\widehat{\\text{ATE}} &= 5 - 3.5 = 1.5\n\\end{align}\n\\]\nRandomization 5: Individuals 2, 4 treated; Individuals 1, 3 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(6 + 7) = 6.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(2 + 3) = 2.5 \\\\\n\\widehat{\\text{ATE}} &= 6.5 - 2.5 = 4\n\\end{align}\n\\]\nRandomization 6: Individuals 3, 4 treated; Individuals 1, 2 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(4 + 7) = 5.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(2 + 4) = 3 \\\\\n\\widehat{\\text{ATE}} &= 5.5 - 3 = 2.5\n\\end{align}\n\\]\nSummary of all estimates:\n\n\n\nRandomization\nTreated Individuals\n\\(\\widehat{\\text{ATE}}\\)\n\n\n\n\n1\n1, 2\n1.5\n\n\n2\n1, 3\n0\n\n\n3\n1, 4\n2.5\n\n\n4\n2, 3\n1.5\n\n\n5\n2, 4\n4\n\n\n6\n3, 4\n2.5\n\n\n\nAverage of all estimates:\n\\[\n\\begin{align}\nE_D[\\widehat{\\text{ATE}}] &= \\frac{1}{6}(1.5 + 0 + 2.5 + 1.5 + 4 + 2.5) \\\\\n&= \\frac{12}{6} \\\\\n&= 2\n\\end{align}\n\\]\nThe average of all possible estimates equals 2, which is exactly the true ATE we computed in Exercise 6. This confirms that \\(\\widehat{\\text{ATE}}\\) is unbiased: averaged across all possible randomizations, it equals the truth.\n\n\n\n2.10.3 Application to Rasinski’s Experiment\n\nRasinski’s Experiment Revisited: Return to the hypothetical Rasinski data from the previous chapter. Suppose we randomly assign 5 respondents to the “assistance to the poor” wording (treatment) and 5 to the “welfare” wording (control).\n\n\n\nRespondent\n\\(Y_i(0)\\) (“welfare”)\n\\(Y_i(1)\\) (“assistance”)\n\n\n\n\n1\n3 (Too much)\n1 (Too little)\n\n\n2\n3 (Too much)\n2 (About right)\n\n\n3\n2 (About right)\n1 (Too little)\n\n\n4\n3 (Too much)\n1 (Too little)\n\n\n5\n2 (About right)\n1 (Too little)\n\n\n6\n3 (Too much)\n2 (About right)\n\n\n7\n2 (About right)\n1 (Too little)\n\n\n8\n3 (Too much)\n1 (Too little)\n\n\n9\n2 (About right)\n2 (About right)\n\n\n10\n3 (Too much)\n1 (Too little)\n\n\n\n\nWe know from the previous chapter that the true ATE is -1.3. If respondents 1, 3, 5, 7, and 9 are assigned to treatment, compute \\(\\widehat{\\text{ATE}}\\). How close is it to the true ATE?\nIf respondents 2, 4, 6, 8, and 10 are assigned to treatment instead, compute \\(\\widehat{\\text{ATE}}\\). How close is it to the true ATE?\nAverage your estimates from (a) and (b). What do you notice?\n\n\n\n\nSolution\n\nPart a. With respondents 1, 3, 5, 7, and 9 assigned to treatment:\n\nTreatment group (sees “assistance to the poor”): Respondents 1, 3, 5, 7, 9\n\nObserved outcomes: \\(Y_1(1) = 1\\), \\(Y_3(1) = 1\\), \\(Y_5(1) = 1\\), \\(Y_7(1) = 1\\), \\(Y_9(1) = 2\\)\n\nControl group (sees “welfare”): Respondents 2, 4, 6, 8, 10\n\nObserved outcomes: \\(Y_2(0) = 3\\), \\(Y_4(0) = 3\\), \\(Y_6(0) = 3\\), \\(Y_8(0) = 3\\), \\(Y_{10}(0) = 3\\)\n\n\nComputing the means:\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{5}(1 + 1 + 1 + 1 + 2) = \\frac{6}{5} = 1.2 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{5}(3 + 3 + 3 + 3 + 3) = \\frac{15}{5} = 3 \\\\\n\\widehat{\\text{ATE}} &= 1.2 - 3 = -1.8\n\\end{align}\n\\]\nThis estimate of \\(-1.8\\) is 0.5 units away from the true ATE of \\(-1.3\\). It overestimates the magnitude of the effect.\nPart b. With respondents 2, 4, 6, 8, and 10 assigned to treatment:\n\nTreatment group: Respondents 2, 4, 6, 8, 10\n\nObserved outcomes: \\(Y_2(1) = 2\\), \\(Y_4(1) = 1\\), \\(Y_6(1) = 2\\), \\(Y_8(1) = 1\\), \\(Y_{10}(1) = 1\\)\n\nControl group: Respondents 1, 3, 5, 7, 9\n\nObserved outcomes: \\(Y_1(0) = 3\\), \\(Y_3(0) = 2\\), \\(Y_5(0) = 2\\), \\(Y_7(0) = 2\\), \\(Y_9(0) = 2\\)\n\n\nComputing the means:\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{5}(2 + 1 + 2 + 1 + 1) = \\frac{7}{5} = 1.4 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{5}(3 + 2 + 2 + 2 + 2) = \\frac{11}{5} = 2.2 \\\\\n\\widehat{\\text{ATE}} &= 1.4 - 2.2 = -0.8\n\\end{align}\n\\]\nThis estimate of \\(-0.8\\) is 0.5 units away from the true ATE of \\(-1.3\\). It underestimates the magnitude of the effect.\nPart c. The average of the two estimates:\n\\[\n\\frac{-1.8 + (-0.8)}{2} = \\frac{-2.6}{2} = -1.3\n\\]\nThe average equals the true ATE exactly! This is a concrete illustration of unbiasedness. The first randomization overestimated the effect (in magnitude), and the second underestimated it by the same amount. When we average them, we get exactly the truth.\nNote: These two randomizations are not the only possible ones—there are \\(\\binom{10}{5} = 252\\) ways to assign 5 of 10 respondents to treatment. If we computed \\(\\widehat{\\text{ATE}}\\) for all 252 and averaged them, we would get exactly \\(-1.3\\).\n\n\nWhat the Researcher Sees: In Rasinski’s actual experiment, the researcher does not observe the potential outcomes table—they only observe the outcomes under the assigned condition.\n\nUsing the randomization from Exercise 8a (respondents 1, 3, 5, 7, 9 assigned to treatment), write out the data table that the researcher would actually observe. Use “?” for unobserved potential outcomes.\nCan the researcher compute the true ATE from this observed data? Why or why not?\nWhat does the researcher compute instead, and why is this a reasonable substitute?\n\n\n\n\nSolution\n\nPart a. With respondents 1, 3, 5, 7, 9 assigned to treatment, the researcher observes:\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n?\n1\n1\n1\n\n\n2\n3\n?\n0\n3\n\n\n3\n?\n1\n1\n1\n\n\n4\n3\n?\n0\n3\n\n\n5\n?\n1\n1\n1\n\n\n6\n3\n?\n0\n3\n\n\n7\n?\n1\n1\n1\n\n\n8\n3\n?\n0\n3\n\n\n9\n?\n2\n1\n2\n\n\n10\n3\n?\n0\n3\n\n\n\nFor each respondent, the researcher sees only one potential outcome—the one corresponding to their assigned condition. The other potential outcome is forever unknown.\nPart b. No, the researcher cannot compute the true ATE from this observed data.\nThe true ATE requires knowing all potential outcomes:\n\\[\\text{ATE} = \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0)\\]\nBut the researcher is missing \\(Y_i(0)\\) for treated respondents (respondents 1, 3, 5, 7, 9) and \\(Y_i(1)\\) for control respondents (respondents 2, 4, 6, 8, 10). Without these counterfactual outcomes, the true ATE cannot be calculated.\nPart c. The researcher computes the difference-in-means estimator:\n\\[\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\]\nThis is a reasonable substitute because:\n\nIt uses only observable quantities (no counterfactuals needed)\nUnder random assignment, it is unbiased for the true ATE\nThe average of \\(Y_i^{\\text{obs}}\\) among treated individuals estimates what the average of \\(Y_i(1)\\) would be for everyone\nThe average of \\(Y_i^{\\text{obs}}\\) among control individuals estimates what the average of \\(Y_i(0)\\) would be for everyone\n\nRandom assignment ensures that the treated and control groups are, on average, comparable samples from the same population. This allows us to use observed group means as stand-ins for the unobservable population means.\n\n\nInterpreting the Estimate in Context: Using the estimate from Exercise 8a (\\(\\widehat{\\text{ATE}} = -1.8\\)):\n\nWrite a one-sentence interpretation of this estimate in the context of Rasinski’s question-wording experiment. Be sure to explain what the negative sign means substantively.\nA colleague says, “A change of 1.8 points on a 3-point scale is huge!” Is this a fair characterization? What context would help evaluate the magnitude?\n\n\n\n\nSolution\n\nPart a. Based on this experiment, respondents gave answers that were on average 1.8 points lower on the 1-to-3 scale (where 1 = “Too little” and 3 = “Too much”) when asked about “assistance to the poor” compared to “welfare,” indicating that the “assistance to the poor” framing substantially increases expressed support for government spending.\nPart b. The colleague’s characterization captures the right intuition—this is a large effect—but deserves more context:\nWhat makes this effect large:\n\nThe outcome scale only has three categories (1, 2, 3), so the maximum possible effect is 2 points (from “Too much” to “Too little” or vice versa)\nAn effect of 1.8 points is 90% of the maximum possible effect\nMany respondents are shifting by a full category or more based solely on word choice\n\nContext that helps evaluation:\n\nThe treatment is minimal—just changing one phrase in a question. The fact that word choice alone produces such a large shift suggests question wording is extremely consequential for survey results.\nIf this effect generalizes to the broader population, it means public opinion polls could show dramatically different levels of support for the same policy depending on how the question is worded.\nIn political terms, this could mean the difference between a policy appearing popular or unpopular.\n\nSo yes, the effect is substantively large, and the colleague’s reaction is warranted. Changing two words shifts responses by nearly the full width of the scale.\n\n\n\n2.10.4 Critical Thinking\n\nUnbiasedness vs. Accuracy: An estimator can be unbiased but still give estimates that are far from the true value.\n\nHow is this possible? What determines how far individual estimates might be from the truth?\nWhat might make \\(\\widehat{\\text{ATE}}\\) more or less variable across different randomizations?\n\n\n\n\nSolution\n\nPart a. Unbiasedness only guarantees that the estimator is correct on average—it says nothing about any single estimate.\nAn unbiased estimator can produce estimates far from the truth because of sampling variability. Each randomization produces a different assignment of individuals to treatment and control. Some randomizations might, by chance, put individuals with unusually high potential outcomes into the treatment group, leading to overestimates. Other randomizations might do the opposite, leading to underestimates.\nThink of it like flipping a fair coin 10 times. On average, you get 5 heads. But any particular sequence might give you 3 heads, 7 heads, or even 0 heads. The “estimator” (count the heads) is unbiased, but individual realizations vary.\nWhat determines how far individual estimates might be from the truth:\n\nThe variance of the estimator—how spread out the distribution of possible estimates is\nThis variance depends on the sample size, the variability in potential outcomes, and the proportion assigned to treatment vs. control\n\nPart b. Several factors affect how variable \\(\\widehat{\\text{ATE}}\\) is across randomizations:\nFactors that increase variability:\n\nSmaller sample sizes (\\(N\\)): Fewer individuals means each randomization can produce more extreme group compositions\nMore heterogeneous potential outcomes: If individuals differ greatly in their outcomes, the groups can be quite different depending on which individuals land where\nUnbalanced designs: Having very few individuals in one group (e.g., \\(N_t = 2\\) out of \\(N = 100\\)) increases variability because the small group’s mean is very sensitive to which specific individuals are included\n\nFactors that decrease variability:\n\nLarger sample sizes: With many individuals, the law of large numbers kicks in—each group is more likely to be representative of the population\nMore homogeneous potential outcomes: If all individuals have similar outcomes, it matters less which ones end up in which group\nBalanced designs: Having roughly equal numbers in treatment and control (\\(N_t \\approx N_c\\)) tends to minimize variance\n\n\n\nBreaking Unbiasedness: The proof of unbiasedness relies on the fact that \\(E_D[D_i] = N_t/N\\) for all individuals \\(i\\).\n\nGive an example of an assignment mechanism where this would not hold.\nIf we used such a biased assignment mechanism, would \\(\\widehat{\\text{ATE}}\\) still be unbiased? Why or why not?\n\n\n\n\nSolution\n\nPart a. Here are examples of assignment mechanisms where \\(E_D[D_i] = N_t/N\\) would not hold for all individuals:\nExample 1: Selection based on a characteristic\nA researcher assigns older participants to treatment with probability 0.8 and younger participants with probability 0.2. If age is associated with the outcome, \\(E_D[D_i]\\) differs across individuals based on their age.\nExample 2: Self-selection\nParticipants choose whether to receive treatment. Motivated participants might be more likely to choose treatment (\\(E_D[D_i]\\) is higher for motivated people).\nExample 3: Researcher discretion\nA researcher “randomly” assigns treatment but subconsciously tends to assign sicker patients to the new treatment. Sicker patients have higher \\(E_D[D_i]\\).\nExample 4: Sequential assignment with learning\nA researcher stops assigning to treatment once they see a few bad outcomes, making later individuals less likely to be treated.\nPart b. No, \\(\\widehat{\\text{ATE}}\\) would generally not be unbiased under such mechanisms.\nThe proof of unbiasedness relied on a key cancellation: the probability of treatment (\\(E_D[D_i] = N_t/N\\)) canceled with the weighting in the estimator (dividing by \\(N_t\\)). This worked because every individual had the same probability of treatment.\nWhen treatment probabilities vary across individuals, this cancellation breaks down. Individuals with higher probabilities of treatment contribute more to the treatment group mean, and individuals with lower probabilities contribute less. If these probabilities are correlated with potential outcomes, the estimator becomes biased.\nFor example, if high-outcome individuals have higher treatment probabilities:\n\nThe treatment group will be enriched with high-outcome individuals\nThe control group will be enriched with low-outcome individuals\n\\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\) will overestimate the true ATE\n\nThe estimator would be capturing both the treatment effect and the selection effect, leading to bias.\n\n\nSample Size Considerations: Consider two experiments estimating the same ATE. Experiment A has \\(N = 10\\) with \\(N_t = 5\\). Experiment B has \\(N = 1000\\) with \\(N_t = 500\\).\n\nAre both estimates unbiased for the ATE?\nIn which experiment would you expect \\(\\widehat{\\text{ATE}}\\) to be closer to the true ATE? Why?\nWhat property of estimators (besides unbiasedness) captures this difference?\n\n\n\n\nSolution\n\nPart a. Yes, both estimates are unbiased for the ATE.\nUnbiasedness depends only on the randomization procedure, not on the sample size. As long as treatment is randomly assigned (with each individual having equal probability), the estimator is unbiased. This is true whether \\(N = 10\\) or \\(N = 1,000,000\\).\nThe proof of unbiasedness holds for any \\(N &gt; 1\\) with \\(1 &lt; N_t &lt; N\\).\nPart b. We would expect \\(\\widehat{\\text{ATE}}\\) from Experiment B (the larger experiment) to be closer to the true ATE.\nWith only 10 individuals, random chance can produce quite unrepresentative groups. Maybe by luck, 4 of the 5 highest-outcome individuals all end up in treatment, producing a large overestimate. With 1000 individuals, such extreme imbalances are far less likely. The law of large numbers ensures that with more individuals, each group’s mean converges toward the population mean of that potential outcome.\nTo use a simple analogy: if you flip a coin 10 times, getting 8 heads (80%) wouldn’t be surprising. If you flip it 1000 times, getting 800 heads (80%) would be extremely unlikely. Larger samples are more stable.\nPart c. The property that captures this difference is the variance (or equivalently, the standard error) of the estimator.\nBoth estimators are unbiased, but the estimator from the larger experiment has smaller variance—its sampling distribution is more concentrated around the true ATE. We often describe this by saying the larger experiment is more precise or has more efficiency.\nRelated concepts include:\n\nStandard error: The standard deviation of the sampling distribution of \\(\\widehat{\\text{ATE}}\\)\nEfficiency: An estimator with smaller variance is more efficient\nConsistency: As \\(N \\to \\infty\\), the estimator converges to the true value (related to variance shrinking to zero)\n\n\n\n\n2.10.5 R Practice\n\nComputing \\(\\widehat{\\text{ATE}}\\) with mean(): Suppose you have a data frame called experiment with columns treatment (1 = treated, 0 = control) and outcome (a numeric outcome variable).\n\nWrite R code to compute \\(\\overline{Y}^{\\text{obs}}_{t}\\) using logical indexing.\nWrite R code to compute \\(\\overline{Y}^{\\text{obs}}_{c}\\) using logical indexing.\nWrite R code to compute \\(\\widehat{\\text{ATE}}\\) as the difference.\n\n\n\n\nSolution\n\nPart a. To compute \\(\\overline{Y}^{\\text{obs}}_{t}\\), the mean outcome among treated individuals:\nmean_treated &lt;- mean(experiment$outcome[experiment$treatment == 1])\nThis works by:\n\nexperiment$treatment == 1 creates a logical vector that is TRUE for treated individuals\nexperiment$outcome[...] subsets the outcome variable to only those rows\nmean(...) computes the average of the subsetted outcomes\n\nPart b. To compute \\(\\overline{Y}^{\\text{obs}}_{c}\\), the mean outcome among control individuals:\nmean_control &lt;- mean(experiment$outcome[experiment$treatment == 0])\nThe logic is identical, but we select rows where treatment == 0.\nPart c. To compute \\(\\widehat{\\text{ATE}}\\) as the difference:\nate_hat &lt;- mean_treated - mean_control\nOr as a single line without intermediate variables:\nate_hat &lt;- mean(experiment$outcome[experiment$treatment == 1]) -\n           mean(experiment$outcome[experiment$treatment == 0])\n\n\nUnderstanding lm() Output: A researcher fits the model lm(outcome ~ treatment, data = experiment) and gets the following output:\n(Intercept)    treatment\n      4.200        1.350\n\nWhat is the mean outcome in the control group?\nWhat is \\(\\widehat{\\text{ATE}}\\)?\nWhat is the mean outcome in the treatment group?\n\n\n\n\nSolution\n\nPart a. The mean outcome in the control group is 4.200.\nThe intercept represents the predicted outcome when treatment = 0. Since the treatment variable is binary (0 or 1), plugging in 0 gives:\n\\[\\hat{Y} = 4.200 + 1.350 \\times 0 = 4.200\\]\nThis is \\(\\overline{Y}^{\\text{obs}}_{c}\\).\nPart b. The \\(\\widehat{\\text{ATE}}\\) is 1.350.\nThe coefficient on treatment represents how much the predicted outcome changes when treatment goes from 0 to 1. This is exactly the difference in means:\n\\[\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c} = 1.350\\]\nPart c. The mean outcome in the treatment group is 5.550.\nThis is the predicted outcome when treatment = 1:\n\\[\\hat{Y} = 4.200 + 1.350 \\times 1 = 5.550\\]\nThis equals \\(\\overline{Y}^{\\text{obs}}_{c} + \\widehat{\\text{ATE}} = 4.200 + 1.350 = 5.550\\).\nWe can verify: \\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c} = 5.550 - 4.200 = 1.350\\), which matches the coefficient.\n\n\nReference Categories: Explain why we used fct_relevel(desc, \"welfare\") in the R code for the mock Rasinski data. What would happen if we had not done this? Would the \\(\\widehat{\\text{ATE}}\\) computed using mean() and lm() still match?\n\n\n\nSolution\n\nWe used fct_relevel(desc, \"welfare\") to set “welfare” as the reference category for the factor variable.\nWhy this matters for lm():\nWhen lm() encounters a factor variable, it creates dummy (indicator) variables. R uses the first level of the factor as the reference category—the category that gets coded as 0. By default, R orders factor levels alphabetically. Since “assistance to the poor” comes before “welfare” alphabetically, it would be the reference category by default.\nWith “assistance to the poor” as reference:\n\nThe intercept would be the mean for “assistance to the poor” (the treatment group)\nThe coefficient would be the change when moving to “welfare” (the control group)\nThe coefficient would be \\(\\overline{Y}^{\\text{obs}}_{c} - \\overline{Y}^{\\text{obs}}_{t}\\), which is the negative of our usual definition\n\nBy using fct_relevel(desc, \"welfare\"), we make “welfare” the reference:\n\nThe intercept is the mean for “welfare” (control group)\nThe coefficient is the change when moving to “assistance to the poor” (treatment)\nThe coefficient equals \\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\), matching our definition\n\nWould mean() and lm() still match?\nThe magnitudes would still match, but the signs might differ depending on how we set up the calculation:\n\nIf we compute mean() as treatment minus control and lm() uses the alphabetical default, the coefficient would have the opposite sign of our mean() calculation\nThe numerical values would still be correct in absolute value\n\nIn practice, for the two approaches to give the same number (not just the same magnitude), we need to ensure the reference category in lm() matches which group we subtract in the mean() calculation.\n\n\nConnecting mean() and lm(): In your own words, explain why regressing the outcome on a binary treatment indicator produces a coefficient that equals the difference in means. What role does the intercept play in this relationship?\n\n\n\nSolution\n\nWhen we regress outcome on a binary treatment indicator, OLS (ordinary least squares) finds the coefficients that minimize the sum of squared residuals—the differences between observed outcomes and predicted outcomes.\nThe key insight:\nFor a binary predictor, the predictions can only take two values:\n\nWhen \\(D_i = 0\\): \\(\\hat{Y}_i = \\hat{\\beta}_0\\)\nWhen \\(D_i = 1\\): \\(\\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1\\)\n\nOLS chooses \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) to make predicted values as close as possible to observed values. The best prediction for a group of observations is their mean (this minimizes squared errors within that group).\nTherefore:\n\n\\(\\hat{\\beta}_0\\) is set to the mean outcome in the control group, because that’s the best prediction for control individuals\n\\(\\hat{\\beta}_0 + \\hat{\\beta}_1\\) is set to the mean outcome in the treatment group, because that’s the best prediction for treated individuals\n\nSolving for the coefficient:\n\\[\\hat{\\beta}_0 = \\overline{Y}^{\\text{obs}}_{c}\\] \\[\\hat{\\beta}_0 + \\hat{\\beta}_1 = \\overline{Y}^{\\text{obs}}_{t}\\]\nSubtracting the first equation from the second:\n\\[\\hat{\\beta}_1 = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\]\nThis is exactly the difference in means—our \\(\\widehat{\\text{ATE}}\\).\nThe role of the intercept:\nThe intercept (\\(\\hat{\\beta}_0\\)) serves as the “baseline”—the predicted outcome for the reference group (control). It anchors the predictions. The coefficient (\\(\\hat{\\beta}_1\\)) then represents how much we add or subtract from this baseline when an individual is treated. This additive structure means the coefficient must equal the difference between the two group means.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  }
]