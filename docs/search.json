[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Logic of Experiments",
    "section": "",
    "text": "Introduction\nThese are notes on the logic of experiments.\nUnderstanding the logic of experiments helps one clearly understand:\n\nwhy randomization is powerful and\nwhat randomization does and does not get you.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "ch/ate.html",
    "href": "ch/ate.html",
    "title": "1  ATE",
    "section": "",
    "text": "1.1 Potential Outcomes\nIn this chapter, we define the average treatment effect or the ATE. This is the key quantity of interest that we want to estimate with an experiment. But to define (and understand) the ATE, we need to define several preliminary concepts.\nThe fundamental problem of causal inference is that we can never observe what would have happened to the same individual if we had instead assigned them to a different condition. We can observe the outcome under—at most—one condition.\nTo formalize this, we use the potential outcomes framework.\nFor each individual \\(i\\) in our study, we define two potential outcomes:\nThese are called “potential” outcomes because we can observe no more than one of them for any given individual. If individual \\(i\\) receives treatment, we observe \\(Y_i(1)\\) but not \\(Y_i(0)\\). If individual \\(i\\) is in control, we observe \\(Y_i(0)\\) but not \\(Y_i(1)\\).\nThe unobserved potential outcome for each individual is called the counterfactual. The counterfactual represents what would have happened in the hypothetical scenario in which the individual was assigned to a different condition.\nTo make this concrete, consider a hypothetical experiment with 10 respondents. The table below shows both potential outcomes for each respondent—something we could never actually observe in reality, but which helps us understand the framework:\nImportantly, though, we cannot observe both potential outcomes. But for now, let’s ignore that difficulty.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#potential-outcomes",
    "href": "ch/ate.html#potential-outcomes",
    "title": "1  ATE",
    "section": "",
    "text": "\\(Y_i(1)\\): the outcome individual \\(i\\) would experience if assigned to treatment (\\(D_i = 1\\))\n\\(Y_i(0)\\): the outcome individual \\(i\\) would experience if assigned to control (\\(D_i = 0\\))\n\n\n\n\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n4\n7\n\n\n2\n6\n5\n\n\n3\n5\n5\n\n\n4\n3\n9\n\n\n5\n7\n10\n\n\n6\n5\n4\n\n\n7\n4\n8\n\n\n8\n6\n7\n\n\n9\n5\n3\n\n\n10\n4\n6",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#the-individual-level-treatment-effect",
    "href": "ch/ate.html#the-individual-level-treatment-effect",
    "title": "1  ATE",
    "section": "1.2 The Individual-Level Treatment Effect",
    "text": "1.2 The Individual-Level Treatment Effect\nOnce we have defined potential outcomes, we can define the individual-level treatment effect for individual \\(i\\) as \\(\\tau_i = Y_i(1) - Y_i(0)\\).\nThis represents the causal effect of treatment for that specific individual. It’s simply the difference between what would happen if they were assigned to treatment versus what would happen if they were assigned to control.\nIf we knew all the potential outcomes, then we could compute the individual-level treatment effect for each respondent.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n4\n7\n7 - 4 = 3\n\n\n2\n6\n5\n5 - 6 = -1\n\n\n3\n5\n5\n5 - 5 = 0\n\n\n4\n3\n9\n9 - 3 = 6\n\n\n5\n7\n10\n10 - 7 = 3\n\n\n6\n5\n4\n4 - 5 = -1\n\n\n7\n4\n8\n8 - 4 = 4\n\n\n8\n6\n7\n7 - 6 = 1\n\n\n9\n5\n3\n3 - 5 = -2\n\n\n10\n4\n6\n6 - 4 = 2\n\n\n\nAgain, there’s a fundamental problem: we can never observe \\(\\tau_i\\) directly because we never observe both potential outcomes for the same individual. This is sometimes called the fundamental problem of causal inference. We observe either \\(Y_i(1)\\) or \\(Y_i(0)\\), but never both. But again, let’s continue to ignore this pesky problem.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#the-average-treatment-effect",
    "href": "ch/ate.html#the-average-treatment-effect",
    "title": "1  ATE",
    "section": "1.3 The Average Treatment Effect",
    "text": "1.3 The Average Treatment Effect\nWe already know that we cannot observe the individual-level treatment effects. So instead, let’s cleverly sidestep the problem. Let’s define the average treatment effect or ATE, defined as\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} [Y_i(1) - Y_i(0)] \\\\\n&= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\text{avg} \\left( Y_i(1) \\right) - \\text{avg} \\left( Y_i(0) \\right) \\\\\n&= \\text{avg. of ALL p.o. under treatment } - \\text{avg. of ALL p.o. under control}\n\\end{align}\n\\]\nThe ATE represents the average causal effect of treatment across all individuals in the population. It tells us: on average, how much does treatment change outcomes?\nHere’s another way to think about. Suppose we assigned everyone to treatment and computed the average outcome. Suppose we also assigned everyone to control and computed the average outcome. (We can’t assign everyone to treatment and everyone to control, but suppose we could). The ATE is the difference between this two average.\nAgain, we cannot observe the ATE, but it turns out that this quantity can be estimated. In later sections, we’ll show how we can use randomized experiments to estimate the ATE. But for now, let’s focus on the meaning of the concept.\nTo make this concrete, we can compute the ATE for the potential outcomes above.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n4\n7\n\n\n2\n6\n5\n\n\n3\n5\n5\n\n\n4\n3\n9\n\n\n5\n7\n10\n\n\n6\n5\n4\n\n\n7\n4\n8\n\n\n8\n6\n7\n\n\n9\n5\n3\n\n\n10\n4\n6\n\n\n\nUsing this table, we can compute the ATE by finding the average of all potential outcomes under control and the average of all potential outcomes under treatment:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\frac{1}{10}(7 + 5 + 5 + 9 + 10 + 4 + 8 + 7 + 3 + 6) - \\frac{1}{10}(4 + 6 + 5 + 3 + 7 + 5 + 4 + 6 + 5 + 4) \\\\\n&= \\frac{64}{10} - \\frac{49}{10} \\\\\n&= 6.4 - 4.9 \\\\\n&= 1.5\n\\end{align}\n\\] The ATE is 1.5, meaning that on average, treatment increases outcomes by 1.5 units. (We could average the \\(\\tau_i\\) in the table above to obtain the identical value.)\n\n\n\n\n\n\nTip\n\n\n\nWhen we write about the “average treatment effect,” it should be understood as something very specific. It should be understood as the difference between two quantities: the hypothetical difference between (1) the average value of the outcome if we assigned everyone to treatment and (2) the average value of the outcome if we assigned everyone to control.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#special-cases",
    "href": "ch/ate.html#special-cases",
    "title": "1  ATE",
    "section": "1.4 Special Cases",
    "text": "1.4 Special Cases\n\n1.4.1 The Sharp Null Hypothesis\nThe sharp null hypothesis is a particularly strong claim about individual treatment effects. The sharp null hypothesis states that\n\\[\\text{sharp null hypothesis}: Y_i(1) = Y_i(0) \\text{ for all } i.\\]\nThis hypothesis states that treatment has exactly zero effect for every single individual in the study. That is, for each individual in the experiment, the outcome is identical regardless of whether it is assigned to treatment or control. Under the sharp null, the treatment effect \\(\\tau_i = 0\\) for all \\(i\\).\nThis hypothesis is helpful because it completely specifies all potential outcomes. If we assume the sharp null hypothesis holds, then we can compute the counterfactual outcome from the observed outcome.\n\nSuppose we observe \\(Y_i(0)\\) for a control individual, we know that \\(Y_i(1) = Y_i(0)\\).\nSimilarly, suppose we observe \\(Y_i(1)\\) for a treated individual, we know that \\(Y_i(0) = Y_i(1)\\).\n\nWhile we never know whether the sharp null hypothesis holds—and it seems implausible that it ever would hold—it can sometimes be convenient to check what would happen if it did hold.\nThe table below shows a set of potential outcomes where the sharp null holds.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n4\n4\n4 - 4 = 0\n\n\n2\n6\n6\n6 - 6 = 0\n\n\n3\n5\n5\n5 - 5 = 0\n\n\n4\n3\n3\n3 - 3 = 0\n\n\n5\n7\n7\n7 - 7 = 0\n\n\n6\n5\n5\n5 - 5 = 0\n\n\n7\n4\n4\n4 - 4 = 0\n\n\n8\n6\n6\n6 - 6 = 0\n\n\n9\n5\n5\n5 - 5 = 0\n\n\n10\n4\n4\n4 - 4 = 0\n\n\n\nUnder the sharp null hypothesis, \\(Y_i(1) = Y_i(0)\\) for all individuals \\(i\\), which means \\(\\tau_i = 0\\) for all individuals. We can verify this by computing the ATE:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\frac{1}{10}(4 + 6 + 5 + 3 + 7 + 5 + 4 + 6 + 5 + 4) - \\frac{1}{10}(4 + 6 + 5 + 3 + 7 + 5 + 4 + 6 + 5 + 4) \\\\\n&= \\frac{49}{10} - \\frac{49}{10} \\\\\n&= 4.9 - 4.9 \\\\\n&= 0\n\\end{align}\n\\]\nThe ATE is exactly 0. This follows from the fact that all of the individual-level effects are exactly zero as well.\n\n\n1.4.2 Constant Treatment Effects\nAnother implausible but sometimes-helpful hypothesis is the constant treatment effects assumption that\n\\[\\tau_i = \\tau \\text{ for all individuals } i\\]\nThis assumes that while the individual-level treatment effect may be different from zero, that effect is exactly the same for every individual so that \\[Y_i(1) - Y_i(0) = \\tau \\text{ for all } i\\]. Here, \\(\\tau\\) is a fixed number like 2 or -4.2 that is the same for all the individuals.\nAs before, we never know whether individual-level treatment effects are constant—and it seems implausible they ever would be. But it can sometimes be convenient to check what would happen if they were constant.\nSimilar to the sharp null hypothesis, the constant effects hypothesis is helpful because it completely specifies all potential outcomes. It allows us to compute the counterfactual outcome from the observed outcome.\n\nSuppose we observe \\(Y_i(0)\\) for a control individual, we know that \\(Y_i(1)\\) is 2 points larger than that so that \\(Y_i(1) = Y_i(0) + 2\\).\nSimilarly, suppose we observe \\(Y_i(1)\\) for a treated individual, we know that \\(Y_i(0)\\) is 2 points less than that so that \\(Y_i(0) = Y_i(1) - 2\\).\n\nThe table below shows a set of potential outcomes where treatment effects are constant at \\(\\tau = 2\\) for all individuals.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n4\n6\n6 - 4 = 2\n\n\n2\n6\n8\n8 - 6 = 2\n\n\n3\n5\n7\n7 - 5 = 2\n\n\n4\n3\n5\n5 - 3 = 2\n\n\n5\n7\n9\n9 - 7 = 2\n\n\n6\n5\n7\n7 - 5 = 2\n\n\n7\n4\n6\n6 - 4 = 2\n\n\n8\n6\n8\n8 - 6 = 2\n\n\n9\n5\n7\n7 - 5 = 2\n\n\n10\n4\n6\n6 - 4 = 2\n\n\n\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\frac{1}{10}(6 + 8 + 7 + 5 + 9 + 7 + 6 + 8 + 7 + 6) - \\frac{1}{10}(4 + 6 + 5 + 3 + 7 + 5 + 4 + 6 + 5 + 4) \\\\\n&= \\frac{69}{10} - \\frac{49}{10} \\\\\n&= 6.9 - 4.9 \\\\\n&= 2\n\\end{align}\n\\]\nThe ATE is exactly 2. This follows from the fact that all of the individual-level effects are exactly 2 as well. When treatment effects are constant, the ATE perfectly captures the treatment effect for every individual.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#rasinskis-question-wording-experiment",
    "href": "ch/ate.html#rasinskis-question-wording-experiment",
    "title": "1  ATE",
    "section": "1.5 Rasinski’s Question-Wording Experiment",
    "text": "1.5 Rasinski’s Question-Wording Experiment\nIn a famous survey experiment, Rasinski (1989) was curious about how question wording affects public support for government spending.1\n\nRasinski, Kenneth A. 1989. “The Effect of Question Wording on Public Support for Government Spending.” Public Opinion Quarterly 53 (3): 388–94.\n1 Respondents were randomly assigned to one of two conditions that asked about spending on programs for low-income individuals, but used different labels to describe these programs. The experiment was conducted across three years (1984, 1985, and 1986) and consistently found that far more respondents said the government was spending “too little” when the program was described as “assistance to the poor” (around 63-65%) compared to when it was described as “welfare” (around 20-25%). This represents a dramatic difference of approximately 40 percentage points due solely to the choice of label used to describe the same underlying government program.Respondents could be assigned to one of two conditions: treatment or control. The two conditions featured an identical question stem, but varied in how they describe the spending.\nQuestion stem (identical for both conditions): “Are we spending too much, too little, or about the right amount on…”\nTreatment condition: “…assistance to the poor?”\nControl condition: “…welfare?”\nResponse options:\n\nToo little = 1\nAbout right = 2\nToo much = 3\n\nThus each respondent had two potential outcomes:\n\n\\(Y_i(1)\\): the response respondent \\(i\\) would give if assigned to the treatment condition (“assistance to the poor”)\n\\(Y_i(0)\\): the response respondent \\(i\\) would give if assigned to the control condition (“welfare”)\n\nAs before, we can never observe both potential outcomes for the same respondent. We can observe their response if the program is described as “assistance to the poor” or as “welfare”, but not both.\n\n1.5.1 Hypothetical Potential Outcomes\nTo illustrate the concepts, suppose we could magically observe both potential outcomes for a sample of 10 respondents. The table below shows what each respondent would answer under each condition:\n\n\n\n\n\n\n\n\n\nRespondent\n\\(Y_i(0)\\) (“welfare”)\n\\(Y_i(1)\\) (“assistance”)\n\\(\\tau_i\\)\n\n\n\n\n1\n3 (Too much)\n1 (Too little)\n1 - 3 = -2\n\n\n2\n3 (Too much)\n2 (About right)\n2 - 3 = -1\n\n\n3\n2 (About right)\n1 (Too little)\n1 - 2 = -1\n\n\n4\n3 (Too much)\n1 (Too little)\n1 - 3 = -2\n\n\n5\n2 (About right)\n1 (Too little)\n1 - 2 = -1\n\n\n6\n3 (Too much)\n2 (About right)\n2 - 3 = -1\n\n\n7\n2 (About right)\n1 (Too little)\n1 - 2 = -1\n\n\n8\n3 (Too much)\n1 (Too little)\n1 - 3 = -2\n\n\n9\n2 (About right)\n2 (About right)\n2 - 2 = 0\n\n\n10\n3 (Too much)\n1 (Too little)\n1 - 3 = -2\n\n\n\nNotice that for most respondents, the treatment effect \\(\\tau_i\\) is negative. This means that asking about “assistance to the poor” produces lower numeric responses than asking about “welfare.” In this case, lower numbers indicate more support for spending (“too little” = 1), these negative treatment effects actually represent increased support for spending when using the “assistance to the poor” wording.\n\n\n1.5.2 Computing the ATE\nWe can compute the ATE for this hypothetical data:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) \\\\\n&= \\frac{1}{10}(1 + 2 + 1 + 1 + 1 + 2 + 1 + 1 + 2 + 1) - \\frac{1}{10}(3 + 3 + 2 + 3 + 2 + 3 + 2 + 3 + 2 + 3) \\\\\n&= \\frac{13}{10} - \\frac{26}{10} \\\\\n&= 1.3 - 2.6 \\\\\n&= -1.3\n\\end{align}\n\\]\nThe ATE is -1.3. Since lower values on our 1-2-3 scale indicate more support for spending, this negative ATE means that the “assistance to the poor” wording increases support for spending by an average of 1.3 scale points compared to the “welfare” wording.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#key-terms",
    "href": "ch/ate.html#key-terms",
    "title": "1  ATE",
    "section": "1.6 Key Terms",
    "text": "1.6 Key Terms\n\nPotential outcomes\nPotential outcomes framework\nCounterfactual\nIndividual-level treatment effect\nFundamental problem of causal inference\nAverage treatment effect (ATE)\nSharp null hypothesis\nConstant treatment effects",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate.html#exercises",
    "href": "ch/ate.html#exercises",
    "title": "1  ATE",
    "section": "1.7 Exercises",
    "text": "1.7 Exercises\n\n1.7.1 Conceptual Understanding\n\nDefining Potential Outcomes. In your own words, explain what \\(Y_i(1)\\) and \\(Y_i(0)\\) represent in the context of Rasinski’s question-wording experiment. Why can we never observe both potential outcomes for the same respondent?\n\n\n\nSolution\n\nIn Rasinski’s question-wording experiment, each respondent has two potential outcomes:\n\n\\(Y_i(1)\\) is the response that respondent \\(i\\) would give if asked about spending on “assistance to the poor.” This is the potential outcome under the treatment condition.\n\\(Y_i(0)\\) is the response that respondent \\(i\\) would give if asked about spending on “welfare.” This is the potential outcome under the control condition.\n\nWe can never observe both potential outcomes for the same respondent because each respondent can only answer one version of the question. Once respondent \\(i\\) sees the question with “welfare” and gives their answer, we cannot rewind time and show them the “assistance to the poor” version as if they had never seen the first one. At most, we observe one potential outcome per respondent—either \\(Y_i(1)\\) or \\(Y_i(0)\\), but never both.\nThis is the fundamental problem of causal inference.\n\n\nThe Fundamental Problem. Explain why we call it the “fundamental problem of causal inference.” What makes this problem “fundamental” rather than just “difficult”?\n\n\n\nSolution\n\nWe call it the “fundamental” problem of causal inference—rather than just a “difficult” problem—because it cannot be solved, even in principle.\nA “difficult” problem is one we might overcome with better technology, more data, or cleverer methods. The fundamental problem is different: it is a logical impossibility. At any given moment, an individual either receives treatment or does not. We cannot observe the same person in two different states of the world at the same time. No amount of resources or ingenuity can change this fact.\nThis is why we need research designs—like randomized experiments—that allow us to estimate causal effects at the group level, even though we can never directly observe individual-level causal effects.\n\n\nATE Interpretation. A researcher finds an ATE of 3.2 in an experiment testing the effect of a new study technique on exam scores (measured 0-100). Write two sentences explaining what this means in plain language that a non-statistician could understand.\n\n\n\nSolution\n\nAn ATE of 3.2 means that, on average, students who use the new study technique score about 3.2 points higher on the exam compared to what they would have scored without using the technique.\nAnother way to say this: if we could magically give the study technique to all students and then also observe what would have happened if none of them used it, the average difference between these two scenarios would be 3.2 points.\n\n\nSharp Null vs. Zero ATE. Is it possible to have an ATE of zero even when the sharp null hypothesis does not hold? Explain your answer and provide an example using a simple table of potential outcomes for 4 individuals.\n\n\n\nSolution\n\nYes, it is possible to have an ATE of zero even when the sharp null hypothesis does not hold.\nThe sharp null hypothesis is a strong claim: it requires that \\(\\tau_i = 0\\) for every single individual. That is, \\(Y_i(1) = Y_i(0)\\) for all \\(i\\).\nThe ATE, on the other hand, is just the average of the individual treatment effects:\n\\[\\text{ATE} = \\frac{1}{N} \\sum_{i=1}^{N} \\tau_i\\]\nIf some individuals have positive treatment effects and others have negative treatment effects, these can cancel out, producing an ATE of zero even though the treatment affected every individual.\nHere is a concrete example with 4 individuals:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i = Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n5\n8\n\\(8 - 5 = 3\\)\n\n\n2\n7\n4\n\\(4 - 7 = -3\\)\n\n\n3\n6\n8\n\\(8 - 6 = 2\\)\n\n\n4\n8\n6\n\\(6 - 8 = -2\\)\n\n\n\nComputing the ATE:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{4} \\sum_{i=1}^{4} \\tau_i \\\\\n&= \\frac{1}{4}(3 + (-3) + 2 + (-2)) \\\\\n&= \\frac{0}{4} \\\\\n&= 0\n\\end{align}\n\\]\nThe ATE equals zero, but the sharp null does not hold. The treatment affected every single individual—individuals 1 and 3 experienced positive effects of 3 and 2, while individuals 2 and 4 experienced negative effects of -3 and -2. The effects simply cancel out when we average them.\n\n\n\n1.7.2 Computational Practice\n\nComputing Individual Treatment Effects. Consider the following potential outcomes for 6 respondents in a hypothetical experiment:\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n5\n8\n\n\n2\n7\n6\n\n\n3\n4\n7\n\n\n4\n6\n9\n\n\n5\n5\n5\n\n\n6\n8\n7\n\n\n\n\nCalculate the individual-level treatment effect (\\(\\tau_i\\)) for each respondent.\nCalculate the ATE.\nWhich respondents experienced a positive treatment effect? A negative treatment effect? No treatment effect?\n\n\n\n\nSolution\n\nPart a. To find each individual treatment effect, we compute \\(\\tau_i = Y_i(1) - Y_i(0)\\):\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i = Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n5\n8\n\\(8 - 5 = 3\\)\n\n\n2\n7\n6\n\\(6 - 7 = -1\\)\n\n\n3\n4\n7\n\\(7 - 4 = 3\\)\n\n\n4\n6\n9\n\\(9 - 6 = 3\\)\n\n\n5\n5\n5\n\\(5 - 5 = 0\\)\n\n\n6\n8\n7\n\\(7 - 8 = -1\\)\n\n\n\nPart b. We can compute the ATE by averaging the individual treatment effects:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{6} \\sum_{i=1}^{6} \\tau_i \\\\\n&= \\frac{1}{6}(3 + (-1) + 3 + 3 + 0 + (-1)) \\\\\n&= \\frac{7}{6} \\\\\n&\\approx 1.167\n\\end{align}\n\\]\nWe can verify this by computing the ATE as the difference between the average potential outcome under treatment and the average potential outcome under control:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{6}\\sum_{i=1}^{6} Y_i(1) - \\frac{1}{6}\\sum_{i=1}^{6} Y_i(0) \\\\\n&= \\frac{1}{6}(8 + 6 + 7 + 9 + 5 + 7) - \\frac{1}{6}(5 + 7 + 4 + 6 + 5 + 8) \\\\\n&= \\frac{42}{6} - \\frac{35}{6} \\\\\n&= 7 - 5.833 \\\\\n&\\approx 1.167\n\\end{align}\n\\]\nBoth methods give the same answer.\nPart c. Classifying the treatment effects:\n\nPositive treatment effect (\\(\\tau_i &gt; 0\\)): Respondents 1, 3, and 4 (with effects of 3, 3, and 3)\nNegative treatment effect (\\(\\tau_i &lt; 0\\)): Respondents 2 and 6 (with effects of -1 and -1)\nNo treatment effect (\\(\\tau_i = 0\\)): Respondent 5\n\n\n\nVerifying the Sharp Null. Consider the following potential outcomes:\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n12\n12\n\n\n2\n8\n8\n\n\n3\n15\n15\n\n\n4\n10\n10\n\n\n\n\nDoes this satisfy the sharp null hypothesis? How do you know?\nCalculate the ATE.\nUnder the sharp null hypothesis, what can you always say about the ATE?\n\n\n\n\nSolution\n\nPart a. Yes, this satisfies the sharp null hypothesis.\nThe sharp null hypothesis requires that \\(Y_i(1) = Y_i(0)\\) for all individuals. We can check each respondent:\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(Y_i(1) = Y_i(0)\\)?\n\n\n\n\n1\n12\n12\nYes\n\n\n2\n8\n8\nYes\n\n\n3\n15\n15\nYes\n\n\n4\n10\n10\nYes\n\n\n\nFor every individual, the potential outcome under treatment equals the potential outcome under control. The sharp null hypothesis holds.\nPart b. Computing the ATE:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{4}\\sum_{i=1}^{4} Y_i(1) - \\frac{1}{4}\\sum_{i=1}^{4} Y_i(0) \\\\\n&= \\frac{1}{4}(12 + 8 + 15 + 10) - \\frac{1}{4}(12 + 8 + 15 + 10) \\\\\n&= \\frac{45}{4} - \\frac{45}{4} \\\\\n&= 11.25 - 11.25 \\\\\n&= 0\n\\end{align}\n\\]\nPart c. Under the sharp null hypothesis, the ATE is always exactly zero.\nThis follows directly from the definitions. If \\(Y_i(1) = Y_i(0)\\) for all \\(i\\), then:\n\\[\\tau_i = Y_i(1) - Y_i(0) = 0 \\text{ for all } i\\]\nThe ATE is the average of the individual treatment effects:\n\\[\\text{ATE} = \\frac{1}{N} \\sum_{i=1}^{N} \\tau_i = \\frac{1}{N} \\sum_{i=1}^{N} 0 = 0\\]\nThe average of zeros is always zero.\n\n\nConstant Treatment Effects. Create a table of potential outcomes for 5 individuals where the constant treatment effects assumption holds with \\(\\tau = -2.5\\) for all individuals. Show that the ATE equals -2.5.\n\n\n\nSolution\n\nThe constant treatment effects assumption requires that \\(\\tau_i = \\tau\\) for all individuals. With \\(\\tau = -2.5\\), we need \\(Y_i(1) - Y_i(0) = -2.5\\) for every individual.\nWe can choose any values for \\(Y_i(0)\\) and then compute \\(Y_i(1) = Y_i(0) + (-2.5) = Y_i(0) - 2.5\\):\n\n\n\n\n\n\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1) = Y_i(0) - 2.5\\)\n\\(\\tau_i = Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n10\n7.5\n\\(7.5 - 10 = -2.5\\)\n\n\n2\n8\n5.5\n\\(5.5 - 8 = -2.5\\)\n\n\n3\n12\n9.5\n\\(9.5 - 12 = -2.5\\)\n\n\n4\n6\n3.5\n\\(3.5 - 6 = -2.5\\)\n\n\n5\n9\n6.5\n\\(6.5 - 9 = -2.5\\)\n\n\n\nNow we verify that the ATE equals -2.5:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{5}\\sum_{i=1}^{5} Y_i(1) - \\frac{1}{5}\\sum_{i=1}^{5} Y_i(0) \\\\\n&= \\frac{1}{5}(7.5 + 5.5 + 9.5 + 3.5 + 6.5) - \\frac{1}{5}(10 + 8 + 12 + 6 + 9) \\\\\n&= \\frac{32.5}{5} - \\frac{45}{5} \\\\\n&= 6.5 - 9 \\\\\n&= -2.5\n\\end{align}\n\\]\nWhen treatment effects are constant at \\(\\tau\\) for all individuals, the ATE equals \\(\\tau\\). This makes sense: the ATE is the average of the individual treatment effects, and the average of a constant is just that constant.\n\n\n\n1.7.3 Application to Rasinski’s Experiment\n\nUnderstanding the Conditions.\n\nIn Rasinski’s experiment, what exactly differs between the treatment and control conditions? What stays the same?\nWhy might the word “welfare” produce different responses than “assistance to the poor” even though both refer to the same government programs?\n\n\n\n\nSolution\n\nPart a.\nWhat differs between the conditions: Only the label used to describe the government programs. The treatment condition uses “assistance to the poor” while the control condition uses “welfare.”\nWhat stays the same: Everything else is identical:\n\nThe question stem: “Are we spending too much, too little, or about the right amount on…”\nThe response options: Too little, About right, Too much\nThe numeric coding: 1, 2, 3\nThe underlying concept being asked about (government spending on programs for low-income people)\n\nPart b. The words “welfare” and “assistance to the poor” may produce different responses because they carry different connotations, even though they refer to the same government programs.\n“Welfare” has acquired negative associations in American political discourse. It is often linked to stereotypes about dependency, fraud, or undeserving recipients. Many people have strong negative reactions to the word itself.\n“Assistance to the poor” is more neutral and descriptive. It focuses attention on the humanitarian purpose of helping people in need, without triggering the same negative associations.\nThese different framings can activate different considerations in respondents’ minds, leading them to express different levels of support even though the underlying programs are identical. This is exactly what Rasinski’s experiment was designed to detect.\n\n\nInterpreting Rasinski’s Results. In the hypothetical Rasinski data presented in the notes, the ATE was -1.3.\n\nExplain what this negative ATE means substantively. Does it indicate increased or decreased support for spending?\nWhy is the sign (positive or negative) of the ATE potentially confusing in this example?\nIf we had instead coded responses as: Too little = 3, About right = 2, Too much = 1, what would the ATE have been? Would your substantive interpretation change?\n\n\n\n\nSolution\n\nPart a. The ATE of -1.3 means that, on average, respondents gave responses that were 1.3 points lower on the 1-2-3 scale when asked about “assistance to the poor” compared to when asked about “welfare.”\nBut what does “lower” mean substantively? Recall the coding:\n\nToo little = 1 (more support for spending)\nAbout right = 2\nToo much = 3 (less support for spending)\n\nLower numbers indicate more support for spending. So a negative ATE indicates increased support for spending when using the “assistance to the poor” wording. The treatment (changing “welfare” to “assistance to the poor”) made people more supportive of government spending.\nPart b. The sign is potentially confusing because the coding scheme runs in the opposite direction from what we might intuitively expect. We often associate “positive” with “more” and “negative” with “less.” But here, a negative ATE means more support for spending.\nThis is an artifact of how the response options were numbered. The researcher could have coded the responses differently.\nPart c. If we reversed the coding:\n\nToo little = 3 (more support for spending)\nAbout right = 2\nToo much = 1 (less support for spending)\n\nThen each potential outcome would transform:\n\nOriginal values of 1 become 3\nOriginal values of 2 stay 2\nOriginal values of 3 become 1\n\nUsing the hypothetical data from the chapter, the new ATE would be:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{10}(3 + 2 + 3 + 3 + 3 + 2 + 3 + 3 + 2 + 3) - \\frac{1}{10}(1 + 1 + 2 + 1 + 2 + 1 + 2 + 1 + 2 + 1) \\\\\n&= \\frac{27}{10} - \\frac{14}{10} \\\\\n&= 2.7 - 1.4 \\\\\n&= +1.3\n\\end{align}\n\\]\nThe ATE becomes \\(+1.3\\) instead of \\(-1.3\\).\nThe substantive interpretation does not change: the “assistance to the poor” wording still increases support for spending compared to “welfare.” The sign of the ATE simply reflects our arbitrary choice of how to code the responses.\n\n\nRasinski’s Potential Outcomes. Consider respondent 9 in the hypothetical Rasinski data, who answered “About right” (2) under both conditions.\n\nWhat is this respondent’s individual treatment effect (\\(\\tau_9\\))?\nDoes this mean the question wording had no effect on this respondent? Explain.\nCan you construct an example with different potential outcomes where the treatment has a large effect for every individual, but the ATE is still zero?\n\n\n\n\nSolution\n\nPart a. Respondent 9 answered “About right” (coded as 2) under both conditions:\n\n\\(Y_9(1) = 2\\) (response if asked about “assistance to the poor”)\n\\(Y_9(0) = 2\\) (response if asked about “welfare”)\n\nThe individual treatment effect is:\n\\[\\tau_9 = Y_9(1) - Y_9(0) = 2 - 2 = 0\\]\nPart b. For this particular respondent, the question wording had no effect on their observed categorical response. They gave the same answer—“About right”—regardless of which version of the question they received.\nHowever, this does not necessarily mean the wording had no psychological effect whatsoever. It could be that:\n\nThe respondent holds consistent, moderate views on this issue that are not affected by framing\nThe two framings activated different considerations, but those considerations happened to produce the same response category\nThe respondent gave a default “middle” response without processing the question carefully\n\nAll we can conclude is that the treatment did not change this respondent’s response on this particular three-category scale.\nPart c. Yes. Here is an example where treatment has a large effect (\\(|\\tau_i| = 3\\)) for every individual, but the ATE is zero:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n2\n5\n\\(5 - 2 = 3\\)\n\n\n2\n6\n3\n\\(3 - 6 = -3\\)\n\n\n3\n4\n7\n\\(7 - 4 = 3\\)\n\n\n4\n8\n5\n\\(5 - 8 = -3\\)\n\n\n\nEvery individual experiences a treatment effect of either \\(+3\\) or \\(-3\\). The treatment clearly matters for each person. But the ATE is:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{4}(3 + (-3) + 3 + (-3)) \\\\\n&= \\frac{0}{4} \\\\\n&= 0\n\\end{align}\n\\]\nThe positive and negative effects cancel perfectly, producing an ATE of zero despite large individual effects.\n\n\n\n1.7.4 Critical Thinking\n\nBeyond the Average. In the original hypothetical example (with 10 respondents and ATE = 1.5), we saw that treatment effects varied across individuals, with some positive, some negative, and some zero.\n\nWhy might this variation in individual treatment effects matter for policy or practical decisions?\nWhat are the limitations of focusing only on the ATE when individual treatment effects vary substantially?\n\n\n\n\nSolution\n\nPart a. Variation in individual treatment effects matters for policy and practical decisions because:\nTargeting interventions: If treatment helps some people but harms others, we might want to identify who benefits and offer the treatment only to them. A positive ATE could mask the fact that a substantial group is being harmed.\nEquity concerns: Even if the average effect is positive, we might care about who benefits. If benefits are concentrated among people who are already well-off, while disadvantaged groups see little improvement, this raises fairness concerns that the ATE alone cannot reveal.\nIndividual decision-making: A person deciding whether to undergo a treatment cares about the effect on them, not the average effect across all people. If effects are highly variable, the ATE may be a poor guide for any particular individual.\nUnderstanding mechanisms: Variation in effects can help us understand why a treatment works. If effects are larger for certain subgroups, this may point to underlying mechanisms or suggest how to improve the treatment.\nPart b. The ATE has several limitations when individual treatment effects vary substantially:\n\nThe ATE can hide important heterogeneity. An ATE of zero could mean “the treatment has no effect on anyone” or “the treatment has large positive effects for half the population and large negative effects for the other half.” These are very different situations with very different policy implications.\nThe ATE does not tell us who benefits and who is harmed.\nThe ATE treats all individuals equally. But we might care more about effects on certain groups, such as those who are most disadvantaged or most at risk.\nThe ATE is a single summary number. Like any average, it can be misleading if the underlying distribution is skewed or bimodal.\nFor individual decision-making, knowing the ATE does not tell any specific person whether the treatment will help or harm them.\n\n\n\nAssumption Plausibility.\n\nFor what kinds of treatments or contexts—if any—might the constant treatment effects assumption be approximately reasonable?\nFor what kinds of treatments would this assumption be clearly implausible? Provide a specific example and explain why treatment effects would likely vary across individuals.\n\n\n\n\nSolution\n\nPart a. The constant treatment effects assumption might be approximately reasonable in some contexts:\nSimple, additive interventions: A treatment that mechanically adds a fixed amount might have roughly constant effects. For example, if a government program gives every recipient exactly $500, the effect on “dollars received” is constant at $500 for everyone.\nHighly standardized settings with homogeneous units: In carefully controlled laboratory experiments with nearly identical subjects (such as certain agricultural experiments with genetically identical plants), treatment effects might be relatively uniform.\nVery small effects: When treatment effects are small relative to natural variation in outcomes, the assumption of constant effects might not matter much practically, even if it’s technically false.\nEven in these cases, truly constant effects are unlikely. But the assumption might be close enough to be useful for certain purposes.\nPart b. Constant treatment effects would be clearly implausible for treatments where individual circumstances strongly influence how people respond.\nExample: A job training program’s effect on earnings\nTreatment effects would likely vary substantially across individuals because:\n\nBaseline skills: Someone with no prior job skills might benefit enormously from training, while someone who already has strong skills might gain little or nothing.\nLocal labor markets: The value of new skills depends on whether employers in the person’s area are hiring for jobs that use those skills. A person in a booming job market might see large earnings gains; a person in a depressed area might see none.\nPersonal circumstances: People differ in their ability to apply what they learn, their job search networks, the discrimination they face, their health, their family responsibilities, and countless other factors that affect how training translates into earnings.\nMotivation and engagement: Some participants engage deeply with training while others do not, leading to different outcomes.\n\nFor a job training program, we would expect some participants to see large earnings gains, others to see modest gains, and some to see no gain or even losses (if, say, the time spent in training caused them to miss other opportunities). Assuming constant effects would ignore this important variation.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html",
    "href": "ch/ate-hat.html",
    "title": "2  Estimating the ATE",
    "section": "",
    "text": "2.1 The Problem; A Solution?\nIn the previous chapter, we defined the average treatment effect (ATE) as the difference in average potential outcomes under treatment and control. This is simply the hypothetical difference between the average outcome if we assigned everyone to treatment and the average outcome if we assigned everyone to control.\nBut we also acknowledged a fundamental problem: we can never observe both potential outcomes for the same individual. So how can we design a procedure to estimate the ATE from data?\nIn this chapter, we develop a simple and intuitive procedure and estimator.\nWe show that this is a good procedure because it is an unbiased estimator of the ATE. Importantly, this result relies only on the design of the experiment (the random assignment), not on any assumptions about how outcomes are generated.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#the-problem-a-solution",
    "href": "ch/ate-hat.html#the-problem-a-solution",
    "title": "2  Estimating the ATE",
    "section": "",
    "text": "2.1.1 Problem: We Can’t Observe the ATE\nRecall from the previous chapter that we define the ATE as the difference between two averages: the average outcome if we assigned everyone to treatment minus the average outcome if we assigned everyone to control.\nBut here’s the problem: we can’t assign everyone to treatment and everyone to control. Each individual can only be in one condition. If we assign someone to treatment, we see their outcome under treatment (but not their outcome under control). If we assign someone to control, we see their outcome under control (but not their outcome under treatment).\nThis means we can never directly compute the ATE. So how do we get around this?\n\n\n2.1.2 Solution?: Random Assignment\nThe key insight is that we don’t need to observe everyone’s outcome under treatment to learn about the average outcome under treatment. If we randomly assign individuals to treatment, then the individuals who happen to be assigned to treatment are—on average—just like the individuals who happen to be assigned to control. They are a simple random sample from the same population.\nThis is the logic of a completely randomized experiment. We take our group of individuals and randomly divide them into two groups: some go to treatment, some go to control.\n\nThe treated individuals are a random sample of the full group. So the average outcome we observe among treated individuals should be a good estimate of what the average outcome would have been if we had assigned everyone to treatment.\nSimilarly, the average outcome among control individuals should be a good estimate of what the average outcome would have been if we had assigned everyone to control.\n\nIn other words, random assignment lets us estimate the two quantities we need—the average outcome under treatment and the average outcome under control—even though we can’t observe them directly for everyone.\nThe difference between these two estimates gives us an estimate of the ATE. It won’t be perfect. Any particular randomization might, by chance, put more higher-outcome individuals in one group than the other. But on average, across all possible randomizations, this approach gets it exactly right.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#the-observed-data",
    "href": "ch/ate-hat.html#the-observed-data",
    "title": "2  Estimating the ATE",
    "section": "2.2 The Observed Data",
    "text": "2.2 The Observed Data\nIn a completely randomized experiment, we have \\(N\\) individuals. We randomly assign \\(N_t\\) individuals to treatment and the remaining \\(N_c = N - N_t\\) individuals to control, where \\(1 &lt; N_t &lt; N\\) (so at least one individual is in each group).\n\n\nIn practice, we tend to use a balanced design where \\(N_t = N_c = \\dfrac{N}{2}\\), so that half of the respondents go into the treatment group and an equal number go into the control group.\nWe use the indicator variable \\(D_i\\) to denote the treatment assignment for individual \\(i\\).\n\n\\(D_i = 1\\) if individual \\(i\\) is assigned to treatment\n\\(D_i = 0\\) if individual \\(i\\) is assigned to control\n\nThus we can write that\n\\[\nN_t = \\sum_{i=1}^{N} D_i \\quad \\text{and} \\quad N_c = \\sum_{i=1}^{N} (1 - D_i).\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThe big sigma (\\(\\sum\\)) just means “add up.” The expression \\(\\sum_{i=1}^{N} D_i\\) says this: start with individual 1, then individual 2, then individual 3, and so on up to individual \\(N\\), and add up all their \\(D_i\\) values.\nSince each \\(D_i\\) is either 0 (control) or 1 (treatment), adding them up counts how many 1’s there are—that is, how many individuals are in the treatment group. That’s \\(N_t\\).\nThe expression \\((1 - D_i)\\) just flips the indicator. If \\(D_i = 1\\), then \\(1 - D_i = 0\\). If \\(D_i = 0\\), then \\(1 - D_i = 1\\). So adding up all the \\((1 - D_i)\\) values counts how many 0’s there are in the original \\(D_i\\)’s—that is, how many individuals are in the control group. That’s \\(N_c\\).\nExample. Suppose we have \\(N = 5\\) individuals with the following treatment assignments:\n\n\n\nIndividual \\(i\\)\n\\(D_i\\)\n\\(1 - D_i\\)\n\n\n\n\n1\n1\n0\n\n\n2\n0\n1\n\n\n3\n1\n0\n\n\n4\n0\n1\n\n\n5\n1\n0\n\n\n\nTo count the treated individuals, we add up the \\(D_i\\) column: \\(N_t = 1 + 0 + 1 + 0 + 1 = 3\\).\nTo count the control individuals, we add up the \\(1 - D_i\\) column: \\(N_c = 0 + 1 + 0 + 1 + 0 = 2\\).\nThree individuals are treated; two are in control.\n\n\n\nFor each individual, we observe only one potential outcome. We call this the observed outcome, denoted \\(Y_i^{\\text{obs}}\\), so that\n\\[\nY_i^{\\text{obs}} = Y_i(D_i) =\n\\begin{cases}\nY_i(0) & \\text{if } D_i = 0 \\\\\nY_i(1) & \\text{if } D_i = 1\n\\end{cases}.\n\\]\nThe other potential outcome—the one we don’t observe—is the missing outcome, denoted \\(Y_i^{\\text{mis}}\\), so that\n\\[\nY_i^{\\text{mis}} = Y_i(1 - D_i) =\n\\begin{cases}\nY_i(1) & \\text{if } D_i = 0 \\\\\nY_i(0) & \\text{if } D_i = 1\n\\end{cases}.\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThe notation \\(Y_i(D_i)\\) means “plug the value of \\(D_i\\) into the potential outcome function.” Since \\(D_i\\) is either 0 or 1, this gives us either \\(Y_i(0)\\) or \\(Y_i(1)\\)—whichever one actually happened.\nThe curly brace notation is just a compact way of writing “if-then” rules. It says: look at \\(D_i\\), and depending on its value, pick the corresponding potential outcome.\nFor the observed outcome \\(Y_i^{\\text{obs}}\\), we get the potential outcome that matches the treatment the individual actually received. For the missing outcome \\(Y_i^{\\text{mis}}\\), we get the other potential outcome—the one we can’t see.\nExample. Suppose we have \\(N = 5\\) individuals with the following potential outcomes and treatment assignments:\n\n\n\n\n\n\n\n\n\n\n\nIndividual \\(i\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\\(Y_i^{\\text{mis}}\\)\n\n\n\n\n1\n4\n7\n1\n7\n4\n\n\n2\n6\n5\n0\n6\n5\n\n\n3\n5\n8\n1\n8\n5\n\n\n4\n3\n6\n0\n3\n6\n\n\n5\n7\n9\n1\n9\n7\n\n\n\nFor individual 1, \\(D_1 = 1\\) (treated), so we observe \\(Y_1^{\\text{obs}} = Y_1(1) = 7\\) and the missing outcome is \\(Y_1^{\\text{mis}} = Y_1(0) = 4\\).\nFor individual 2, \\(D_2 = 0\\) (control), so we observe \\(Y_2^{\\text{obs}} = Y_2(0) = 6\\) and the missing outcome is \\(Y_2^{\\text{mis}} = Y_2(1) = 5\\).\n\n\n\n\n2.2.1 What the Data Look Like\nTo make this concrete, consider again our hypothetical experiment with 10 respondents. Suppose we know all the potential outcomes:\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n4\n7\n3\n\n\n2\n6\n5\n-1\n\n\n3\n5\n5\n0\n\n\n4\n3\n9\n6\n\n\n5\n7\n10\n3\n\n\n6\n5\n4\n-1\n\n\n7\n4\n8\n4\n\n\n8\n6\n7\n1\n\n\n9\n5\n3\n-2\n\n\n10\n4\n6\n2\n\n\n\nWe computed in the previous chapter that \\(\\text{ATE} = 1.5\\) for these data.\nNow suppose we run an experiment with \\(N_t = 5\\) and \\(N_c = 5\\). After randomization, respondents 1, 4, 5, 7, and 10 are assigned to treatment, while respondents 2, 3, 6, 8, and 9 are assigned to control. What do we actually observe?\n\n\n\n\n\n\n\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n?\n7\n1\n7\n\n\n2\n6\n?\n0\n6\n\n\n3\n5\n?\n0\n5\n\n\n4\n?\n9\n1\n9\n\n\n5\n?\n10\n1\n10\n\n\n6\n5\n?\n0\n5\n\n\n7\n?\n8\n1\n8\n\n\n8\n6\n?\n0\n6\n\n\n9\n5\n?\n0\n5\n\n\n10\n?\n6\n1\n6\n\n\n\nNotice that for each respondent, we observe exactly one potential outcome. The question marks represent the counterfactual outcomes we can never observe. We cannot compute \\(\\tau_i = Y_i(1) - Y_i(0)\\) for any individual because we never have both values.\nBut here’s the key insight: even though we can’t compute individual treatment effects, we can compute averages within the treatment and control groups.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#the-difference-in-means-estimator",
    "href": "ch/ate-hat.html#the-difference-in-means-estimator",
    "title": "2  Estimating the ATE",
    "section": "2.3 The Difference-in-Means Estimator",
    "text": "2.3 The Difference-in-Means Estimator\nA natural approach is to estimate the ATE by comparing the average outcome among treated individuals to the average outcome among control individuals. We define \\(\\overline{Y}^{\\text{obs}}_{t}\\) and \\(\\overline{Y}^{\\text{obs}}_{c}\\) as\n\\[\n\\overline{Y}^{\\text{obs}}_{t} = \\frac{1}{N_t} \\sum_{i:D_i=1} Y^{\\text{obs}}_{i} \\quad \\text{and} \\quad \\overline{Y}^{\\text{obs}}_{c} = \\frac{1}{N_c} \\sum_{i:D_i=0} Y^{\\text{obs}}_{i}.\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThe bar over \\(Y\\) (as in \\(\\overline{Y}\\)) means “average.” So \\(\\overline{Y}^{\\text{obs}}_{t}\\) is the average observed outcome in the treatment group, and \\(\\overline{Y}^{\\text{obs}}_{c}\\) is the average observed outcome in the control group.\nThe subscript \\(i:D_i=1\\) under the summation sign means “only add up the individuals where \\(D_i = 1\\)”—that is, only the treated individuals. Similarly, \\(i:D_i=0\\) means “only the control individuals.”\nSo the formula says this: add up the observed outcomes for all treated individuals, then divide by \\(N_t\\) (the number of treated individuals) to get the average. Do the same for control individuals, dividing by \\(N_c\\).\nExample. Suppose we have \\(N = 5\\) individuals:\n\n\n\nIndividual \\(i\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n1\n7\n\n\n2\n0\n6\n\n\n3\n1\n8\n\n\n4\n0\n3\n\n\n5\n1\n9\n\n\n\nThere are \\(N_t = 3\\) treated individuals (individuals 1, 3, and 5) and \\(N_c = 2\\) control individuals (individuals 2 and 4).\nFor the treatment group, we add up only the outcomes where \\(D_i = 1\\), so that\n\\[\n\\overline{Y}^{\\text{obs}}_{t} = \\frac{1}{3}(7 + 8 + 9) = \\frac{24}{3} = 8.\n\\]\nFor the control group, we add up only the outcomes where \\(D_i = 0\\), so that\n\\[\n\\overline{Y}^{\\text{obs}}_{c} = \\frac{1}{2}(6 + 3) = \\frac{9}{2} = 4.5.\n\\]\n\n\n\nThese are the average observed outcomes in the treatment group and the control group, respectively.\nThe difference-in-means estimator for the ATE is\n\\[\n\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}.\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThe “hat” over ATE (as in \\(\\widehat{\\text{ATE}}\\)) means “estimate of.” We can’t compute the true ATE because we don’t observe all potential outcomes, so we estimate it using the data we have.\nThe formula says: take the average outcome among treated individuals and subtract the average outcome among control individuals. That’s it—just a difference of two averages.\nExample. Using the same 5 individuals from before:\n\n\n\nIndividual \\(i\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n1\n7\n\n\n2\n0\n6\n\n\n3\n1\n8\n\n\n4\n0\n3\n\n\n5\n1\n9\n\n\n\nWe already computed \\(\\overline{Y}^{\\text{obs}}_{t} = 8\\) and \\(\\overline{Y}^{\\text{obs}}_{c} = 4.5\\).\nThus \\(\\widehat{\\text{ATE}} = 8 - 4.5 = 3.5\\). Our estimate is that the treatment increases outcomes by 3.5 units on average.\n\n\n\n\n2.3.1 Computing the Estimate\nUsing our example data, we can compute\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{5}(7 + 9 + 10 + 8 + 6) = \\frac{40}{5} = 8\n\\end{align}\n\\]\nand\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{5}(6 + 5 + 5 + 6 + 5) = \\frac{27}{5} = 5.4\n\\end{align}.\n\\]\nTherefore \\(\\widehat{\\text{ATE}} = 8 - 5.4 = 2.6\\). But recall that the true ATE (which we computed using all potential outcomes) is 1.5. So our estimate is off by 1.1 units.\nIs this a problem? Not necessarily. Any particular estimate will differ from the true ATE due to the randomness in treatment assignment. The question is whether, on average across all possible randomizations, our estimator gets it right.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#why-this-estimator",
    "href": "ch/ate-hat.html#why-this-estimator",
    "title": "2  Estimating the ATE",
    "section": "2.4 Why This Estimator?",
    "text": "2.4 Why This Estimator?\nWhy is \\(\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\) a sensible estimator of the ATE?\nRecall that we define the ATE as\n\\[\n\\text{ATE} = \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0) = \\overline{Y}(1) - \\overline{Y}(0).\n\\]\nThe ATE is the difference between two population averages: the average of all potential outcomes under treatment and the average of all potential outcomes under control.\nOur estimator replaces these population averages with sample averages:\n\nInstead of averaging \\(Y_i(1)\\) over all individuals, we average \\(Y_i^{\\text{obs}}\\) over individuals assigned to treatment\nInstead of averaging \\(Y_i(0)\\) over all individuals, we average \\(Y_i^{\\text{obs}}\\) over individuals assigned to control\n\n\n\nThis “plug-in” approach—replacing population quantities with their sample counterparts—is a fundamental strategy in statistics. Under random assignment, the treated individuals are a random sample from the population, so \\(\\overline{Y}^{\\text{obs}}_{t}\\) should be a good estimate of \\(\\overline{Y}(1)\\). Similarly, the control individuals are a random sample, so \\(\\overline{Y}^{\\text{obs}}_{c}\\) should be a good estimate of \\(\\overline{Y}(0)\\).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#design-based-inference",
    "href": "ch/ate-hat.html#design-based-inference",
    "title": "2  Estimating the ATE",
    "section": "2.5 Design-Based Inference",
    "text": "2.5 Design-Based Inference\nBefore proving that the estimator \\(\\widehat{\\text{ATE}}\\) is unbiased, we need to understand\n\nthat the estimate \\(\\widehat{\\text{ATE}}\\) is a noisy and random estimate and\n\nwhat makes this estimate random in the first place.\n\nIn typical statistical settings, we imagine that data are drawn from some distribution \\(Y_i \\sim f(\\theta)\\). The randomness comes from imagining that the data could have been different if we had drawn a different sample from the population.\nBut in the potential outcomes framework for randomized experiments, we take a different view. The potential outcomes \\(Y_i(0)\\) and \\(Y_i(1)\\) are treated as fixed values, not random variables. They are simply the outcomes each individual would experience under each condition—there’s nothing random about the potential outcomes.\nThe only randomness in the experiment comes from the treatment assignment \\(D_i\\). And because we designed the randomization mechanism, we know exactly how this randomness works.\nThis is important: because we designed the randomization mechanism, we know exactly how this randomness works.\nThis is called design-based inference in which all uncertainty comes from the design of the experiment (i.e., the random assignment in this case), not from any model of how outcomes are generated.\nTo make this explicit, we can rewrite the estimator to highlight what is random and what is fixed, so that\n\\[\n\\widehat{\\text{ATE}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{D_i \\cdot Y_i(1)}{N_t/N} - \\frac{(1 - D_i) \\cdot Y_i(0)}{N_c/N} \\right).\n\\]\n\n\n\n\n\n\nUnderstanding This Notation\n\n\n\n\n\nThis formula looks intimidating, but it’s just a clever rewriting of the difference-in-means estimator that separates the random part (\\(D_i\\)) from the fixed parts (potential outcomes).\nLet’s break it down piece by piece:\n\n\\(D_i \\cdot Y_i(1)\\): This equals \\(Y_i(1)\\) when individual \\(i\\) is treated (\\(D_i = 1\\)) and equals 0 when individual \\(i\\) is in control (\\(D_i = 0\\)). So it “turns on” the treated potential outcome only for treated individuals.\n\\((1 - D_i) \\cdot Y_i(0)\\): This does the opposite—it equals \\(Y_i(0)\\) when \\(D_i = 0\\) and equals 0 when \\(D_i = 1\\). It “turns on” the control potential outcome only for control individuals.\n\\(N_t/N\\): This is the fraction of individuals assigned to treatment (the treatment probability).\nDividing by \\(N_t/N\\) in the first term and \\(N_c/N\\) in the second term rescales each contribution so that the formula averages correctly over each group.\n\nThe key insight is that when you work through the algebra, this formula gives exactly the same answer as \\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\). But writing it this way makes clear that \\(D_i\\) is the only random quantity—the potential outcomes \\(Y_i(1)\\) and \\(Y_i(0)\\) are fixed numbers.\nExample. Suppose \\(N = 4\\) with \\(N_t = 2\\) and \\(N_c = 2\\) and the following potential outcomes and randomization:\n\n\n\nIndividual \\(i\\)\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\n\n\n\n1\n4\n7\n1\n\n\n2\n6\n5\n0\n\n\n3\n3\n8\n1\n\n\n4\n5\n6\n0\n\n\n\nFor individual 1 (\\(D_1 = 1\\)): the contribution is \\(\\frac{1 \\cdot 7}{2/4} - \\frac{0 \\cdot 4}{2/4} = \\frac{7}{0.5} - 0 = 14\\).\nFor individual 2 (\\(D_2 = 0\\)): the contribution is \\(\\frac{0 \\cdot 5}{2/4} - \\frac{1 \\cdot 6}{2/4} = 0 - \\frac{6}{0.5} = -12\\).\nFor individual 3 (\\(D_3 = 1\\)): the contribution is \\(\\frac{1 \\cdot 8}{0.5} - 0 = 16\\).\nFor individual 4 (\\(D_4 = 0\\)): the contribution is \\(0 - \\frac{5}{0.5} = -10\\).\nAdding these and dividing by \\(N = 4\\): \\(\\widehat{\\text{ATE}} = \\frac{1}{4}(14 - 12 + 16 - 10) = \\frac{8}{4} = 2\\).\nYou can verify this equals the simple difference in means: \\(\\overline{Y}^{\\text{obs}}_{t} = \\frac{7 + 8}{2} = 7.5\\) and \\(\\overline{Y}^{\\text{obs}}_{c} = \\frac{6 + 5}{2} = 5.5\\), so \\(\\widehat{\\text{ATE}} = 7.5 - 5.5 = 2\\).\n\n\n\nIn this expression\n\n\\(Y_i(1)\\) and \\(Y_i(0)\\) are fixed (the potential outcomes)\n\\(N\\), \\(N_t\\), and \\(N_c\\) are fixed (determined by design)\n\\(D_i\\) is random (the only source of uncertainty)\n\nThe subscript notation \\(E_D[\\cdot]\\) indicates that we are taking expectations with respect to the randomization distribution—the distribution induced by the random assignment of individuals to treatment and control.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#unbiasedness-of-widehattextate",
    "href": "ch/ate-hat.html#unbiasedness-of-widehattextate",
    "title": "2  Estimating the ATE",
    "section": "2.6 Unbiasedness of \\(\\widehat{\\text{ATE}}\\)",
    "text": "2.6 Unbiasedness of \\(\\widehat{\\text{ATE}}\\)\nWe now prove the key result: \\(\\widehat{\\text{ATE}}\\) is an unbiased estimator of \\(\\text{ATE}\\). Informally, this means that our estimator “gets it right on average”. It means that if we could repeat the randomization many times, our estimates would exactly equal the ATE in the long-run.\nTo state this result precisely, we need to introduce some notation. The notation is tedious, but the underlying idea is straightforward, important, and powerful.\n\n2.6.1 The Expectation Operator \\(E[\\cdot]\\)\nThe expectation operator \\(E[\\cdot]\\) is just a way of writing “long-run average.”\n\n\nThe expectation of a random variable is its average value across all possible outcomes, weighted by how likely each outcome is. You can think of \\(E[X]\\) as asking: “If I could repeat this random process infinitely many times, what would \\(X\\) average out to?”\nFor our purposes, we need four simple rules about expectations.\nRule 1: The expectation of a constant is that constant.\nIf \\(c\\) is a fixed number (not random), then \\(E[c] = c\\).\nIf something never changes, its “average” is just itself. For example, \\(E[5] = 5\\).\nRule 2: Constants can be pulled outside the expectation.\nIf \\(c\\) is a constant and \\(X\\) is random, then \\(E[c \\cdot X] = c \\cdot E[X]\\).\nThe average of “5 times something random” equals 5 times the average of that random thing. If on average you earn $100 per day, then on average you earn $500 per five-day week.\nRule 3: The expectation of a sum is the sum of the expectations.\nIf \\(X\\) and \\(Y\\) are random variables, then\n\\[\nE[X + Y] = E[X] + E[Y].\n\\]\nThe average of “two random things added together” equals the sum of their averages. If on average you earn $100 per day from your job and $20 per day from side work, then on average you earn $120 per day total. You do not need \\(X\\) and \\(Y\\) to be independent for this rule to hold.\nRule 4: The expectation of a binary (0/1) random variable equals its probability of being 1.\nIf \\(X\\) can only be 0 or 1, then \\(E[X] = \\Pr(X = 1)\\).\nThis is the key rule for our proof. And it’s intuitive. If you flip a fair coin and let \\(X = 1\\) for heads and \\(X = 0\\) for tails, what’s the average value of \\(X\\)? Half the time you get 1, half the time you get 0, so the average is \\(\\frac{1}{2}(1) + \\frac{1}{2}(0) = 0.5\\). And \\(\\Pr(X = 1) = 0.5\\). They match!\nMore generally, if you repeat the process many times, the fraction of 1’s you observe will approach the probability of getting a 1. So the average value equals the probability.\n\n\nWhy does Rule 4 work? Well, remember that the expectation of a random variable is defined as the sum of each possible value times its probability, so that\n\\[\nE[X] = \\sum_{\\text{all values } x} x \\cdot \\Pr(X = x).\n\\]\nFor a binary variable that can only be 0 or 1, then we have\n\\[\nE[X] = 0 \\cdot \\Pr(X = 0) + 1 \\cdot \\Pr(X = 1) = \\Pr(X = 1).\n\\]\nThe zero term disappears, and we’re left with just the probability that \\(X\\) equals 1.\nExample. Suppose you roll a die and let \\(X = 1\\) if you roll a 6, and \\(X = 0\\) otherwise. Then \\(\\Pr(X = 1) = 1/6\\), so \\(E[X] = 1/6 \\approx 0.167\\). If you rolled the die 600 times, you’d expect about 100 sixes, and your average value of \\(X\\) would be about \\(100/600 = 0.167\\).\n\n\n2.6.2 The Theorem\nNow we can state the key result precisely. When we write \\(E_D[\\widehat{\\text{ATE}}]\\), we mean “the average value of our estimate across all possible random assignments.” (The subscript \\(D\\) reminds us that the only randomness comes from treatment assignment.)\n\n\n\n\n\n\nTheorem\n\n\n\nUnder random assignment, \\(\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\) is an unbiased estimator of the ATE. This mean that \\[\nE_D[\\widehat{\\text{ATE}}] = \\text{ATE}.\n\\]\n\n\nIf we average our estimate over all the different ways we could have randomly assigned individuals to treatment and control, we get exactly the true ATE.\n\n\n2.6.3 The Proof\nProof. We want to show that \\(E_D[\\widehat{\\text{ATE}}] = \\text{ATE}\\).\nStep 1: Write the estimator to separate random from fixed.\nFirst, we write \\(\\widehat{\\text{ATE}}\\) in a form that clearly separates the random part (\\(D_i\\)) from the fixed parts (the potential outcomes \\(Y_i(1)\\) and \\(Y_i(0)\\)). We borrow the representation above, where\n\\[\n\\widehat{\\text{ATE}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{D_i \\cdot Y_i(1)}{N_t/N} - \\frac{(1 - D_i) \\cdot Y_i(0)}{N_c/N} \\right).\n\\]\nThis formula looks complicated, but it has two important features:\n\nIt equals the difference in the observed means (though this is only apparent after studying it carefully).\nIt highlights that \\(D_i\\) is the only random thing.\nIt will be easy to use with the rules for expectations.\n\nStep 2: Take the expectation.\nNow we ask: what is the average value of \\(\\widehat{\\text{ATE}}\\) across all possible randomizations?\n\\[\nE_D[\\widehat{\\text{ATE}}] = E_D\\left[ \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{D_i \\cdot Y_i(1)}{N_t/N} - \\frac{(1 - D_i) \\cdot Y_i(0)}{N_c/N} \\right) \\right]\n\\]\nStep 3: Move the expectation inside.\nHere’s where the magic happens. Because the potential outcomes are fixed numbers and only \\(D_i\\) is random, we can move the expectation operator inside the formula until it includes only \\(D_i\\) and \\(1 - D_i\\). Rule 2 above allows us to do this.\n\n\nThink of it this way: if you’re computing the average of “5 times something random,” you can compute it as “5 times the average of that random thing” (that’s Rule 2). The \\(\\frac{1}{N}\\), the \\(\\sum\\), the potential outcomes \\(Y_i(1)\\) and \\(Y_i(0)\\), the fractions \\(N_t/N\\) and \\(N_c/N\\) are all fixed numbers that pass right through the expectation. The expectation only “grabs onto” the random part, \\(D_i\\).\n\\[\nE_D[\\widehat{\\text{ATE}}] = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{E_D[D_i] \\cdot Y_i(1)}{N_t/N} - \\frac{E_D[1 - D_i] \\cdot Y_i(0)}{N_c/N} \\right)\n\\]\n\\[\\begin{align}\nE_D[\\widehat{\\text{ATE}}]\n&= E_D\\!\\left[\n\\frac{1}{N} \\sum_{i=1}^{N}\n\\left(\n\\frac{D_i\\, Y_i(1)}{N_t/N}\n-\n\\frac{(1 - D_i)\\, Y_i(0)}{N_c/N}\n\\right)\n\\right]\n\\qquad \\text{(definition of the estimator)} \\\\[6pt]\n\n&= \\frac{1}{N}\nE_D\\!\\left[\n\\sum_{i=1}^{N}\n\\left(\n\\frac{D_i\\, Y_i(1)}{N_t/N}\n-\n\\frac{(1 - D_i)\\, Y_i(0)}{N_c/N}\n\\right)\n\\right]\n\\qquad \\text{($\\tfrac{1}{N}$ is constant; Rule 2)} \\\\[6pt]\n\n&= \\frac{1}{N}\n\\sum_{i=1}^{N}\nE_D\\!\\left[\n\\frac{D_i\\, Y_i(1)}{N_t/N}\n-\n\\frac{(1 - D_i)\\, Y_i(0)}{N_c/N}\n\\right]\n\\qquad \\text{(expectation of a sum; Rule 3)} \\\\[6pt]\n\n&= \\frac{1}{N}\n\\sum_{i=1}^{N}\n\\left(\n\\frac{Y_i(1)}{N_t/N} \\, E_D[D_i]\n-\n\\frac{Y_i(0)}{N_c/N} \\, E_D[1 - D_i]\n\\right)\n\\qquad \\text{(only $D_i$ is random; Rule 2)}.\n\\end{align}\\]\nStep 4: Compute the expectation of \\(D_i\\).\nNow we need to find \\(E_D[D_i]\\). Remember that \\(D_i\\) is a binary variable that equals 1 if individual \\(i\\) is assigned to treatment, and 0 if individual \\(i\\) is assigned to control. By Rule 4, the expectation of a binary variable equals its probability of being 1, so that\n\\[\nE_D[D_i] = \\Pr(D_i = 1).\n\\]\nUnder completely randomized assignment, every individual has the same chance of being assigned to treatment. If we’re assigning \\(N_t\\) individuals to treatment out of \\(N\\) total individuals, then each individual has probability \\(N_t/N\\) of being treated so that\n\\[\nE_D[D_i] = \\Pr(D_i = 1) = \\frac{N_t}{N}.\n\\]\nStep 5: Compute the expectation of \\(1 - D_i\\).\nSimilarly, \\(1 - D_i\\) is also binary. It equals 1 when \\(D_i = 0\\) (individual in control) and equals 0 when \\(D_i = 1\\) (individual in treatment). Then we have\n\\[\nE_D[1 - D_i] = \\Pr(D_i = 0) = \\frac{N_c}{N}.\n\\]\nStep 6: Substitute and simplify.\nNow we plug these values back in, we obtain\n\\[\n\\begin{align}\nE_D[\\widehat{\\text{ATE}}] &= \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\frac{(N_t/N) \\cdot Y_i(1)}{N_t/N} - \\frac{(N_c/N) \\cdot Y_i(0)}{N_c/N} \\right).\n\\end{align}\n\\] Then something magical happens. In the first term, we have \\(N_t/N\\) in both the numerator and denominator, so they cancel out.\nThe same thing happens with \\(N_c/N\\) in the second term, so that\n\\[\n\\begin{align}\nE_D[\\widehat{\\text{ATE}}] &= \\frac{1}{N} \\sum_{i=1}^{N} \\left( Y_i(1) - Y_i(0) \\right).\n\\end{align}\n\\]\nThis is just the average of individual treatment effects across all individuals. This is exactly the definition of the ATE, so that\n\\[\nE_D[\\widehat{\\text{ATE}}] = \\text{ATE}.\n\\]\nThis completes the proof and shows that \\(\\widehat{\\text{ATE}}\\) is an unbiased estimator of \\(\\widehat{\\text{ATE}}\\). \\(\\square\\)\n\n\n\n\n\n\nTip\n\n\n\nThe key insight is that the fractions \\(N_t/N\\) and \\(N_c/N\\) cancel perfectly. This happens because (1) the probability of assignment to treatment equals \\(N_t/N\\), and (2) we divide by \\(N_t\\) when averaging over treated individuals. The “selection” into treatment is perfectly balanced by the “weighting” in our estimator.\n\n\n\n\n2.6.4 What Does Unbiasedness Mean?\nUnbiasedness means that on average, across all possible randomizations, our estimator equals the true ATE. Any particular estimate might be too high or too low, but there’s no systematic tendency to over- or under-estimate.\nIn our example, we got \\(\\widehat{\\text{ATE}} = 2.6\\) when the true ATE is 1.5. This particular randomization overestimated. But if we had assigned different individuals to treatment, we might have gotten a different estimate. Some randomizations would overestimate, some would underestimate, and on average we would get it right.\n\n\n2.6.5 No Model Required\nNotice what we did not assume in this proof:\n\nWe did not assume any particular distribution for the outcomes\nWe did not assume the treatment effects are constant\nWe did not assume the outcomes are normally distributed\nWe did not assume any functional form for how treatment affects outcomes\nWe did not assume a “large” sample\n\nThe only assumption is that treatment was randomly assigned. This is why randomized experiments are so powerful. Randomization provides unbiased estimates (and other good things to be discussed later) without requiring strong modeling assumptions.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#a-different-randomization",
    "href": "ch/ate-hat.html#a-different-randomization",
    "title": "2  Estimating the ATE",
    "section": "2.7 A Different Randomization",
    "text": "2.7 A Different Randomization\nTo reinforce that \\(\\widehat{\\text{ATE}}\\) depends on the randomization, consider what happens with a different random assignment. Suppose instead that individuals 2, 3, 6, 8, and 9 are assigned to treatment, while individuals 1, 4, 5, 7, and 10 are assigned to control.\n\n\n\n\n\n\n\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n4\n?\n0\n4\n\n\n2\n?\n5\n1\n5\n\n\n3\n?\n5\n1\n5\n\n\n4\n3\n?\n0\n3\n\n\n5\n7\n?\n0\n7\n\n\n6\n?\n4\n1\n4\n\n\n7\n4\n?\n0\n4\n\n\n8\n?\n7\n1\n7\n\n\n9\n?\n3\n1\n3\n\n\n10\n4\n?\n0\n4\n\n\n\nNow we compute\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{5}(5 + 5 + 4 + 7 + 3) = \\frac{24}{5} = 4.8\n\\end{align}\n\\]\nand\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{5}(4 + 3 + 7 + 4 + 4) = \\frac{22}{5} = 4.4.\n\\end{align}\n\\]\nThus \\(\\widehat{\\text{ATE}} = 4.8 - 4.4 = 0.4\\).\nThis randomization gives us \\(\\widehat{\\text{ATE}} = 0.4\\), which underestimates the true ATE of 1.5. The first randomization overestimated (2.6), this one underestimates (0.4). Unbiasedness tells us that if we averaged over all possible randomizations, we would get exactly 1.5.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#computing-widehattextate-in-r",
    "href": "ch/ate-hat.html#computing-widehattextate-in-r",
    "title": "2  Estimating the ATE",
    "section": "2.8 Computing \\(\\widehat{\\text{ATE}}\\) in R",
    "text": "2.8 Computing \\(\\widehat{\\text{ATE}}\\) in R\nSo far, we have computed \\(\\widehat{\\text{ATE}}\\) by hand. In practice, we use software. In this section, we walk through two approaches in R: (1) using mean() to compute the difference in means directly, and (2) using lm() to fit a linear regression. Both approaches give the same answer, but mean() is a little more intuitive and lm() is more useful in the practice.\n\n2.8.1 The Mock Rasinski Data\nWe collected data that mimics Rasinski’s experiment. Each respondent was randomly assigned to see either the “welfare” wording or the “assistance to the poor” wording. The respondent then indicated whether they thought government spending on this program was “Too little,” “About right,” or “Too much.”\nFirst, let’s load the data and prepare it for analysis. For convenience, I’ve written a little tribble() as a convenient way to hold the data (rather than loading from a CSV).\n\n# load packages\nlibrary(tidyverse)\nlibrary(tibble)\nlibrary(forcats)\n\n# load the mock rasinski data\nrasinski &lt;- tribble(\n  ~desc,                     ~response,\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"About right\",\n  \"welfare\",                \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"About right\",\n  \"welfare\",                \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"welfare\",                \"Too much\",\n  \"welfare\",                \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too much\",\n  \"welfare\",                \"Too little\",\n  \"welfare\",                \"About right\",\n  \"welfare\",                \"About right\",\n  \"welfare\",                \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                \"Too little\"\n)\n\n# take a quick look\nglimpse(rasinski)\n\nRows: 39\nColumns: 2\n$ desc     &lt;chr&gt; \"assistance to the poor\", \"welfare\", \"assistance to the poor\"…\n$ response &lt;chr&gt; \"Too little\", \"Too little\", \"Too little\", \"Too little\", \"Too …\n\n\nThe desc variable contains the experimental condition. It takes on the value \"welfare\" (control) or \"assistance to the poor\" (treatment). The response variable contains the respondent’s answer.\nFollowing Rasinski’s coding scheme from the previous chapter, we code the outcome numerically:\n\nToo little = 1\nAbout right = 2\nToo much = 3\n\n\n# code the outcome variable numerically\nrasinski &lt;- rasinski |&gt;\n  mutate(\n    outcome = case_when(\n      response == \"Too little\" ~ 1,\n      response == \"About right\" ~ 2,\n      response == \"Too much\" ~ 3\n    )\n  ) |&gt;\n  glimpse()\n\nRows: 39\nColumns: 3\n$ desc     &lt;chr&gt; \"assistance to the poor\", \"welfare\", \"assistance to the poor\"…\n$ response &lt;chr&gt; \"Too little\", \"Too little\", \"Too little\", \"Too little\", \"Too …\n$ outcome  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 3…\n\n\nWe also need to create a treatment indicator variable. Following our convention, treatment (\\(D_i = 1\\)) is the “assistance to the poor” wording and control (\\(D_i = 0\\)) is the “welfare” wording.\n\n# create treatment indicator\nrasinski &lt;- rasinski |&gt;\n  mutate(\n    treatment = if_else(desc == \"assistance to the poor\", 1, 0)\n  ) |&gt;\n  glimpse()\n\nRows: 39\nColumns: 4\n$ desc      &lt;chr&gt; \"assistance to the poor\", \"welfare\", \"assistance to the poor…\n$ response  &lt;chr&gt; \"Too little\", \"Too little\", \"Too little\", \"Too little\", \"Too…\n$ outcome   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, …\n$ treatment &lt;dbl&gt; 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, …\n\n\n\n\n2.8.2 Approach 1: Using mean()\nThe difference-in-means estimator is\n\\[\n\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}.\n\\]\nWe can compute this directly using R’s mean() function. The key is to subset the data to get the outcomes for each group separately.\nStep 1: Identify the treated and control observations.\nWe use logical indexing to select rows where the treatment indicator equals 1 (treated) or 0 (control).\nWe can write compactly in a single line.\n\n# direct computation of difference in means\nate_hat &lt;- mean(rasinski$outcome[rasinski$treatment == 1]) -\n  mean(rasinski$outcome[rasinski$treatment == 0])\n\nate_hat\n\n[1] -0.2210526\n\n\nThe estimated ATE is -0.221. Since lower values indicate more support for spending (“Too little” = 1), a negative estimate means the “assistance to the poor” wording increases support for spending compared to the “welfare” wording.\n\n\n\n\n\n\nThis Is Only an Estimate\n\n\n\n\n\nRemember that \\(\\widehat{\\text{ATE}}\\) is an estimate of the true \\(\\text{ATE}\\), not the \\(\\text{ATE}\\) itself. If we had randomized respondents differently—assigning different people to treatment and control—we would have observed different outcomes and computed a different estimate. Perhaps it would have been a bit larger, perhaps a bit smaller, or perhaps even the opposite sign.\nThis is a fundamental feature of randomized experiments: the estimate we get depends on the particular randomization we happened to draw. The true \\(\\text{ATE}\\) is fixed (it’s determined by the potential outcomes in the population), but our estimate of it varies with the randomization.\nIn future chapters, we will address this uncertainty head-on. Our framework allows us to say a great deal about how good our estimate is—that is, how close \\(\\widehat{\\text{ATE}}\\) is likely to be to the true \\(\\text{ATE}\\). For now, just keep in mind that the number we computed is our best guess, but it comes with uncertainty that we haven’t yet quantified.\n\n\n\n\n\n2.8.3 Approach 2: Using lm()\nSetting Up the Model\nLinear regression with lm() provides another way to compute the same estimate. This might seem surprising at first. After all, regression is usually taught as a way to model relationships between variables. But it turns out that a simple regression of the outcome on a treatment indicator gives us exactly the difference in means.\nWhen can fit the model\n\\[\nY_i = \\beta_0 + \\beta_1 D_i + \\epsilon_i,\n\\]\nwhere \\(D_i\\) is the treatment indicator (1 = treated, 0 = control).\nThe estimated coefficients have a direct interpretation:\n\n\\(\\hat{\\beta}_0\\) is the mean outcome in the control group (\\(\\overline{Y}^{\\text{obs}}_{c}\\))\n\\(\\hat{\\beta}_1\\) is the difference in means (\\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\))\n\nFitting the Model\nFirst, we need to ensure that “welfare” (control) is the reference category for our treatment variable. When lm() encounters a factor variable, it creates a dummy variable using the first level as the reference. By default, R orders factor levels alphabetically, which would make “assistance to the poor” the reference—the opposite of what we want.\nWe use fct_relevel() from the forcats package to set “welfare” as the reference category.\n\n# create a factor with \"welfare\" as the reference category\nrasinski &lt;- rasinski |&gt;\n  mutate(\n    condition = fct_relevel(desc, \"welfare\")\n  )\n\n# verify: \"welfare\" should be first\nlevels(rasinski$condition)\n\n[1] \"welfare\"                \"assistance to the poor\"\n\n\nNow we fit the linear model.\n\n# fit the model\nfit &lt;- lm(outcome ~ condition, data = rasinski)\n\n# extract the coefficients\ncoef(fit)\n\n                    (Intercept) conditionassistance to the poor \n                      1.4210526                      -0.2210526 \n\n\nLet’s verify that these coefficients match our manual calculations.\n\n# the slope should equal the ATE estimate\ncoef(fit)[2]\n\nconditionassistance to the poor \n                     -0.2210526 \n\nate_hat\n\n[1] -0.2210526\n\n\nThe values match exactly. Using mean() makes the calculation transparent. You can see exactly what quantities are being computed: the mean in each group and their difference. This is valuable for understanding and teaching the concept. Using lm() will be more valuable in applied work. We’ll use lm() moving forward.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#key-terms",
    "href": "ch/ate-hat.html#key-terms",
    "title": "2  Estimating the ATE",
    "section": "2.9 Key Terms",
    "text": "2.9 Key Terms\n\nCompletely randomized experiment\nObserved outcome\nMissing outcome\nDifference-in-means estimator\nDesign-based inference\nUnbiasedness",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/ate-hat.html#exercises",
    "href": "ch/ate-hat.html#exercises",
    "title": "2  Estimating the ATE",
    "section": "2.10 Exercises",
    "text": "2.10 Exercises\n\n2.10.1 Conceptual Understanding\n\nObserved vs. Missing Outcomes. In your own words, explain the difference between \\(Y_i^{\\text{obs}}\\) and \\(Y_i^{\\text{mis}}\\). Why is one observable and the other not?\n\n\n\nSolution\n\n\\(Y_i^{\\text{obs}}\\) is the observed outcome—the potential outcome that corresponds to the treatment condition the individual actually received. If individual \\(i\\) was assigned to treatment (\\(D_i = 1\\)), then \\(Y_i^{\\text{obs}} = Y_i(1)\\). If individual \\(i\\) was assigned to control (\\(D_i = 0\\)), then \\(Y_i^{\\text{obs}} = Y_i(0)\\).\n\\(Y_i^{\\text{mis}}\\) is the missing outcome—the potential outcome that corresponds to the treatment condition the individual did not receive. It is the counterfactual: what would have happened if the individual had been assigned to the other condition.\nWe can observe \\(Y_i^{\\text{obs}}\\) because it is the outcome that actually occurred. Once we assign individual \\(i\\) to treatment, we see how they respond to treatment. But we cannot observe \\(Y_i^{\\text{mis}}\\) because we cannot simultaneously assign the same individual to both treatment and control. The individual can only be in one condition at a time, so we only ever see one of the two potential outcomes.\nThis is the fundamental problem of causal inference applied to the observed data.\n\n\nDesign-Based Inference. Explain what it means to say that inference in randomized experiments is “design-based” rather than “model-based.” What is the source of randomness in each approach?\n\n\n\nSolution\n\nIn design-based inference, the potential outcomes \\(Y_i(0)\\) and \\(Y_i(1)\\) are treated as fixed values—they are simply the outcomes each individual would experience under each condition. The only source of randomness comes from the treatment assignment \\(D_i\\). Because we designed the randomization mechanism, we know exactly how this randomness works.\nIn model-based inference, the outcomes themselves are treated as random draws from some probability distribution. The randomness comes from imagining that the data could have been different if we had drawn a different sample from the population, or from random variation in how outcomes are generated.\nThe key difference is where the uncertainty comes from:\n\nDesign-based: Uncertainty comes from the random assignment. The potential outcomes are fixed; we just don’t know which ones we’ll observe because we don’t know the randomization in advance.\nModel-based: Uncertainty comes from the data-generating process. The outcomes themselves are random, drawn from some distribution with unknown parameters.\n\nDesign-based inference is powerful because we don’t need to make assumptions about how outcomes are generated. We only rely on the randomization we controlled.\n\n\nThe Meaning of Unbiasedness. A student says, “Since \\(\\widehat{\\text{ATE}}\\) is unbiased, my estimate must equal the true ATE.” Explain why this is incorrect. What does unbiasedness actually guarantee?\n\n\n\nSolution\n\nThe student’s statement is incorrect. Unbiasedness does not mean that any single estimate equals the true ATE.\nUnbiasedness is a property about averages over repeated randomizations. Specifically, \\(\\widehat{\\text{ATE}}\\) is unbiased means:\n\\[E_D[\\widehat{\\text{ATE}}] = \\text{ATE}\\]\nIn plain language: if we could repeat the randomization infinitely many times and compute \\(\\widehat{\\text{ATE}}\\) each time, the average of all those estimates would equal the true ATE.\nAny particular estimate will almost certainly differ from the true ATE. Some randomizations will, by chance, put more high-outcome individuals in the treatment group, leading to overestimates. Other randomizations will put more high-outcome individuals in control, leading to underestimates. Unbiasedness tells us that these over- and under-estimates balance out on average—there is no systematic tendency to err in one direction.\nThe chapter example illustrates this: one randomization gave \\(\\widehat{\\text{ATE}} = 2.6\\) (overestimate), another gave \\(\\widehat{\\text{ATE}} = 0.4\\) (underestimate), but the true ATE was 1.5. Neither estimate equaled the truth, but they averaged out correctly.\n\n\nWhy Randomization Matters. Suppose instead of randomly assigning treatment, we let participants choose whether to receive treatment. Why would \\(\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\) no longer be unbiased for the ATE?\n\n\n\nSolution\n\nIf participants choose whether to receive treatment, the people who select into treatment may be systematically different from those who select into control. This is called self-selection bias.\nFor example, in a job training program where participants choose whether to enroll:\n\nPeople who are more motivated, more confident, or have better prospects might be more likely to enroll\nThese same characteristics might also lead to better outcomes regardless of training\n\nIn this case, the treatment group would have higher average outcomes than the control group even if the training itself had no effect. The difference in means would reflect both (1) any true effect of training and (2) pre-existing differences between the groups.\nMathematically, the proof of unbiasedness relies on the fact that \\(E_D[D_i] = N_t/N\\) for all individuals \\(i\\)—every individual has the same probability of being treated. With self-selection, this no longer holds. Individuals with higher potential outcomes might have higher probabilities of selecting treatment, which means \\(E_D[D_i]\\) would vary across individuals and would be correlated with potential outcomes.\nWhen treatment assignment is correlated with potential outcomes, the difference-in-means estimator captures both the treatment effect and the selection effect, making it biased for the ATE.\n\n\n\n2.10.2 Computational Practice\n\nComputing the Estimate. Consider the following observed data from a randomized experiment:\n\n\n\nIndividual\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n1\n12\n\n\n2\n0\n8\n\n\n3\n1\n15\n\n\n4\n0\n7\n\n\n5\n0\n9\n\n\n6\n1\n11\n\n\n\n\nWhat are \\(N_t\\) and \\(N_c\\)?\nCompute \\(\\overline{Y}^{\\text{obs}}_{t}\\) and \\(\\overline{Y}^{\\text{obs}}_{c}\\).\nCompute \\(\\widehat{\\text{ATE}}\\).\n\n\n\n\nSolution\n\nPart a. Count the individuals in each group by looking at the \\(D_i\\) column:\n\nIndividuals with \\(D_i = 1\\) (treatment): Individuals 1, 3, and 6\nIndividuals with \\(D_i = 0\\) (control): Individuals 2, 4, and 5\n\nSo \\(N_t = 3\\) and \\(N_c = 3\\).\nPart b. Compute the mean outcome in each group.\nFor the treatment group (individuals where \\(D_i = 1\\)):\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{N_t} \\sum_{i:D_i=1} Y_i^{\\text{obs}} \\\\\n&= \\frac{1}{3}(12 + 15 + 11) \\\\\n&= \\frac{38}{3} \\\\\n&\\approx 12.67\n\\end{align}\n\\]\nFor the control group (individuals where \\(D_i = 0\\)):\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{N_c} \\sum_{i:D_i=0} Y_i^{\\text{obs}} \\\\\n&= \\frac{1}{3}(8 + 7 + 9) \\\\\n&= \\frac{24}{3} \\\\\n&= 8\n\\end{align}\n\\]\nPart c. The difference-in-means estimator is:\n\\[\n\\begin{align}\n\\widehat{\\text{ATE}} &= \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c} \\\\\n&= 12.67 - 8 \\\\\n&= 4.67\n\\end{align}\n\\]\nOur estimate is that treatment increases outcomes by about 4.67 units on average.\n\n\nDifferent Randomizations. Suppose the true potential outcomes for 4 individuals are:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n2\n5\n\n\n2\n4\n6\n\n\n3\n3\n4\n\n\n4\n5\n7\n\n\n\n\nCompute the true ATE.\nIf individuals 1 and 3 are assigned to treatment (\\(D_1 = D_3 = 1\\)) and individuals 2 and 4 are assigned to control (\\(D_2 = D_4 = 0\\)), compute \\(\\widehat{\\text{ATE}}\\).\nIf individuals 2 and 4 are assigned to treatment and individuals 1 and 3 are assigned to control, compute \\(\\widehat{\\text{ATE}}\\).\nAverage your two estimates from (b) and (c). How does this compare to the true ATE?\n\n\n\n\nSolution\n\nPart a. First, compute the individual treatment effects:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i = Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n2\n5\n\\(5 - 2 = 3\\)\n\n\n2\n4\n6\n\\(6 - 4 = 2\\)\n\n\n3\n3\n4\n\\(4 - 3 = 1\\)\n\n\n4\n5\n7\n\\(7 - 5 = 2\\)\n\n\n\nThe true ATE is:\n\\[\n\\begin{align}\n\\text{ATE} &= \\frac{1}{4} \\sum_{i=1}^{4} \\tau_i \\\\\n&= \\frac{1}{4}(3 + 2 + 1 + 2) \\\\\n&= \\frac{8}{4} \\\\\n&= 2\n\\end{align}\n\\]\nPart b. With individuals 1 and 3 treated, and individuals 2 and 4 in control:\n\nTreatment group observes: \\(Y_1(1) = 5\\) and \\(Y_3(1) = 4\\)\nControl group observes: \\(Y_2(0) = 4\\) and \\(Y_4(0) = 5\\)\n\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(5 + 4) = \\frac{9}{2} = 4.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(4 + 5) = \\frac{9}{2} = 4.5 \\\\\n\\widehat{\\text{ATE}} &= 4.5 - 4.5 = 0\n\\end{align}\n\\]\nPart c. With individuals 2 and 4 treated, and individuals 1 and 3 in control:\n\nTreatment group observes: \\(Y_2(1) = 6\\) and \\(Y_4(1) = 7\\)\nControl group observes: \\(Y_1(0) = 2\\) and \\(Y_3(0) = 3\\)\n\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(6 + 7) = \\frac{13}{2} = 6.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(2 + 3) = \\frac{5}{2} = 2.5 \\\\\n\\widehat{\\text{ATE}} &= 6.5 - 2.5 = 4\n\\end{align}\n\\]\nPart d. The average of the two estimates:\n\\[\n\\frac{0 + 4}{2} = 2\n\\]\nThis equals the true ATE exactly! The first randomization underestimated (0 vs. 2), and the second overestimated (4 vs. 2), but they balanced out. This illustrates unbiasedness: on average, the estimator gets it right.\n\n\nVerifying Unbiasedness. Using the same potential outcomes from Exercise 6, list all possible ways to assign exactly 2 individuals to treatment and 2 to control. For each, compute \\(\\widehat{\\text{ATE}}\\). Then compute the average of all these estimates and verify that it equals the true ATE.\n\n\n\nSolution\n\nWith 4 individuals and 2 assigned to treatment, there are \\(\\binom{4}{2} = 6\\) possible randomizations. Let’s list each one and compute \\(\\widehat{\\text{ATE}}\\).\nRecall the potential outcomes:\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n2\n5\n\n\n2\n4\n6\n\n\n3\n3\n4\n\n\n4\n5\n7\n\n\n\nRandomization 1: Individuals 1, 2 treated; Individuals 3, 4 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(5 + 6) = 5.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(3 + 5) = 4 \\\\\n\\widehat{\\text{ATE}} &= 5.5 - 4 = 1.5\n\\end{align}\n\\]\nRandomization 2: Individuals 1, 3 treated; Individuals 2, 4 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(5 + 4) = 4.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(4 + 5) = 4.5 \\\\\n\\widehat{\\text{ATE}} &= 4.5 - 4.5 = 0\n\\end{align}\n\\]\nRandomization 3: Individuals 1, 4 treated; Individuals 2, 3 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(5 + 7) = 6 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(4 + 3) = 3.5 \\\\\n\\widehat{\\text{ATE}} &= 6 - 3.5 = 2.5\n\\end{align}\n\\]\nRandomization 4: Individuals 2, 3 treated; Individuals 1, 4 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(6 + 4) = 5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(2 + 5) = 3.5 \\\\\n\\widehat{\\text{ATE}} &= 5 - 3.5 = 1.5\n\\end{align}\n\\]\nRandomization 5: Individuals 2, 4 treated; Individuals 1, 3 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(6 + 7) = 6.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(2 + 3) = 2.5 \\\\\n\\widehat{\\text{ATE}} &= 6.5 - 2.5 = 4\n\\end{align}\n\\]\nRandomization 6: Individuals 3, 4 treated; Individuals 1, 2 control\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{2}(4 + 7) = 5.5 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{2}(2 + 4) = 3 \\\\\n\\widehat{\\text{ATE}} &= 5.5 - 3 = 2.5\n\\end{align}\n\\]\nSummary of all estimates:\n\n\n\nRandomization\nTreated Individuals\n\\(\\widehat{\\text{ATE}}\\)\n\n\n\n\n1\n1, 2\n1.5\n\n\n2\n1, 3\n0\n\n\n3\n1, 4\n2.5\n\n\n4\n2, 3\n1.5\n\n\n5\n2, 4\n4\n\n\n6\n3, 4\n2.5\n\n\n\nAverage of all estimates:\n\\[\n\\begin{align}\nE_D[\\widehat{\\text{ATE}}] &= \\frac{1}{6}(1.5 + 0 + 2.5 + 1.5 + 4 + 2.5) \\\\\n&= \\frac{12}{6} \\\\\n&= 2\n\\end{align}\n\\]\nThe average of all possible estimates equals 2, which is exactly the true ATE we computed in Exercise 6. This confirms that \\(\\widehat{\\text{ATE}}\\) is unbiased: averaged across all possible randomizations, it equals the truth.\n\n\n\n2.10.3 Application to Rasinski’s Experiment\n\nRasinski’s Experiment Revisited. Return to the hypothetical Rasinski data from the previous chapter. Suppose we randomly assign 5 respondents to the “assistance to the poor” wording (treatment) and 5 to the “welfare” wording (control).\n\n\n\nRespondent\n\\(Y_i(0)\\) (“welfare”)\n\\(Y_i(1)\\) (“assistance”)\n\n\n\n\n1\n3 (Too much)\n1 (Too little)\n\n\n2\n3 (Too much)\n2 (About right)\n\n\n3\n2 (About right)\n1 (Too little)\n\n\n4\n3 (Too much)\n1 (Too little)\n\n\n5\n2 (About right)\n1 (Too little)\n\n\n6\n3 (Too much)\n2 (About right)\n\n\n7\n2 (About right)\n1 (Too little)\n\n\n8\n3 (Too much)\n1 (Too little)\n\n\n9\n2 (About right)\n2 (About right)\n\n\n10\n3 (Too much)\n1 (Too little)\n\n\n\n\nWe know from the previous chapter that the true ATE is -1.3. If respondents 1, 3, 5, 7, and 9 are assigned to treatment, compute \\(\\widehat{\\text{ATE}}\\). How close is it to the true ATE?\nIf respondents 2, 4, 6, 8, and 10 are assigned to treatment instead, compute \\(\\widehat{\\text{ATE}}\\). How close is it to the true ATE?\nAverage your estimates from (a) and (b). What do you notice?\n\n\n\n\nSolution\n\nPart a. With respondents 1, 3, 5, 7, and 9 assigned to treatment:\n\nTreatment group (sees “assistance to the poor”): Respondents 1, 3, 5, 7, 9\n\nObserved outcomes: \\(Y_1(1) = 1\\), \\(Y_3(1) = 1\\), \\(Y_5(1) = 1\\), \\(Y_7(1) = 1\\), \\(Y_9(1) = 2\\)\n\nControl group (sees “welfare”): Respondents 2, 4, 6, 8, 10\n\nObserved outcomes: \\(Y_2(0) = 3\\), \\(Y_4(0) = 3\\), \\(Y_6(0) = 3\\), \\(Y_8(0) = 3\\), \\(Y_{10}(0) = 3\\)\n\n\nComputing the means:\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{5}(1 + 1 + 1 + 1 + 2) = \\frac{6}{5} = 1.2 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{5}(3 + 3 + 3 + 3 + 3) = \\frac{15}{5} = 3 \\\\\n\\widehat{\\text{ATE}} &= 1.2 - 3 = -1.8\n\\end{align}\n\\]\nThis estimate of \\(-1.8\\) is 0.5 units away from the true ATE of \\(-1.3\\). It overestimates the magnitude of the effect.\nPart b. With respondents 2, 4, 6, 8, and 10 assigned to treatment:\n\nTreatment group: Respondents 2, 4, 6, 8, 10\n\nObserved outcomes: \\(Y_2(1) = 2\\), \\(Y_4(1) = 1\\), \\(Y_6(1) = 2\\), \\(Y_8(1) = 1\\), \\(Y_{10}(1) = 1\\)\n\nControl group: Respondents 1, 3, 5, 7, 9\n\nObserved outcomes: \\(Y_1(0) = 3\\), \\(Y_3(0) = 2\\), \\(Y_5(0) = 2\\), \\(Y_7(0) = 2\\), \\(Y_9(0) = 2\\)\n\n\nComputing the means:\n\\[\n\\begin{align}\n\\overline{Y}^{\\text{obs}}_{t} &= \\frac{1}{5}(2 + 1 + 2 + 1 + 1) = \\frac{7}{5} = 1.4 \\\\\n\\overline{Y}^{\\text{obs}}_{c} &= \\frac{1}{5}(3 + 2 + 2 + 2 + 2) = \\frac{11}{5} = 2.2 \\\\\n\\widehat{\\text{ATE}} &= 1.4 - 2.2 = -0.8\n\\end{align}\n\\]\nThis estimate of \\(-0.8\\) is 0.5 units away from the true ATE of \\(-1.3\\). It underestimates the magnitude of the effect.\nPart c. The average of the two estimates:\n\\[\n\\frac{-1.8 + (-0.8)}{2} = \\frac{-2.6}{2} = -1.3\n\\]\nThe average equals the true ATE exactly! This is a concrete illustration of unbiasedness. The first randomization overestimated the effect (in magnitude), and the second underestimated it by the same amount. When we average them, we get exactly the truth.\nNote: These two randomizations are not the only possible ones—there are \\(\\binom{10}{5} = 252\\) ways to assign 5 of 10 respondents to treatment. If we computed \\(\\widehat{\\text{ATE}}\\) for all 252 and averaged them, we would get exactly \\(-1.3\\).\n\n\nWhat the Researcher Sees. In Rasinski’s actual experiment, the researcher does not observe the potential outcomes table—they only observe the outcomes under the assigned condition.\n\nUsing the randomization from Exercise 8a (respondents 1, 3, 5, 7, 9 assigned to treatment), write out the data table that the researcher would actually observe. Use “?” for unobserved potential outcomes.\nCan the researcher compute the true ATE from this observed data? Why or why not?\nWhat does the researcher compute instead, and why is this a reasonable substitute?\n\n\n\n\nSolution\n\nPart a. With respondents 1, 3, 5, 7, 9 assigned to treatment, the researcher observes:\n\n\n\n\n\n\n\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n?\n1\n1\n1\n\n\n2\n3\n?\n0\n3\n\n\n3\n?\n1\n1\n1\n\n\n4\n3\n?\n0\n3\n\n\n5\n?\n1\n1\n1\n\n\n6\n3\n?\n0\n3\n\n\n7\n?\n1\n1\n1\n\n\n8\n3\n?\n0\n3\n\n\n9\n?\n2\n1\n2\n\n\n10\n3\n?\n0\n3\n\n\n\nFor each respondent, the researcher sees only one potential outcome—the one corresponding to their assigned condition. The other potential outcome is forever unknown.\nPart b. No, the researcher cannot compute the true ATE from this observed data.\nThe true ATE requires knowing all potential outcomes:\n\\[\\text{ATE} = \\frac{1}{N}\\sum_{i=1}^{N} Y_i(1) - \\frac{1}{N}\\sum_{i=1}^{N} Y_i(0)\\]\nBut the researcher is missing \\(Y_i(0)\\) for treated respondents (respondents 1, 3, 5, 7, 9) and \\(Y_i(1)\\) for control respondents (respondents 2, 4, 6, 8, 10). Without these counterfactual outcomes, the true ATE cannot be calculated.\nPart c. The researcher computes the difference-in-means estimator:\n\\[\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\]\nThis is a reasonable substitute because:\n\nIt uses only observable quantities (no counterfactuals needed)\nUnder random assignment, it is unbiased for the true ATE\nThe average of \\(Y_i^{\\text{obs}}\\) among treated individuals estimates what the average of \\(Y_i(1)\\) would be for everyone\nThe average of \\(Y_i^{\\text{obs}}\\) among control individuals estimates what the average of \\(Y_i(0)\\) would be for everyone\n\nRandom assignment ensures that the treated and control groups are, on average, comparable samples from the same population. This allows us to use observed group means as stand-ins for the unobservable population means.\n\n\nInterpreting the Estimate in Context. Using the estimate from Exercise 8a (\\(\\widehat{\\text{ATE}} = -1.8\\)):\n\nWrite a one-sentence interpretation of this estimate in the context of Rasinski’s question-wording experiment. Be sure to explain what the negative sign means substantively.\nA colleague says, “A change of 1.8 points on a 3-point scale is huge!” Is this a fair characterization? What context would help evaluate the magnitude?\n\n\n\n\nSolution\n\nPart a. Based on this experiment, respondents gave answers that were on average 1.8 points lower on the 1-to-3 scale (where 1 = “Too little” and 3 = “Too much”) when asked about “assistance to the poor” compared to “welfare,” indicating that the “assistance to the poor” framing substantially increases expressed support for government spending.\nPart b. The colleague’s characterization captures the right intuition—this is a large effect—but deserves more context:\nWhat makes this effect large:\n\nThe outcome scale only has three categories (1, 2, 3), so the maximum possible effect is 2 points (from “Too much” to “Too little” or vice versa)\nAn effect of 1.8 points is 90% of the maximum possible effect\nMany respondents are shifting by a full category or more based solely on word choice\n\nContext that helps evaluation:\n\nThe treatment is minimal—just changing one phrase in a question. The fact that word choice alone produces such a large shift suggests question wording is extremely consequential for survey results.\nIf this effect generalizes to the broader population, it means public opinion polls could show dramatically different levels of support for the same policy depending on how the question is worded.\nIn political terms, this could mean the difference between a policy appearing popular or unpopular.\n\nSo yes, the effect is substantively large, and the colleague’s reaction is warranted. Changing two words shifts responses by nearly the full width of the scale.\n\n\n\n2.10.4 Critical Thinking\n\nUnbiasedness vs. Accuracy. An estimator can be unbiased but still give estimates that are far from the true value.\n\nHow is this possible? What determines how far individual estimates might be from the truth?\nWhat might make \\(\\widehat{\\text{ATE}}\\) more or less variable across different randomizations?\n\n\n\n\nSolution\n\nPart a. Unbiasedness only guarantees that the estimator is correct on average—it says nothing about any single estimate.\nAn unbiased estimator can produce estimates far from the truth because of sampling variability. Each randomization produces a different assignment of individuals to treatment and control. Some randomizations might, by chance, put individuals with unusually high potential outcomes into the treatment group, leading to overestimates. Other randomizations might do the opposite, leading to underestimates.\nThink of it like flipping a fair coin 10 times. On average, you get 5 heads. But any particular sequence might give you 3 heads, 7 heads, or even 0 heads. The “estimator” (count the heads) is unbiased, but individual realizations vary.\nWhat determines how far individual estimates might be from the truth:\n\nThe variance of the estimator—how spread out the distribution of possible estimates is\nThis variance depends on the sample size, the variability in potential outcomes, and the proportion assigned to treatment vs. control\n\nPart b. Several factors affect how variable \\(\\widehat{\\text{ATE}}\\) is across randomizations:\nFactors that increase variability:\n\nSmaller sample sizes (\\(N\\)): Fewer individuals means each randomization can produce more extreme group compositions\nMore heterogeneous potential outcomes: If individuals differ greatly in their outcomes, the groups can be quite different depending on which individuals land where\nUnbalanced designs: Having very few individuals in one group (e.g., \\(N_t = 2\\) out of \\(N = 100\\)) increases variability because the small group’s mean is very sensitive to which specific individuals are included\n\nFactors that decrease variability:\n\nLarger sample sizes: With many individuals, the law of large numbers kicks in—each group is more likely to be representative of the population\nMore homogeneous potential outcomes: If all individuals have similar outcomes, it matters less which ones end up in which group\nBalanced designs: Having roughly equal numbers in treatment and control (\\(N_t \\approx N_c\\)) tends to minimize variance\n\n\n\nBreaking Unbiasedness. The proof of unbiasedness relies on the fact that \\(E_D[D_i] = N_t/N\\) for all individuals \\(i\\).\n\nGive an example of an assignment mechanism where this would not hold.\nIf we used such a biased assignment mechanism, would \\(\\widehat{\\text{ATE}}\\) still be unbiased? Why or why not?\n\n\n\n\nSolution\n\nPart a. Here are examples of assignment mechanisms where \\(E_D[D_i] = N_t/N\\) would not hold for all individuals:\nExample 1: Selection based on a characteristic\nA researcher assigns older participants to treatment with probability 0.8 and younger participants with probability 0.2. If age is associated with the outcome, \\(E_D[D_i]\\) differs across individuals based on their age.\nExample 2: Self-selection\nParticipants choose whether to receive treatment. Motivated participants might be more likely to choose treatment (\\(E_D[D_i]\\) is higher for motivated people).\nExample 3: Researcher discretion\nA researcher “randomly” assigns treatment but subconsciously tends to assign sicker patients to the new treatment. Sicker patients have higher \\(E_D[D_i]\\).\nExample 4: Sequential assignment with learning\nA researcher stops assigning to treatment once they see a few bad outcomes, making later individuals less likely to be treated.\nPart b. No, \\(\\widehat{\\text{ATE}}\\) would generally not be unbiased under such mechanisms.\nThe proof of unbiasedness relied on a key cancellation: the probability of treatment (\\(E_D[D_i] = N_t/N\\)) canceled with the weighting in the estimator (dividing by \\(N_t\\)). This worked because every individual had the same probability of treatment.\nWhen treatment probabilities vary across individuals, this cancellation breaks down. Individuals with higher probabilities of treatment contribute more to the treatment group mean, and individuals with lower probabilities contribute less. If these probabilities are correlated with potential outcomes, the estimator becomes biased.\nFor example, if high-outcome individuals have higher treatment probabilities:\n\nThe treatment group will be enriched with high-outcome individuals\nThe control group will be enriched with low-outcome individuals\n\\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\) will overestimate the true ATE\n\nThe estimator would be capturing both the treatment effect and the selection effect, leading to bias.\n\n\nSample Size Considerations. Consider two experiments estimating the same ATE. Experiment A has \\(N = 10\\) with \\(N_t = 5\\). Experiment B has \\(N = 1000\\) with \\(N_t = 500\\).\n\nAre both estimates unbiased for the ATE?\nIn which experiment would you expect \\(\\widehat{\\text{ATE}}\\) to be closer to the true ATE? Why?\nWhat property of estimators (besides unbiasedness) captures this difference?\n\n\n\n\nSolution\n\nPart a. Yes, both estimates are unbiased for the ATE.\nUnbiasedness depends only on the randomization procedure, not on the sample size. As long as treatment is randomly assigned (with each individual having equal probability), the estimator is unbiased. This is true whether \\(N = 10\\) or \\(N = 1,000,000\\).\nThe proof of unbiasedness holds for any \\(N &gt; 1\\) with \\(1 &lt; N_t &lt; N\\).\nPart b. We would expect \\(\\widehat{\\text{ATE}}\\) from Experiment B (the larger experiment) to be closer to the true ATE.\nWith only 10 individuals, random chance can produce quite unrepresentative groups. Maybe by luck, 4 of the 5 highest-outcome individuals all end up in treatment, producing a large overestimate. With 1000 individuals, such extreme imbalances are far less likely. The law of large numbers ensures that with more individuals, each group’s mean converges toward the population mean of that potential outcome.\nTo use a simple analogy: if you flip a coin 10 times, getting 8 heads (80%) wouldn’t be surprising. If you flip it 1000 times, getting 800 heads (80%) would be extremely unlikely. Larger samples are more stable.\nPart c. The property that captures this difference is the variance (or equivalently, the standard error) of the estimator.\nBoth estimators are unbiased, but the estimator from the larger experiment has smaller variance—its sampling distribution is more concentrated around the true ATE. We often describe this by saying the larger experiment is more precise or has more efficiency.\nRelated concepts include:\n\nStandard error: The standard deviation of the sampling distribution of \\(\\widehat{\\text{ATE}}\\)\nEfficiency: An estimator with smaller variance is more efficient\nConsistency: As \\(N \\to \\infty\\), the estimator converges to the true value (related to variance shrinking to zero)\n\n\n\n\n2.10.5 R Practice\n\nComputing \\(\\widehat{\\text{ATE}}\\) with mean(). Suppose you have a data frame called experiment with columns treatment (1 = treated, 0 = control) and outcome (a numeric outcome variable).\n\nWrite R code to compute \\(\\overline{Y}^{\\text{obs}}_{t}\\) using logical indexing.\nWrite R code to compute \\(\\overline{Y}^{\\text{obs}}_{c}\\) using logical indexing.\nWrite R code to compute \\(\\widehat{\\text{ATE}}\\) as the difference.\n\n\n\n\nSolution\n\nPart a. To compute \\(\\overline{Y}^{\\text{obs}}_{t}\\), the mean outcome among treated individuals:\nmean_treated &lt;- mean(experiment$outcome[experiment$treatment == 1])\nThis works by:\n\nexperiment$treatment == 1 creates a logical vector that is TRUE for treated individuals\nexperiment$outcome[...] subsets the outcome variable to only those rows\nmean(...) computes the average of the subsetted outcomes\n\nPart b. To compute \\(\\overline{Y}^{\\text{obs}}_{c}\\), the mean outcome among control individuals:\nmean_control &lt;- mean(experiment$outcome[experiment$treatment == 0])\nThe logic is identical, but we select rows where treatment == 0.\nPart c. To compute \\(\\widehat{\\text{ATE}}\\) as the difference:\nate_hat &lt;- mean_treated - mean_control\nOr as a single line without intermediate variables:\nate_hat &lt;- mean(experiment$outcome[experiment$treatment == 1]) -\n           mean(experiment$outcome[experiment$treatment == 0])\n\n\nUnderstanding lm() Output. A researcher fits the model lm(outcome ~ treatment, data = experiment) and gets the following output:\n(Intercept)    treatment\n      4.200        1.350\n\nWhat is the mean outcome in the control group?\nWhat is \\(\\widehat{\\text{ATE}}\\)?\nWhat is the mean outcome in the treatment group?\n\n\n\n\nSolution\n\nPart a. The mean outcome in the control group is 4.200.\nThe intercept represents the predicted outcome when treatment = 0. Since the treatment variable is binary (0 or 1), plugging in 0 gives:\n\\[\\hat{Y} = 4.200 + 1.350 \\times 0 = 4.200\\]\nThis is \\(\\overline{Y}^{\\text{obs}}_{c}\\).\nPart b. The \\(\\widehat{\\text{ATE}}\\) is 1.350.\nThe coefficient on treatment represents how much the predicted outcome changes when treatment goes from 0 to 1. This is exactly the difference in means:\n\\[\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c} = 1.350\\]\nPart c. The mean outcome in the treatment group is 5.550.\nThis is the predicted outcome when treatment = 1:\n\\[\\hat{Y} = 4.200 + 1.350 \\times 1 = 5.550\\]\nThis equals \\(\\overline{Y}^{\\text{obs}}_{c} + \\widehat{\\text{ATE}} = 4.200 + 1.350 = 5.550\\).\nWe can verify: \\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c} = 5.550 - 4.200 = 1.350\\), which matches the coefficient.\n\n\nReference Categories. Explain why we used fct_relevel(desc, \"welfare\") in the R code for the mock Rasinski data. What would happen if we had not done this? Would the \\(\\widehat{\\text{ATE}}\\) computed using mean() and lm() still match?\n\n\n\nSolution\n\nWe used fct_relevel(desc, \"welfare\") to set “welfare” as the reference category for the factor variable.\nWhy this matters for lm():\nWhen lm() encounters a factor variable, it creates dummy (indicator) variables. R uses the first level of the factor as the reference category—the category that gets coded as 0. By default, R orders factor levels alphabetically. Since “assistance to the poor” comes before “welfare” alphabetically, it would be the reference category by default.\nWith “assistance to the poor” as reference:\n\nThe intercept would be the mean for “assistance to the poor” (the treatment group)\nThe coefficient would be the change when moving to “welfare” (the control group)\nThe coefficient would be \\(\\overline{Y}^{\\text{obs}}_{c} - \\overline{Y}^{\\text{obs}}_{t}\\), which is the negative of our usual definition\n\nBy using fct_relevel(desc, \"welfare\"), we make “welfare” the reference:\n\nThe intercept is the mean for “welfare” (control group)\nThe coefficient is the change when moving to “assistance to the poor” (treatment)\nThe coefficient equals \\(\\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\), matching our definition\n\nWould mean() and lm() still match?\nThe magnitudes would still match, but the signs might differ depending on how we set up the calculation:\n\nIf we compute mean() as treatment minus control and lm() uses the alphabetical default, the coefficient would have the opposite sign of our mean() calculation\nThe numerical values would still be correct in absolute value\n\nIn practice, for the two approaches to give the same number (not just the same magnitude), we need to ensure the reference category in lm() matches which group we subtract in the mean() calculation.\n\n\nConnecting mean() and lm(). In your own words, explain why regressing the outcome on a binary treatment indicator produces a coefficient that equals the difference in means. What role does the intercept play in this relationship?\n\n\n\nSolution\n\nWhen we regress outcome on a binary treatment indicator, OLS (ordinary least squares) finds the coefficients that minimize the sum of squared residuals—the differences between observed outcomes and predicted outcomes.\nThe key insight:\nFor a binary predictor, the predictions can only take two values:\n\nWhen \\(D_i = 0\\): \\(\\hat{Y}_i = \\hat{\\beta}_0\\)\nWhen \\(D_i = 1\\): \\(\\hat{Y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1\\)\n\nOLS chooses \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) to make predicted values as close as possible to observed values. The best prediction for a group of observations is their mean (this minimizes squared errors within that group).\nTherefore:\n\n\\(\\hat{\\beta}_0\\) is set to the mean outcome in the control group, because that’s the best prediction for control individuals\n\\(\\hat{\\beta}_0 + \\hat{\\beta}_1\\) is set to the mean outcome in the treatment group, because that’s the best prediction for treated individuals\n\nSolving for the coefficient:\n\\[\\hat{\\beta}_0 = \\overline{Y}^{\\text{obs}}_{c}\\] \\[\\hat{\\beta}_0 + \\hat{\\beta}_1 = \\overline{Y}^{\\text{obs}}_{t}\\]\nSubtracting the first equation from the second:\n\\[\\hat{\\beta}_1 = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\]\nThis is exactly the difference in means—our \\(\\widehat{\\text{ATE}}\\).\nThe role of the intercept:\nThe intercept (\\(\\hat{\\beta}_0\\)) serves as the “baseline”—the predicted outcome for the reference group (control). It anchors the predictions. The coefficient (\\(\\hat{\\beta}_1\\)) then represents how much we add or subtract from this baseline when an individual is treated. This additive structure means the coefficient must equal the difference between the two group means.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Estimating the ATE</span>"
    ]
  },
  {
    "objectID": "ch/var.html",
    "href": "ch/var.html",
    "title": "3  The Variance of \\(\\widehat{\\text{ATE}}\\)",
    "section": "",
    "text": "3.1 The Variance Operator \\(\\text{Var}[\\cdot]\\)\nIn the previous chapter, we showed that the difference-in-means estimator \\(\\widehat{\\text{ATE}} = \\overline{Y}^{\\text{obs}}_{t} - \\overline{Y}^{\\text{obs}}_{c}\\) is an unbiased estimator of the average treatment effect. Unbiasedness tells us that our estimator gets it right on average in the long-run.1\nBut unbiasedness is only part of the story. An estimator can be unbiased yet still produce estimates that are far from the true value in any given experiment. What we need to understand is how much our estimate varies from one randomization to another. We want our procedure to produce an estimate that is right on average AND usually close to the ATE. The variance of the estimator tells us how close the estimate falls to the ATE in the long run.\nIn this chapter, we state the variance formula for \\(\\widehat{\\text{ATE}}\\) under completely randomized experiments and explain what it means. The proof, which involves very tedious algebra (but only tedious algebra), appears in Appendix A.\nUnderstanding this variance formula will help us understand the noisiness of our estimates and think carefully about how to design experiments.\nThe variance operator \\(\\text{Var}[\\cdot]\\) is a way of measuring “how spread out” a random variable is around its average value. The variance of a random variable measures its typical squared distance from the mean.\nRule: Variance is defined as the expected squared deviation from the mean.\nIf \\(X\\) is random, then\n\\[\n\\text{Var}(X) = E\\left[(X - E[X])^2\\right].\n\\]\nNotice the logic. We’re just computing the long-run average of \\((X - E[X])^2\\), which is the squared difference between \\(X\\) and its own long-run average.\nA simulation helps illustrate. Suppose we sample once from the collection -2, -1, 0, 1, 2. This single sample is random—it might be -2, -1, 0, 1, or 2 with equal probability.\n# a collection of numbers (that we'll sample from below)\ncollection &lt;- c(-2, -1, 0, 1, 2)\n\n# take one sample from the collection\nsample(collection, size = 1)\n\n[1] -1\nWhat’s the variance of this sample?\nWe can take 100,000 samples x from this collection and compute mean((x - mean(x))^2). In this case, 100,000 is long enough approximate the “long run.”\n# take and store many (approximating long-run) samples from the collection (with replacement)\nx &lt;- sample(collection, size = 100000, replace = TRUE)\n\n# compute variance in several steps \navg &lt;- mean(x)\nsq_dev &lt;- (x - avg)^2\nmean(sq_dev)  # avg squared deviation\n\n[1] 2.00787\n\n# compute in one step\nmean((x - mean(x))^2)\n\n[1] 2.00787",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Variance of $\\widehat{\\text{ATE}}$</span>"
    ]
  },
  {
    "objectID": "ch/var.html#the-variance-operator-textvarcdot",
    "href": "ch/var.html#the-variance-operator-textvarcdot",
    "title": "3  The Variance of \\(\\widehat{\\text{ATE}}\\)",
    "section": "",
    "text": "It also turns out that\n\\[\n\\text{Var}(X) = E\\left[X^2 \\right] - \\left(E[X]\\right)^2,\n\\]\nwhich can be a little easier to work with, but is somewhat harder to conceptualize.\n\n\n\n\n\n\n\n\n\n\n\nWe don’t need a computer to find this, though!\n\n\n\n\n\nWe don’t need a computer to approximate the variance; we can use our knowledge of expected values to find it exactly. We can compute it most easily using the definition \\(\\text{Var}(X) = E\\left[X^2 \\right] - \\left(E[X]\\right)^2\\) mentioned in the aside above.\nLet \\(X\\) be a random variable that takes values in \\(\\{-2,-1,0,1,2\\}\\) with equal probability \\(1/5\\). This is what the code is doing when it samples x.\nWe need to compute both \\(E\\left[X^2 \\right]\\) and \\(\\left(E[X]\\right)^2\\). Let’s start with the second, because it’s easier.\nFirst compute \\(E[X]\\). This is easy.\n\\[\nE[X] = \\frac{1}{5}(-2 - 1 + 0 + 1 + 2) = 0.\n\\]\nSince \\(E[X] = 0\\), \\(E[X]^2 = 0\\) and the second term on the right-hand side drops out.\nNext, compute \\(E\\left[X^2 \\right]\\).\n\\[\nE[X^2]\n= \\frac{1}{5}\\left( (-2)^2 + (-1)^2 + 0^2 + 1^2 + 2^2 \\right)\n= \\frac{10}{5}\n= 2.\n\\]\nTherefore, \\[\n\\text{Var}(X) = E\\left[X^2 \\right] - \\left(E[X]\\right)^2 = 2 - 0 = 2.\n\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Variance of $\\widehat{\\text{ATE}}$</span>"
    ]
  },
  {
    "objectID": "ch/var.html#the-main-theorem",
    "href": "ch/var.html#the-main-theorem",
    "title": "3  The Variance of \\(\\widehat{\\text{ATE}}\\)",
    "section": "3.2 The Main Theorem",
    "text": "3.2 The Main Theorem\nNow that we understand how variance measures the spread of a random variable, we can state the variance of our estimator \\(\\widehat{\\text{ATE}}\\). Remember, because we are choosing to randomly assign participants to treatment and control, our procedure produces a random estimate.\n\n\n\n\n\n\nTheorem: Variance of the Difference-in-Means Estimator\n\n\n\nUnder completely randomized assignment, the variance of \\(\\widehat{\\text{ATE}}\\) is\n\\[\n\\text{Var}_D \\left(\\widehat{\\text{ATE}}\\right) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} - \\frac{S_{tc}^2}{N},\n\\]\nwhere \\(S_t^2\\) is defined as\n\\[\nS_t^2 = \\frac{1}{N - 1} \\sum_{i=1}^{N} (Y_i(1) - \\overline{Y}(1))^2 \\quad \\text{and},\n\\]\n\\(S_c^2\\) is defined as\n\\[\nS_c^2 = \\frac{1}{N - 1} \\sum_{i=1}^{N} (Y_i(0) - \\overline{Y}(0))^2,\n\\]\nand \\(S_{tc}^2\\) is defined as\n\\[\nS_{tc}^2 = \\frac{1}{N - 1} \\sum_{i=1}^{N} \\left(\\tau_i - \\text{ATE}\\right)^2.\n\\]\n\n\n\n\nSomewhat (or perhaps very) confusingly, \\(S_t^2\\), \\(S_c^2\\), and \\(S_{tc}^2\\) are also called “variance.” We use the variance \\(\\text{Var}(X) = E\\left[(X - E[X])^2\\right]\\) to describe the spread of random numbers (like noisy estimates) and the variances \\(S_t^2\\), \\(S_c^2\\), and \\(S_{tc}^2\\) to describe the spread of a fixed collection of numbers (like potential outcomes under treatment). Statisticians sometimes call the latter finite population variances to distinguish them.\n\n\n\n\n\n\nOn the \\(1/(N-1)\\) Convention\n\n\n\n\n\nYou may notice that \\(S_t^2\\), \\(S_c^2\\), and \\(S_{tc}^2\\) are defined with \\(1/(N-1)\\) in the denominator rather than \\(1/N\\). This follows the convention used by Cochran (1977) and later adopted by Imbens and Rubin (2015).\nThis choice differs from the arguably more “elementary” variance\n\\[\nV_N = \\frac{1}{N} \\sum_{i=1}^N (x_i - \\bar{x})^2,\n\\]\nwhich is often introduced in introductory texts and interpretable as the average squared deviation from the mean.\nThe \\(1/(N-1)\\) convention has a key advantage: it aligns the definition of the population variance with the sample variance estimator, so that sample variances are unbiased estimators of population variances. This simplifies the algebra of variance estimation in randomized experiments. While readers accustomed to the \\(1/N\\) normalization may find this convention unfamiliar, for design-based inference—where randomness arises from treatment assignment—the \\(1/(N-1)\\) normalization offers conceptual and algebraic advantages.\n\n\n\nLet’s unpack this formula.\n\n3.2.1 Understanding the Variance Formula\nBefore interpreting the formula, let’s understand what each quantity measures. \\(S_t^2\\) measures how spread out the potential outcomes under treatment are across individuals. \\(S_c^2\\) measures the same for control. And \\(S_{tc}^2\\) measures how spread out the individual treatment effects are—that is, how much the treatment effect varies from person to person.\nThe variance formula has three terms.\nTerm 1: \\(\\frac{S_t^2}{N_t}\\) This is the variance of the treatment group mean. If potential outcomes under treatment vary a lot across individuals (large \\(S_t^2\\)), our estimate of the treatment group mean will be more variable. Dividing by \\(N_t\\) reflects that larger treatment groups give us more precise estimates.\nTerm 2: \\(\\frac{S_c^2}{N_c}\\) Similarly, this is the variance of the control group mean. More variability in control potential outcomes or fewer control individuals increases variance.\nTerm 3: \\(-\\frac{S_{tc}^2}{N}\\) This is the interesting (and difficult) term. Importantly, it shrinks the variance. The quantity \\(S_{tc}^2\\) measures how variable the individual treatment effects are. If everyone has the same treatment effect (constant effects), then \\(S_{tc}^2 = 0\\) and this term disappears.\n\n\n3.2.2 The Special Case of Constant Treatment Effects\nWhen treatment effects are constant (every individual experiences the same effect \\(\\tau\\)), we have \\(\\tau_i = \\tau\\) for all \\(i\\). In this case, something remarkable happens: \\(S_{tc}^2 = 0\\). In this case, the variance simplifies to\n\\[\n\\text{Var}_D \\left(\\widehat{\\text{ATE}}\\right) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c}.\n\\]\n\n\nMoreover, when effects are constant, \\(S_t^2 = S_c^2 = S^2\\) (the variance of potential outcomes is the same under treatment and control), so\n\\[\n\\text{Var}_D \\left(\\widehat{\\text{ATE}}\\right) = S^2 \\left(\\frac{1}{N_t} + \\frac{1}{N_c}\\right).\n\\]\nThis is the familiar variance formula you might have seen in an introductory statistics course for the difference of two means.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Variance of $\\widehat{\\text{ATE}}$</span>"
    ]
  },
  {
    "objectID": "ch/var.html#intuition",
    "href": "ch/var.html#intuition",
    "title": "3  The Variance of \\(\\widehat{\\text{ATE}}\\)",
    "section": "3.3 Intuition",
    "text": "3.3 Intuition\nThe algebraic proof of the variance formula is long, but the intuition of the result is straightforward.\nThe variance of \\(\\widehat{\\text{ATE}}\\) reflects how much our estimate would change if we repeated the same experiment many times.2\n2 Remember all that changes across these many repetitions is who is assigned to treatment and control. Every randomization produces a slightly different treatment group and a slightly different control group, and therefore a slightly different estimate of the ATE.\n3.3.1 Two Obvious Sources of Variation\nThere are two obvious reasons why \\(\\widehat{\\text{ATE}}\\) varies across repetitions.\n\nRandomness in the treatment-group mean. Different randomizations place different individuals into the treatment group. Since individuals have different potential outcomes under treatment, the treatment-group mean \\(\\overline{Y}^{\\text{obs}}_t\\) will not be exactly the same every time. The amount it varies depends on the spread of the potential outcomes (\\(S_t^2\\)) and the number of individuals assigned to treatment (\\(N_t\\)). This produces the term \\(\\frac{S_t^2}{N_t}\\).\nRandomness in the control-group mean. The same logic applies to the control group. Different randomizations create different control groups, so the control-group mean also varies in the same way as the treatment group.\n\nIf these two sources of variation were unrelated, the variance of \\(\\widehat{\\text{ATE}}\\) would simply be the sum of these two terms. However, they are not unrelated. They are related in a subtle, interesting, and important way.\n\n\n3.3.2 Why the Third Term Matters\nEach individual can be in only one group. If someone is assigned to treatment, they cannot be assigned to control. This creates a link between the two group means.\nTo understand why this matters, focus on an individual with an unusually large treatment effect. For this person, the difference between their treated outcome \\(Y_i(1)\\) and their control outcome \\(Y_i(0)\\) is especially large.3\n3 To make this even more concrete, we might imagine this person’s potential outcomes are among the largest under treatment and among the smallest under control.Now consider what happens when this individual is assigned to the treatment group. Their treated outcome \\(Y_i(1)\\) is relatively high, so their presence pushes the treatment-group mean upward.\nBut assigning them to treatment also means they are missing from the control group. Because their treatment effect is unusually large, their control outcome \\(Y_i(0)\\) is relatively low. Had they been assigned to control, their low outcome would have pulled the mean of the control-group downward. Since they are not in the control group, that downward pull doesn’t happen.\nAs a result, two things happen.\n\nThe treatment-group mean is higher than usual, because this individual is included.\nThe control-group mean is also higher than usual, because this individual is missing.\n\nThese effects partially cancel out when we take the difference between the treatment and control group.\nThis stabilizing effect comes specifically from individuals with unusually large (or unusually small) treatment effects. Individuals with “typical” treatment effects do not create this cancelling dynamic. The more treatment effects vary across people, the stronger this stabilizing effect becomes. That variation is exactly what \\(S_{tc}^2\\) measures.\nThis is why the variance formula includes the negative term \\(-\\frac{S_{tc}^2}{N}\\).\nAnd then, if treatment effects are constant, then no one has unusually large (or unusually small) treatment effect and the cancelling dynamic is absent.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Variance of $\\widehat{\\text{ATE}}$</span>"
    ]
  },
  {
    "objectID": "ch/var.html#numerical-illustration",
    "href": "ch/var.html#numerical-illustration",
    "title": "3  The Variance of \\(\\widehat{\\text{ATE}}\\)",
    "section": "3.4 Numerical Illustration",
    "text": "3.4 Numerical Illustration\nLet’s verify the variance formula with a simulation. We’ll create a small population of 10 individuals with known potential outcomes, compute the theoretical variance using the formula, and then simulate 1,000 randomizations to see if the simulated variance matches.\n\n3.4.1 Step 1: Create the Potential Outcomes\nFirst, we create potential outcomes for 10 individuals. We’ll use the same hypothetical data from the previous chapters.\n\n# load packages\nlibrary(tidyverse)\n\n# create potential outcomes for 10 individuals\npo &lt;- tibble(\n  i = 1:10,\n  Y0 = c(4, 6, 5, 3, 7, 5, 4, 6, 5, 4),  # potential outcome under control\n  Y1 = c(7, 5, 5, 9, 10, 4, 8, 7, 3, 6)  # potential outcome under treatment\n)\n\n# compute individual treatment effects\npo &lt;- po |&gt;\n  mutate(tau = Y1 - Y0)\n\n# view the data\npo\n\n# A tibble: 10 × 4\n       i    Y0    Y1   tau\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1     4     7     3\n 2     2     6     5    -1\n 3     3     5     5     0\n 4     4     3     9     6\n 5     5     7    10     3\n 6     6     5     4    -1\n 7     7     4     8     4\n 8     8     6     7     1\n 9     9     5     3    -2\n10    10     4     6     2\n\n\n\n\n3.4.2 Step 2: Compute the True ATE and Variance Components\nNow we compute the quantities we need for the variance formula.\n\n# sample size and group sizes\nN &lt;- 10\nN_t &lt;- 5\nN_c &lt;- 5\n\n# compute means of potential outcomes\nY1_bar &lt;- mean(po$Y1)\nY0_bar &lt;- mean(po$Y0)\n\n# compute the true ATE\nATE &lt;- Y1_bar - Y0_bar\nATE\n\n[1] 1.5\n\n\nNext, we compute \\(S_t^2\\), \\(S_c^2\\), and \\(S_{tc}^2\\).\n\n# variance of Y(1)\nS_t_sq &lt;- var(po$Y1)\nS_t_sq\n\n[1] 4.933333\n\n# variance of Y(0)\nS_c_sq &lt;- var(po$Y0)\nS_c_sq\n\n[1] 1.433333\n\n# variance of treatment effects\nS_tc_sq &lt;- var(po$tau)\nS_tc_sq\n\n[1] 6.5\n\n\n\n\n3.4.3 Step 3: Compute the Theoretical Variance\nUsing the variance formula, we compute the theoretical variance of \\(\\widehat{\\text{ATE}}\\).\n\n# theoretical variance using the formula\ntheoretical_var &lt;- S_t_sq / N_t + S_c_sq / N_c - S_tc_sq / N\ntheoretical_var\n\n[1] 0.6233333\n\n\n\n\n3.4.4 Step 4: Simulate Many Randomizations\nNow we simulate 1,000 randomizations and compute \\(\\widehat{\\text{ATE}}\\) for each one. We use a simple for-loop to make the logic clear.\n\n# set seed for reproducibility\nset.seed(1234)\n\n# number of simulations\nn_sims &lt;- 1000\n\n# create a vector to store the estimates\nate_estimates &lt;- numeric(n_sims)\n\n# run the simulation\nfor (sim in 1:n_sims) {\n\n # randomly assign 5 individuals to treatment\n  treated &lt;- sample(1:N, size = N_t, replace = FALSE)\n\n  # compute observed outcomes\n  Y_obs_t &lt;- po$Y1[treated]       # treated individuals show Y(1)\n  Y_obs_c &lt;- po$Y0[-treated]      # control individuals show Y(0)\n\n  # compute the estimate for this randomization\n  ate_estimates[sim] &lt;- mean(Y_obs_t) - mean(Y_obs_c)\n}\n\n\n\n3.4.5 Step 5: Compare Theoretical and Simulated Variance\nFinally, we compare the theoretical variance to the variance of our simulated estimates.\n\n# simulated variance\nsimulated_var &lt;- var(ate_estimates)\n\n# compare the two\ntibble(\n  theoretical_variance = theoretical_var,\n  simulated_variance = simulated_var,\n)\n\n# A tibble: 1 × 2\n  theoretical_variance simulated_variance\n                 &lt;dbl&gt;              &lt;dbl&gt;\n1                0.623              0.552\n\n\nThe simulated variance is very close to the theoretical variance. The small difference is due to simulation error. With more simulations, the two values would converge.\n\n\nWe can also visualize the distribution of estimates.\n\nggplot(tibble(ate = ate_estimates), aes(x = ate)) +\n  geom_histogram(binwidth = 0.25, fill = \"grey80\") +\n  geom_vline(xintercept = ATE) +\n  theme_minimal()\n\n\n\n\nDistribution of \\(\\widehat{\\text{ATE}}\\) across 1,000 randomizations. The vertical dashed line shows the true ATE. The histogram shows that the estimates are centered around the true ATE (confirming unbiasedness) and spread out according to the variance we computed. Some randomizations produce estimates close to the true ATE, while others are further away. But on average, we get it right.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Variance of $\\widehat{\\text{ATE}}$</span>"
    ]
  },
  {
    "objectID": "ch/var.html#key-terms",
    "href": "ch/var.html#key-terms",
    "title": "3  The Variance of \\(\\widehat{\\text{ATE}}\\)",
    "section": "3.5 Key Terms",
    "text": "3.5 Key Terms\n\nVariance operator (\\(\\text{Var}[\\cdot]\\))\nVariance of an estimator\nFinite population variance\nVariance of potential outcomes (\\(S_t^2\\), \\(S_c^2\\))\nVariance of treatment effects (\\(S_{tc}^2\\))\nHeterogeneous treatment effects",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Variance of $\\widehat{\\text{ATE}}$</span>"
    ]
  },
  {
    "objectID": "ch/var.html#exercises",
    "href": "ch/var.html#exercises",
    "title": "3  The Variance of \\(\\widehat{\\text{ATE}}\\)",
    "section": "3.6 Exercises",
    "text": "3.6 Exercises\n\n3.6.1 Conceptual Understanding\n\nVariance vs. Bias. In your own words, explain the difference between an estimator being unbiased and an estimator having low variance. Can an estimator be unbiased but still give poor estimates in practice?\n\n\n\nSolution\n\nUnbiasedness means that the estimator is correct on average. If we could repeat the experiment many times with different randomizations, the average of all our estimates would equal the true ATE. But any single estimate might be far from the truth.\nLow variance means that the estimates are tightly clustered around their average value. Different randomizations produce similar estimates.\nYes, an estimator can be unbiased but still give poor estimates in practice. Imagine an estimator that, across many randomizations, produces estimates of \\(-100\\) half the time and \\(+102\\) half the time (when the true ATE is 1). This estimator is unbiased (the average is 1), but any single estimate is wildly wrong.\nIn practice, we want both properties: an estimator that is unbiased and has low variance. The ideal estimator hits close to the target on average (unbiased) and doesn’t scatter too much around that average (low variance).\n\n\nThe Three Terms. The variance formula has three terms: \\(S_t^2/N_t\\), \\(S_c^2/N_c\\), and \\(-S_{tc}^2/N\\). Explain in plain language what each term represents and why the third term is negative.\n\n\n\nSolution\n\nFirst term (\\(S_t^2/N_t\\)): This represents the uncertainty in estimating the average treatment group outcome. \\(S_t^2\\) measures how much the potential outcomes under treatment vary across individuals. When there’s more variation, the particular individuals who happen to land in the treatment group could have very different outcomes from another randomization. Dividing by \\(N_t\\) reflects that larger treatment groups give more stable estimates.\nSecond term (\\(S_c^2/N_c\\)): Similarly, this represents the uncertainty in estimating the average control group outcome. It depends on how variable the control potential outcomes are and how many individuals are in the control group.\nThird term (\\(-S_{tc}^2/N\\)): This term reduces the variance, which seems surprising at first. Here \\(S_{tc}^2\\) is the variance of the individual-level treatment effects \\(\\tau_i = Y_i(1) - Y_i(0)\\). It measures how much treatment effects vary across individuals. Formally,\n\\[\nS_{tc}^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} (\\tau_i - \\text{ATE})^2.\n\\]\nThe third term captures the fact that treatment and control group assignments are not independent. They are negatively correlated. If one individual goes to treatment, another must go to control.\nThe negative sign arises because treatment and control assignments are linked. When a high-treatment-effect individual is assigned to treatment, they are necessarily missing from control. This creates a stabilizing dynamic: the treatment mean goes up (because they have high \\(Y(1)\\)), but so does the control mean (because their low \\(Y(0)\\) is absent). The difference between the means is more stable than either mean alone. This stabilizing effect is stronger when treatment effects are more heterogeneous (larger \\(S_{tc}^2\\)). When treatment effects are constant (\\(S_{tc}^2 = 0\\)), this stabilizing effect disappears entirely.\n\n\nConstant Treatment Effects. Suppose the treatment effect is the same for every individual (\\(\\tau_i = \\tau\\) for all \\(i\\)). Explain what happens to \\(S_{tc}^2\\). What does the variance formula simplify to?\n\n\n\nSolution\n\nIf the treatment effect is constant, meaning \\(\\tau_i = \\tau\\) for all individuals, then every individual’s treatment effect equals the ATE. The deviations \\(\\tau_i - \\text{ATE}\\) are all zero, so\n\\[\nS_{tc}^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} (\\tau_i - \\text{ATE})^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} 0 = 0.\n\\]\nThe variance formula simplifies to\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c}.\n\\]\nMoreover, when treatment effects are constant, the variance of potential outcomes under treatment equals the variance under control: \\(S_t^2 = S_c^2 = S^2\\). This is because \\(Y_i(1) = Y_i(0) + \\tau\\), so both sets of potential outcomes are just shifted versions of each other, with the same spread.\nIn this case, the formula further simplifies to\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = S^2 \\left(\\frac{1}{N_t} + \\frac{1}{N_c}\\right),\n\\]\nwhich is the familiar formula for the variance of a difference of two sample means.\n\n\n\n3.6.2 Computational Practice\n\nComputing \\(S_t^2\\), \\(S_c^2\\), and \\(S_{tc}^2\\). Consider the following potential outcomes for 4 individuals.\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n2\n5\n\n\n2\n4\n6\n\n\n3\n3\n4\n\n\n4\n5\n7\n\n\n\n\nCompute \\(\\overline{Y}(0)\\) and \\(\\overline{Y}(1)\\).\nCompute \\(S_c^2\\), the variance of \\(Y_i(0)\\).\nCompute \\(S_t^2\\), the variance of \\(Y_i(1)\\).\nCompute the individual treatment effects \\(\\tau_i\\) and the ATE.\nCompute \\(S_{tc}^2\\), the variance of the treatment effects.\n\n\n\n\nSolution\n\nPart a. The means of the potential outcomes are\n\\[\n\\begin{align}\n\\overline{Y}(0) &= \\frac{1}{4}(2 + 4 + 3 + 5) = \\frac{14}{4} = 3.5 \\\\\n\\overline{Y}(1) &= \\frac{1}{4}(5 + 6 + 4 + 7) = \\frac{22}{4} = 5.5\n\\end{align}\n\\]\nPart b. To compute \\(S_c^2\\), we first find the squared deviations from the mean \\(\\overline{Y}(0) = 3.5\\).\n\n\n\n\n\n\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(0) - \\overline{Y}(0)\\)\n\\((Y_i(0) - \\overline{Y}(0))^2\\)\n\n\n\n\n1\n2\n\\(-1.5\\)\n\\(2.25\\)\n\n\n2\n4\n\\(0.5\\)\n\\(0.25\\)\n\n\n3\n3\n\\(-0.5\\)\n\\(0.25\\)\n\n\n4\n5\n\\(1.5\\)\n\\(2.25\\)\n\n\n\n\\[\nS_c^2 = \\frac{1}{4-1}(2.25 + 0.25 + 0.25 + 2.25) = \\frac{5}{3} \\approx 1.67\n\\]\nPart c. Similarly, for \\(S_t^2\\) using \\(\\overline{Y}(1) = 5.5\\).\n\n\n\n\n\n\n\n\n\nIndividual\n\\(Y_i(1)\\)\n\\(Y_i(1) - \\overline{Y}(1)\\)\n\\((Y_i(1) - \\overline{Y}(1))^2\\)\n\n\n\n\n1\n5\n\\(-0.5\\)\n\\(0.25\\)\n\n\n2\n6\n\\(0.5\\)\n\\(0.25\\)\n\n\n3\n4\n\\(-1.5\\)\n\\(2.25\\)\n\n\n4\n7\n\\(1.5\\)\n\\(2.25\\)\n\n\n\n\\[\nS_t^2 = \\frac{1}{3}(0.25 + 0.25 + 2.25 + 2.25) = \\frac{5}{3} \\approx 1.67\n\\]\nPart d. The individual treatment effects are shown in the following table.\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i = Y_i(1) - Y_i(0)\\)\n\n\n\n\n1\n2\n5\n3\n\n\n2\n4\n6\n2\n\n\n3\n3\n4\n1\n\n\n4\n5\n7\n2\n\n\n\n\\[\n\\text{ATE} = \\frac{1}{4}(3 + 2 + 1 + 2) = \\frac{8}{4} = 2\n\\]\nPart e. For \\(S_{tc}^2\\), we compute deviations from \\(\\text{ATE} = 2\\).\n\n\n\n\n\n\n\n\n\nIndividual\n\\(\\tau_i\\)\n\\(\\tau_i - \\text{ATE}\\)\n\\((\\tau_i - \\text{ATE})^2\\)\n\n\n\n\n1\n3\n1\n1\n\n\n2\n2\n0\n0\n\n\n3\n1\n\\(-1\\)\n1\n\n\n4\n2\n0\n0\n\n\n\n\\[\nS_{tc}^2 = \\frac{1}{3}(1 + 0 + 1 + 0) = \\frac{2}{3} \\approx 0.67\n\\]\n\n\nComputing the Variance. Using the values you computed in Exercise 4, suppose we conduct an experiment with \\(N_t = 2\\) and \\(N_c = 2\\).\n\nCompute the variance of \\(\\widehat{\\text{ATE}}\\) using the formula.\nIn Exercise 7 of the previous chapter, you computed \\(\\widehat{\\text{ATE}}\\) for all 6 possible randomizations. Verify that the variance of those 6 estimates matches your answer to part (a).\n\n\n\n\nSolution\n\nPart a. Using the variance formula with \\(N = 4\\), \\(N_t = 2\\), \\(N_c = 2\\), we have\n\\[\n\\begin{align}\n\\text{Var}_D(\\widehat{\\text{ATE}}) &= \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} - \\frac{S_{tc}^2}{N} \\\\\n&= \\frac{5/3}{2} + \\frac{5/3}{2} - \\frac{2/3}{4} \\\\\n&= \\frac{5}{6} + \\frac{5}{6} - \\frac{2}{12} \\\\\n&= \\frac{10}{6} - \\frac{1}{6} \\\\\n&= \\frac{9}{6} = 1.5\n\\end{align}\n\\]\nPart b. From Exercise 7 of the previous chapter, the 6 possible estimates were as follows.\n\n\n\nRandomization\n\\(\\widehat{\\text{ATE}}\\)\n\n\n\n\n1, 2 treated\n1.5\n\n\n1, 3 treated\n0\n\n\n1, 4 treated\n2.5\n\n\n2, 3 treated\n1.5\n\n\n2, 4 treated\n4\n\n\n3, 4 treated\n2.5\n\n\n\nThe mean of these estimates is \\(\\frac{1.5 + 0 + 2.5 + 1.5 + 4 + 2.5}{6} = \\frac{12}{6} = 2\\), which equals the true ATE (confirming unbiasedness).\nThe variance is\n\\[\n\\begin{align}\n\\text{Var} &= \\frac{1}{6}\\left[(1.5-2)^2 + (0-2)^2 + (2.5-2)^2 + (1.5-2)^2 + (4-2)^2 + (2.5-2)^2\\right] \\\\\n&= \\frac{1}{6}\\left[0.25 + 4 + 0.25 + 0.25 + 4 + 0.25\\right] \\\\\n&= \\frac{9}{6} = 1.5\n\\end{align}\n\\]\nThis matches our answer from part (a).\n\n\n\n3.6.3 Application to Rasinski’s Experiment\n\nVariance in the Rasinski Context. Return to the hypothetical Rasinski data from the previous chapters.\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\n\n\n\n1\n3\n1\n\n\n2\n3\n2\n\n\n3\n2\n1\n\n\n4\n3\n1\n\n\n5\n2\n1\n\n\n6\n3\n2\n\n\n7\n2\n1\n\n\n8\n3\n1\n\n\n9\n2\n2\n\n\n10\n3\n1\n\n\n\n\nUse R to compute \\(S_c^2\\), \\(S_t^2\\), and \\(S_{tc}^2\\) for this population.\nSuppose we run an experiment with \\(N_t = 5\\) and \\(N_c = 5\\). Use R to compute the variance of \\(\\widehat{\\text{ATE}}\\).\nHow would the variance change if we instead used \\(N_t = 3\\) and \\(N_c = 7\\)?\n\n\n\n\nSolution\n\nPart a. First, we create the data and compute the variance components using R.\n# create the potential outcomes\nY0 &lt;- c(3, 3, 2, 3, 2, 3, 2, 3, 2, 3)\nY1 &lt;- c(1, 2, 1, 1, 1, 2, 1, 1, 2, 1)\ntau &lt;- Y1 - Y0\n\n# compute the variances\nS_c_sq &lt;- var(Y0)\nS_t_sq &lt;- var(Y1)\nS_tc_sq &lt;- var(tau)\n\n# display the results\nS_c_sq   # approximately 0.267\nS_t_sq   # approximately 0.233\nS_tc_sq  # approximately 0.456\nPart b. With \\(N = 10\\), \\(N_t = 5\\), \\(N_c = 5\\), we compute the variance using the formula.\nN &lt;- 10\nN_t &lt;- 5\nN_c &lt;- 5\n\n# compute variance using the formula\nvariance_balanced &lt;- S_t_sq / N_t + S_c_sq / N_c - S_tc_sq / N\nvariance_balanced  # approximately 0.0544\nPart c. With \\(N_t = 3\\) and \\(N_c = 7\\), we have\nN_t &lt;- 3\nN_c &lt;- 7\n\n# compute variance with unbalanced design\nvariance_unbalanced &lt;- S_t_sq / N_t + S_c_sq / N_c - S_tc_sq / N\nvariance_unbalanced  # approximately 0.0703\nThe variance is higher (0.0703 vs. 0.0544) with the unbalanced design. Balanced designs (\\(N_t = N_c\\)) generally minimize variance for a given total sample size.\n\n\nInterpreting the Variance. Based on your calculations in Exercise 6, answer the following.\n\nThe standard deviation is the square root of the variance. The variance with the balanced design (\\(N_t = N_c = 5\\)) is about 0.055. What is the standard deviation of \\(\\widehat{\\text{ATE}}\\)?\nIf the true ATE is \\(-1.3\\), and the standard deviation is about 0.24, roughly what range of estimates would you expect to see across different randomizations? (Hint: remember the normal table.)\nHow does this compare to the estimates we computed in the previous chapter (one randomization gave \\(-1.8\\), another gave \\(-0.8\\))?\n\n\n\n\nSolution\n\nPart a. The standard deviation is the square root of the variance.\n\\[\n\\text{SD}(\\widehat{\\text{ATE}}) = \\sqrt{0.0544} \\approx 0.233\n\\]\nPart b. A common rule of thumb is that most estimates (roughly 95%) fall within about 2 standard deviations of the mean. With the true ATE of \\(-1.3\\) and standard deviation of about 0.24, we can compute the following.\n\nMost estimates would fall between \\(-1.3 - 2(0.24) = -1.78\\) and \\(-1.3 + 2(0.24) = -0.82\\)\nThe typical estimate would be within about 0.24 units of the true value\n\nPart c. In the previous chapter, we computed the following estimates.\n\nOne randomization: \\(\\widehat{\\text{ATE}} = -1.8\\) (deviation of \\(-0.5\\) from truth)\nAnother randomization: \\(\\widehat{\\text{ATE}} = -0.8\\) (deviation of \\(+0.5\\) from truth)\n\nBoth of these estimates fall within 2 standard deviations of the true ATE, which is exactly what we’d expect. The estimate of \\(-1.8\\) is about 2 standard deviations below the true value, and \\(-0.8\\) is about 2 standard deviations above. These are at the edges of the typical range but not implausible.\nThis illustrates how the variance formula helps us understand and calibrate our expectations for how far estimates might be from the truth.\n\n\n\n3.6.4 Critical Thinking\n\nThe Negative Term. A colleague claims, “More heterogeneous treatment effects lead to higher variance in our estimates.” Based on the variance formula, explain why this claim needs to be stated more carefully.\n\n\n\nSolution\n\nThe colleague’s claim is not quite right. The variance formula is given by\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} - \\frac{S_{tc}^2}{N}.\n\\]\nMore heterogeneous treatment effects means larger \\(S_{tc}^2\\). But \\(S_{tc}^2\\) enters with a negative sign! So increasing \\(S_{tc}^2\\) actually decreases the variance, all else equal.\nHowever, “all else equal” is the key caveat. Treatment effect heterogeneity is linked to the variances of potential outcomes. Specifically, we have\n\\[\nS_{tc}^2 = S_t^2 + S_c^2 - 2\\text{Cov}(Y_i(1), Y_i(0))\n\\]\nIf treatment effects become more heterogeneous because the potential outcomes become more variable (larger \\(S_t^2\\) and \\(S_c^2\\)), the first two terms of the variance formula increase, which could outweigh the reduction from the third term.\nA more careful statement would be the following. “Holding the variances of potential outcomes fixed, more heterogeneous treatment effects lead to lower variance in our estimates, because of the negative term in the variance formula. But if treatment effect heterogeneity arises because potential outcomes themselves are more variable, the net effect on variance is ambiguous.”\n\n\nDesign Choices. Suppose you are designing an experiment with a fixed budget that allows you to include \\(N = 100\\) individuals. You can choose how many to assign to treatment (\\(N_t\\)) and how many to control (\\(N_c = 100 - N_t\\)).\n\nIf you knew that \\(S_t^2 = S_c^2\\), what allocation would minimize variance?\nIf you knew that \\(S_t^2 = 4\\) and \\(S_c^2 = 1\\), would you still use the same allocation? Why or why not?\nIn practice, you don’t know \\(S_t^2\\) and \\(S_c^2\\) before running the experiment. What allocation would you recommend, and why?\n\n\n\n\nSolution\n\nPart a. If \\(S_t^2 = S_c^2 = S^2\\), the variance (ignoring the \\(S_{tc}^2\\) term for simplicity) is\n\\[\n\\text{Var} \\approx S^2 \\left(\\frac{1}{N_t} + \\frac{1}{N_c}\\right) = S^2 \\left(\\frac{1}{N_t} + \\frac{1}{100 - N_t}\\right)\n\\]\nTaking the derivative with respect to \\(N_t\\) and setting it to zero:\n\\[\n\\frac{d}{dN_t}\\left(\\frac{1}{N_t} + \\frac{1}{100 - N_t}\\right) = -\\frac{1}{N_t^2} + \\frac{1}{(100-N_t)^2} = 0\n\\]\nThis gives \\(N_t = 100 - N_t\\), so \\(N_t = 50\\). A balanced design minimizes variance when variances are equal.\nPart b. If \\(S_t^2 = 4\\) and \\(S_c^2 = 1\\), we would want to allocate more individuals to the group with higher variance (treatment). The optimal allocation satisfies:\n\\[\n\\frac{N_t}{N_c} = \\sqrt{\\frac{S_t^2}{S_c^2}} = \\sqrt{\\frac{4}{1}} = 2\n\\]\nSo we’d want \\(N_t = 2 N_c\\), which with \\(N = 100\\) gives \\(N_t \\approx 67\\) and \\(N_c \\approx 33\\).\nThe intuition is that we need more observations from the noisier group to get the same precision in estimating that group’s mean.\nPart c. In practice, I would recommend a balanced design (\\(N_t = N_c = 50\\)) for several reasons.\n\nRobustness. Without knowing the true variances, a balanced design is a safe choice that performs well across many scenarios.\nNear-optimal. Even when variances differ, the balanced design is often close to optimal unless the variance ratio is extreme.\nSimplicity. A balanced design is easier to implement and explain.\n\nIf there’s strong prior information suggesting very different variances, one could consider an unbalanced design, but for most applications a 50-50 split is a sensible default.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>The Variance of $\\widehat{\\text{ATE}}$</span>"
    ]
  },
  {
    "objectID": "ch/var-est.html",
    "href": "ch/var-est.html",
    "title": "4  Estimating the Variance",
    "section": "",
    "text": "4.1 The Problem: We Can’t Observe What We Need\nIn the previous chapter, we derived the variance of \\(\\widehat{\\text{ATE}}\\) under completely randomized experiments. We showed that\n\\[\n\\text{Var}_D \\left(\\widehat{\\text{ATE}}\\right) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} - \\frac{S_{tc}^2}{N},\n\\]\nwhere \\(S_t^2\\) and \\(S_c^2\\) are the variances of the potential outcomes and \\(S_{tc}^2\\) is the variance of the individual treatment effects. Remember, we defined these as\n\\[\nS_t^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} [Y_i(1) - \\overline{Y}(1)]^2,\n\\]\n\\[\nS_c^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} [Y_i(0) - \\overline{Y}(0)]^2,\n\\]\nand\n\\[\nS_{tc}^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} (\\tau_i - \\text{ATE})^2.\n\\]\nBut there’s a problem. This formula depends on quantities we cannot observe.\nTo make inferences about the ATE, we need to estimate the variance using only the observed data. This chapter addresses that challenge.\nLet’s be explicit about what we can and cannot observe. Recall our running example with 10 respondents. Here are the full potential outcomes (which only we, as omniscient author and reader, can see).\nFrom this complete table, we can compute \\(S_t^2 \\approx 4.93\\), \\(S_c^2 \\approx 1.43\\), and \\(S_{tc}^2 = 6.5\\). With \\(N_t = N_c = 5\\), the true variance of the estimator is\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = \\frac{4.93}{5} + \\frac{1.43}{5} - \\frac{6.5}{10} \\approx 0.99 + 0.29 - 0.65 = 0.62.\n\\]\nBut in practice, after running the experiment, we only see the observed outcomes. Suppose respondents 1, 4, 5, 7, and 10 are assigned to treatment. Here’s what we actually observe.\nThe question marks represent counterfactual outcomes we cannot observe. We have no way to compute \\(S_t^2\\), \\(S_c^2\\), or \\(S_{tc}^2\\) from this data because we don’t observe all the potential outcomes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating the Variance</span>"
    ]
  },
  {
    "objectID": "ch/var-est.html#the-problem-we-cant-observe-what-we-need",
    "href": "ch/var-est.html#the-problem-we-cant-observe-what-we-need",
    "title": "4  Estimating the Variance",
    "section": "",
    "text": "Respondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n4\n7\n3\n\n\n2\n6\n5\n-1\n\n\n3\n5\n5\n0\n\n\n4\n3\n9\n6\n\n\n5\n7\n10\n3\n\n\n6\n5\n4\n-1\n\n\n7\n4\n8\n4\n\n\n8\n6\n7\n1\n\n\n9\n5\n3\n-2\n\n\n10\n4\n6\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRespondent\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n?\n7\n?\n1\n7\n\n\n2\n6\n?\n?\n0\n6\n\n\n3\n5\n?\n?\n0\n5\n\n\n4\n?\n9\n?\n1\n9\n\n\n5\n?\n10\n?\n1\n10\n\n\n6\n5\n?\n?\n0\n5\n\n\n7\n?\n8\n?\n1\n8\n\n\n8\n6\n?\n?\n0\n6\n\n\n9\n5\n?\n?\n0\n5\n\n\n10\n?\n6\n?\n1\n6",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating the Variance</span>"
    ]
  },
  {
    "objectID": "ch/var-est.html#estimating-s_t2-and-s_c2",
    "href": "ch/var-est.html#estimating-s_t2-and-s_c2",
    "title": "4  Estimating the Variance",
    "section": "4.2 Estimating \\(S_t^2\\) and \\(S_c^2\\)",
    "text": "4.2 Estimating \\(S_t^2\\) and \\(S_c^2\\)\nEven though we cannot compute \\(S_t^2\\) exactly, we can estimate it using the observed outcomes in the treatment group. Similarly, we can estimate \\(S_c^2\\) using the observed outcomes in the control group.\n\n4.2.1 The Sample Variance in the Treatment Group\nWe define the sample variance in the treatment group as\n\\[\ns_t^2 = \\frac{1}{N_t - 1} \\sum_{i:D_i=1} \\left( Y^{\\text{obs}}_i - \\overline{Y}^{\\text{obs}}_t \\right)^2.\n\\]\nThis is just the ordinary sample variance formula applied to the observed outcomes of treated individuals.\n\n\n\n\n\n\nUnderstanding This Formula\n\n\n\n\n\nThe formula computes the variance of the observed outcomes among treated individuals. The subscript \\(i:D_i=1\\) means “only sum over individuals with \\(D_i = 1\\)” (i.e., the treated individuals).\nIt’s exactly analogous to teh formatula for \\(S_t^2\\), except here we only use the observed values in the treatment group.\nExample. In our experiment, the treated individuals (1, 4, 5, 7, 10) have observed outcomes 7, 9, 10, 8, 6. The treatment group mean is\n\\[\n\\overline{Y}^{\\text{obs}}_t = \\frac{7 + 9 + 10 + 8 + 6}{5} = \\frac{40}{5} = 8.\n\\]\nThe sample variance is\n\\[\n\\begin{align}\ns_t^2 &= \\frac{1}{5-1}\\left[(7-8)^2 + (9-8)^2 + (10-8)^2 + (8-8)^2 + (6-8)^2\\right] \\\\\n&= \\frac{1 + 1 + 4 + 0 + 4}{4} \\\\\n&= \\frac{10}{4} = 2.5.\n\\end{align}\n\\]\n\n\n\n\n\n4.2.2 The Sample Variance in the Control Group\nSimilarly, we define the sample variance in the control group as\n\\[\ns_c^2 = \\frac{1}{N_c - 1} \\sum_{i:D_i=0} \\left( Y^{\\text{obs}}_i - \\overline{Y}^{\\text{obs}}_c \\right)^2.\n\\]\n\n\n\n\n\n\nUnderstanding This Formula\n\n\n\n\n\nThis is the same idea, applied to the control group. We compute the variance of the observed outcomes among control individuals.\nExample. The control individuals (2, 3, 6, 8, 9) have observed outcomes 6, 5, 5, 6, 5. The control group mean is\n\\[\n\\overline{Y}^{\\text{obs}}_c = \\frac{6 + 5 + 5 + 6 + 5}{5} = \\frac{27}{5} = 5.4.\n\\]\nThe sample variance is\n\\[\n\\begin{align}\ns_c^2 &= \\frac{1}{4}\\left[(6-5.4)^2 + (5-5.4)^2 + (5-5.4)^2 + (6-5.4)^2 + (5-5.4)^2\\right] \\\\\n&= \\frac{0.36 + 0.16 + 0.16 + 0.36 + 0.16}{4} \\\\\n&= \\frac{1.2}{4} = 0.3.\n\\end{align}\n\\]\n\n\n\n\n\n4.2.3 Are These Good Estimates?\nA natural question is whether \\(s_t^2\\) and \\(s_c^2\\) are good estimates of \\(S_t^2\\) and \\(S_c^2\\). They are! Under random assignment, these variances of the observed outcomes equals the variance of all the potential outcomes.\n\n\n\n\n\n\nUnbiasedness of Sample Variances\n\n\n\nUnder completely randomized assignment, we have\n\\[\nE_D[s_t^2] = S_t^2 \\quad \\text{and} \\quad E_D[s_c^2] = S_c^2.\n\\]\nThat is, on average across all possible randomizations, the variances of the observed outcomes equals the variances of all the potential outcomes.\nThe intuition is straightforward. Random assignment ensures that the treated individuals are a representative sample of the full population. So the variance of the observed outcomes among treated individuals should, on average, equal the variance of potential outcomes under treatment for the full population. The same logic applies to the control group.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating the Variance</span>"
    ]
  },
  {
    "objectID": "ch/var-est.html#the-problem-with-s_tc2",
    "href": "ch/var-est.html#the-problem-with-s_tc2",
    "title": "4  Estimating the Variance",
    "section": "4.3 The Problem with \\(S_{tc}^2\\)",
    "text": "4.3 The Problem with \\(S_{tc}^2\\)\nWe can estimate \\(S_t^2\\) and \\(S_c^2\\) from observed data. But what about \\(S_{tc}^2\\), the variance of the individual treatment effects?\nHere’s a big problem. Recall that \\(S_{tc}^2\\) is defined as\n\\[\nS_{tc}^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} (\\tau_i - \\text{ATE})^2,\n\\]\nwhere \\(\\tau_i = Y_i(1) - Y_i(0)\\). This requires knowing both potential outcomes for every individual. But we only observe one potential outcome per individual. We can never compute \\(\\tau_i\\) for any individual, let alone its variance across individuals.\nThis is a fundamental limitation. The quantity \\(S_{tc}^2\\) is inherently unobservable. We cannot even estimate it from the observed data.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating the Variance</span>"
    ]
  },
  {
    "objectID": "ch/var-est.html#neymans-variance-estimator",
    "href": "ch/var-est.html#neymans-variance-estimator",
    "title": "4  Estimating the Variance",
    "section": "4.4 Neyman’s Variance Estimator",
    "text": "4.4 Neyman’s Variance Estimator\nIn 1923, Jerzy Neyman proposed a solution to this problem (Neyman 1923). Rather than trying to estimate \\(S_{tc}^2\\), we simply drop the third term from the variance formula.\n\nNeyman, Jerzy. 1923. “On the Application of Probability Theory to Agricultural Experiments: Essay on Principles, Section 9.” Statistical Science 5 (4): 465–72.\n\nLet that sink in: in the last chapter, we took a deep dive into this third term. Now we just drop it?!? How can that be right?\n\nThis gives what we call Neyman’s variance estimator.\n\\[\n\\widehat{\\text{Var}}(\\widehat{\\text{ATE}}) = \\frac{s_t^2}{N_t} + \\frac{s_c^2}{N_c}.\n\\]\nThis estimator uses only observable quantities: the sample variances in the treatment and control groups.\n\n\n\n\n\n\nUnderstanding This Estimator\n\n\n\n\n\nNeyman’s variance estimator replaces the population variances \\(S_t^2\\) and \\(S_c^2\\) with their sample counterparts \\(s_t^2\\) and \\(s_c^2\\), and ignores the \\(-S_{tc}^2/N\\) term entirely.\nExample. Using our earlier calculations where \\(s_t^2 = 2.5\\) and \\(s_c^2 = 0.3\\) with \\(N_t = N_c = 5\\), Neyman’s variance estimator is\n\\[\n\\widehat{\\text{Var}}(\\widehat{\\text{ATE}}) = \\frac{2.5}{5} + \\frac{0.3}{5} = 0.5 + 0.06 = 0.56.\n\\]\nRecall that the true variance (computed from the full potential outcomes) was 0.62. Our estimate of 0.56 is reasonably close.\n\n\n\nBut why is it safe to drop this third term? Let’s consider three scenarios.\n\n4.4.1 Case 1: The Sharp Null Hypothesis\nUnder the sharp null hypothesis, the treatment has no effect on any individual. That is, \\(Y_i(1) = Y_i(0)\\) for all \\(i\\), which means \\(\\tau_i = 0\\) for all \\(i\\).\nIf all treatment effects are zero, then the variance of the treatment effects is also zero. We have \\(S_{tc}^2 = 0\\). What happens to the true variance formula? The third term vanishes, and the formula simplifies to\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c}.\n\\]\nBut this is exactly what Neyman’s estimator estimates! This leads to a nice result: Under the sharp null, Neyman’s estimator is unbiased.\n\n\n4.4.2 Case 2: Constant Treatment Effects\nUnder constant treatment effects, every individual experiences the same treatment effect. That is, \\(\\tau_i = \\tau\\) for some constant \\(\\tau\\) and all individuals \\(i\\).\nIf treatment effects are constant, then there is no variance in the treatment effects. Every \\(\\tau_i\\) equals \\(\\tau\\), which equals the ATE. So \\(S_{tc}^2 = 0\\). Once again, the third term vanishes, and the true variance formula simplifies to\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c}.\n\\]\nAnd we have another nice result: Under constant treatment effects, Neyman’s estimator is unbiased.\n\n\n4.4.3 A Simulation Under Constant Effects\nLet’s verify this claim with a simulation. We’ll create a population where treatment effects are constant, then repeatedly randomize and compute both \\(\\widehat{\\text{ATE}}\\) and \\(\\widehat{\\text{Var}}(\\widehat{\\text{ATE}})\\). If Neyman’s variance estimator is unbiased, the long-run average of our variance estimates should equal the true variance.\nWhat does it mean for a variance estimator to be “unbiased”? The idea is subtle. Just as \\(\\widehat{\\text{ATE}}\\) is unbiased if its long-run average equals the true ATE, the variance estimator \\(\\widehat{\\text{Var}}(\\widehat{\\text{ATE}})\\) is unbiased if its long-run average equals the true variance \\(\\text{Var}_D(\\widehat{\\text{ATE}})\\). If we could repeat the experiment many times and compute Neyman’s variance estimate each time, the average of all those variance estimates would equal the true variance of the estimator.\n\n# load packages\nlibrary(tidyverse)\n\n# create potential outcomes with CONSTANT treatment effect of 2\npo_data &lt;- tibble(\n  respondent = 1:10,\n  Y0 = c(4, 6, 5, 3, 7, 5, 4, 6, 5, 4),  # control potential outcomes\n  Y1 = Y0 + 2  # treatment potential outcomes (constant effect = 2)\n)\n\npo_data\n\n# A tibble: 10 × 3\n   respondent    Y0    Y1\n        &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1          1     4     6\n 2          2     6     8\n 3          3     5     7\n 4          4     3     5\n 5          5     7     9\n 6          6     5     7\n 7          7     4     6\n 8          8     6     8\n 9          9     5     7\n10         10     4     6\n\n\nWith constant treatment effects, every \\(\\tau_i = 2\\), so the ATE is also 2. We can verify that \\(S_{tc}^2 = 0\\).\n\n# compute the true ATE\ntrue_ate &lt;- mean(po_data$Y1 - po_data$Y0)\ntrue_ate\n\n[1] 2\n\n# verify S_tc^2 = 0 (variance of treatment effects)\ntau &lt;- po_data$Y1 - po_data$Y0\nvar(tau) \n\n[1] 0\n\n\nNow we simulate many randomizations. For each randomization, we compute \\(\\widehat{\\text{ATE}}\\) and \\(\\widehat{\\text{Var}}(\\widehat{\\text{ATE}})\\).\n\n# set seed for reproducibility\nset.seed(1234)\n\n# number of simulations\nn_sims &lt;- 100000\n\n# group sizes\nN_t &lt;- 5\nN_c &lt;- 5\n\n# storage for results\nate_estimates &lt;- numeric(n_sims)\nvar_estimates &lt;- numeric(n_sims)\n\n# run the simulation\nfor (i in 1:n_sims) {\n  # randomly assign 5 of 10 respondents to treatment\n  treated &lt;- sample(1:10, size = 5)\n\n  # compute observed outcomes\n  Y_obs &lt;- ifelse(1:10 %in% treated, po_data$Y1, po_data$Y0)\n\n  # compute ATE estimate\n  Y_bar_t &lt;- mean(Y_obs[1:10 %in% treated])\n  Y_bar_c &lt;- mean(Y_obs[!(1:10 %in% treated)])\n  ate_estimates[i] &lt;- Y_bar_t - Y_bar_c\n\n  # compute Neyman's variance estimate\n  s_t_sq &lt;- var(Y_obs[1:10 %in% treated])\n  s_c_sq &lt;- var(Y_obs[!(1:10 %in% treated)])\n  var_estimates[i] &lt;- s_t_sq / N_t + s_c_sq / N_c\n}\n\nNow let’s compare our variance estimates to the actual variance of the ATE estimates across simulations.\n\n# compare average of variance estimates to variance of ATE estimates\nmean(var_estimates)  # average of estimated variances\n\n[1] 0.5733308\n\nvar(ate_estimates)   # variance of ATE estimates across simulations\n\n[1] 0.5733391\n\n\nThe average of our variance estimates (0.573) is very close to the actual variance of the ATE estimates (0.573). This confirms that under constant treatment effects, Neyman’s variance estimator is unbiased. In the long run, our variance estimates correctly capture how much \\(\\widehat{\\text{ATE}}\\) varies across randomizations.\n\n\n4.4.4 Case 3: Non-Constant Treatment Effects\nWhat if treatment effects are neither zero nor constant? What if they vary across individuals, as they almost certainly do in practice?\nThis is where things get interesting. Recall the true variance formula\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} - \\frac{S_{tc}^2}{N}.\n\\]\nWhen treatment effects vary, \\(S_{tc}^2 &gt; 0\\). Critically, the third term is always negative. It shrinks the variance. So what happens when Neyman’s estimator drops this term?\nThe estimator becomes too large. It overestimates the true variance.\nMore formally, since \\(S_{tc}^2 \\geq 0\\), we have\n\\[\n\\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} \\geq \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} - \\frac{S_{tc}^2}{N} = \\text{Var}_D(\\widehat{\\text{ATE}}).\n\\]\nAnd since \\(E_D[s_t^2] = S_t^2\\) and \\(E_D[s_c^2] = S_c^2\\), the expected value of Neyman’s estimator is\n\\[\nE_D\\left[\\widehat{\\text{Var}}(\\widehat{\\text{ATE}})\\right] = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} \\geq \\text{Var}_D(\\widehat{\\text{ATE}}).\n\\]\nHere is the surprising result. We might have worried that dropping an unobservable term would cause serious problems. Instead, it makes our variance estimate conservative. We err on the side of overestimating uncertainty rather than underestimating it.\nIn practice, having a conservative variance estimator is often acceptable. If we use an overestimated variance to construct confidence intervals or conduct hypothesis tests, our inferences will be conservative.\n\nConfidence intervals will be wider than necessary, so they will cover the true ATE at least as often as advertised (95% or more).\nHypothesis tests will reject the null hypothesis less often than they “should,” so the actual Type I error rate will be at most the nominal level (5% or less).\n\n\n\n4.4.5 A Simulation Under Non-Constant Effects\nLet’s verify this with a simulation, using the same structure as before. This time, we’ll create a population where treatment effects vary across individuals, so \\(S_{tc}^2 &gt; 0\\).\n\n# create potential outcomes with NON-CONSTANT treatment effects\npo_data &lt;- tibble(\n  respondent = 1:10,\n  Y0 = c(4, 6, 5, 3, 7, 5, 4, 6, 5, 4),  # control potential outcomes (same as before)\n  Y1 = c(7, 5, 5, 9, 10, 4, 8, 7, 3, 6)   # treatment potential outcomes (varying effects)\n)\n\n# compute individual treatment effects\npo_data &lt;- po_data |&gt;\n  mutate(tau = Y1 - Y0)\n\npo_data\n\n# A tibble: 10 × 4\n   respondent    Y0    Y1   tau\n        &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1          1     4     7     3\n 2          2     6     5    -1\n 3          3     5     5     0\n 4          4     3     9     6\n 5          5     7    10     3\n 6          6     5     4    -1\n 7          7     4     8     4\n 8          8     6     7     1\n 9          9     5     3    -2\n10         10     4     6     2\n\n\n\n\n\ncor(po_data$Y0, po_data$Y1)\n\n[1] -0.02507061\n\nggplot(po_data, aes(x = Y0, y = Y1)) +\n  geom_point()\n\n\n\n\n\n\n\n\nNotice that the treatment effects vary across individuals, ranging from -2 to 6.\n\n# compute S_tc^2 (variance of treatment effects)\nS_tc_sq &lt;- var(po_data$tau)\nS_tc_sq\n\n[1] 6.5\n\n\nWith \\(S_{tc}^2 = 6.5\\), the third term in the variance formula is no longer zero. Now we simulate many randomizations, just as before.\n\n# set seed for reproducibility\nset.seed(1234)\n\n# number of simulations\nn_sims &lt;- 100000\n\n# group sizes\nN_t &lt;- 5\nN_c &lt;- 5\n\n# storage for results\nate_estimates &lt;- numeric(n_sims)\nvar_estimates &lt;- numeric(n_sims)\n\n# run the simulation\nfor (i in 1:n_sims) {\n  # randomly assign 5 of 10 respondents to treatment\n  treated &lt;- sample(1:10, size = 5)\n\n  # compute observed outcomes\n  Y_obs &lt;- ifelse(1:10 %in% treated, po_data$Y1, po_data$Y0)\n\n  # compute ATE estimate\n  Y_bar_t &lt;- mean(Y_obs[1:10 %in% treated])\n  Y_bar_c &lt;- mean(Y_obs[!(1:10 %in% treated)])\n  ate_estimates[i] &lt;- Y_bar_t - Y_bar_c\n\n  # compute Neyman's variance estimate\n  s_t_sq &lt;- var(Y_obs[1:10 %in% treated])\n  s_c_sq &lt;- var(Y_obs[!(1:10 %in% treated)])\n  var_estimates[i] &lt;- s_t_sq / N_t + s_c_sq / N_c\n}\n\nNow let’s compare our variance estimates to the actual variance of the ATE estimates across simulations.\n\n# compare average of variance estimates to variance of ATE estimates\nmean(var_estimates)  # average of estimated variances\n\n[1] 1.27524\n\nvar(ate_estimates)   # variance of ATE estimates across simulations\n\n[1] 0.6219203\n\n\nThe average of our variance estimates (1.275) is larger than the actual variance of the ATE estimates (0.622). This confirms that under non-constant treatment effects, Neyman’s variance estimator is conservative. It systematically overestimates how much \\(\\widehat{\\text{ATE}}\\) varies across randomizations.\n\n\n\n\n\n\nThe Overestimate Doesn’t Shrink with Sample Size\n\n\n\nYou might hope that the conservative bias becomes negligible as the sample size grows. Unfortunately, the percent overestimate does not diminish with \\(N\\).\nTo see why, suppose we split the sample evenly so that \\(N_t = N_c = N/2\\). Then the true variance is\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = \\frac{2S_t^2}{N} + \\frac{2S_c^2}{N} - \\frac{S_{tc}^2}{N} = \\frac{2S_t^2 + 2S_c^2 - S_{tc}^2}{N},\n\\]\nand Neyman’s estimator targets\n\\[\n\\frac{2S_t^2 + 2S_c^2}{N}.\n\\]\nThe percent overestimate is\n\\[\n\\frac{S_{tc}^2 / N}{(2S_t^2 + 2S_c^2 - S_{tc}^2)/N} = \\frac{S_{tc}^2}{2S_t^2 + 2S_c^2 - S_{tc}^2}.\n\\]\nNotice that \\(N\\) cancels out entirely. The percent overestimate depends only on the population variances \\(S_t^2\\), \\(S_c^2\\), and \\(S_{tc}^2\\), not on the sample size. If treatment effects are heterogeneous, Neyman’s variance estimator will overestimate by the same percentage whether you have 10 respondents or 1,000.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating the Variance</span>"
    ]
  },
  {
    "objectID": "ch/var-est.html#computing-the-variance-estimate-in-r",
    "href": "ch/var-est.html#computing-the-variance-estimate-in-r",
    "title": "4  Estimating the Variance",
    "section": "4.5 Computing the Variance Estimate in R",
    "text": "4.5 Computing the Variance Estimate in R\nLet’s compute Neyman’s variance estimator using R. We’ll use the same hypothetical experiment from above.\n\n# load packages\nlibrary(tidyverse)\n\n# create the observed data\nobs_data &lt;- tibble(\n  respondent = 1:10,\n  D = c(1, 0, 0, 1, 1, 0, 1, 0, 0, 1),  # treatment assignment\n  Y_obs = c(7, 6, 5, 9, 10, 5, 8, 6, 5, 6)  # observed outcomes\n)\n\nobs_data\n\n# A tibble: 10 × 3\n   respondent     D Y_obs\n        &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1          1     1     7\n 2          2     0     6\n 3          3     0     5\n 4          4     1     9\n 5          5     1    10\n 6          6     0     5\n 7          7     1     8\n 8          8     0     6\n 9          9     0     5\n10         10     1     6\n\n\n\n4.5.1 Computing the Sample Variances\nWe compute the sample variances in each group.\n\n# sample variance in treatment group\ns_t_sq &lt;- obs_data |&gt;\n  filter(D == 1) |&gt;\n  pull(Y_obs) |&gt;\n  var()\n\ns_t_sq\n\n[1] 2.5\n\n# sample variance in control group\ns_c_sq &lt;- obs_data |&gt;\n  filter(D == 0) |&gt;\n  pull(Y_obs) |&gt;\n  var()\n\ns_c_sq\n\n[1] 0.3\n\n\n\n\n4.5.2 Computing Neyman’s Variance Estimator\nNow we can compute Neyman’s variance estimator.\n\n# group sizes\nN_t &lt;- sum(obs_data$D)\nN_c &lt;- sum(1 - obs_data$D)\n\n# Neyman's variance estimator\nvar_hat &lt;- s_t_sq / N_t + s_c_sq / N_c\nvar_hat\n\n[1] 0.56\n\n# standard error is a common conversion (square root of variance)\nse_hat &lt;- sqrt(var_hat)\nse_hat\n\n[1] 0.7483315\n\n\nThe estimated variance is 0.56 and the estimated standard error is 0.748.\n\n\n4.5.3 Using OLS with HC2 Standard Errors\nWe can also compute Neyman’s variance estimator in R using lm(). As we showed in an earlier chapter, the difference-in-means estimator equals the coefficient from a regression of \\(Y_i^{\\text{obs}}\\) on \\(D_i\\). But the default standard errors from lm() (as reported by summary() for example) assume homoscedasticity, which is not appropriate here.\nSamii and Aronow (2012) show that HC2 robust standard errors are exactly equivalent to Neyman’s variance estimator for completely randomized experiments. The HC2 estimator is one of several “heteroscedasticity-consistent” variance estimators developed in econometrics. Samii and Aronow’s result means we can obtain the Neyman standard error directly from regression output by requesting HC2 standard errors.\n\nSamii, Cyrus, and Peter M. Aronow. 2012. “On Equivalencies Between Design-Based and Regression-Based Variance Estimators for Randomized Experiments.” Statistics and Probability Letters 82 (2): 365–70.\n\n# load the sandwich package for robust standard errors\nlibrary(sandwich)\nlibrary(lmtest)\n\n# fit the regression\nfit &lt;- lm(Y_obs ~ D, data = obs_data)\n\n# print estimates and HC2 SEs\nvar_hat_hc2 &lt;- vcovHC(fit, type = \"HC2\")\ncoeftest(fit, vcov. = var_hat_hc2)\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  5.40000    0.24495 22.0454 1.893e-08 ***\nD            2.60000    0.74833  3.4744  0.008388 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# extract variance estimates using HC2\ndiag(var_hat_hc2)[2] # variance\n\n   D \n0.56 \n\nsqrt(diag(var_hat_hc2)[2]) # SE\n\n        D \n0.7483315 \n\n\nThe coefficient on D is 2.6, which is our \\(\\widehat{\\text{ATE}}\\). The HC2 standard error is 0.748, which matches the Neyman standard error we computed by hand (0.748).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating the Variance</span>"
    ]
  },
  {
    "objectID": "ch/var-est.html#clifford2021",
    "href": "ch/var-est.html#clifford2021",
    "title": "4  Estimating the Variance",
    "section": "4.6 Clifford, Sheagley, and Piston (2021)",
    "text": "4.6 Clifford, Sheagley, and Piston (2021)\n\nClifford, Scott, Geoffrey Sheagley, and Spencer Piston. 2021. “Increasing Precision Without Altering Treatment Effects: Repeated Measures Designs in Survey Experiments.” American Political Science Review 115 (3): 1048–65.\nAs part of an important paper we’ll return to later, Clifford, Sheagley, and Piston (2021) conducted a question-wording experiment similar to the Rasinski experiment we’ve been using as an example.\nTheir Study 1 replicates the canonical welfare question-wording experiment examining whether public support for government spending differs when the policy is described as “welfare” versus “assistance to the poor”.\nRespondents were randomly assigned to one of two question wordings: “Generally speaking, do you think we’re spending too much, too little or about the right amount on…””\n\n“assistance to the poor?” (control)1\n“welfare?” (treatment)\n\n1 In the original Rasinski example, we treated “welfare” as the control.Both versions of the question used the same three-point response scale below.\n\nToo much (1)\nAbout the right amount (2)\nToo little (3 \\(\\rightarrow\\) higher = more liberal response)\n\nThe R code below loads their data. Their experiment has other things going on, but the R code below wrangles it into the simple treatment-control portion that is analogous to our running Rasinski example (except they have over 400 real respondents!).2\n2 We’ll return to the other portions later.\n# load the study 1 data directly from Harvard Dataverse\n# https://dataverse.harvard.edu/file.xhtml?fileId=4459780&version=1.0\n\nlibrary(tidyverse)\n\n# read tab-delimited file from the Dataverse API\nstudy1 &lt;- read_tsv(\"https://dataverse.harvard.edu/api/access/datafile/4459780\") |&gt;\n  filter(design == 0) |&gt;\n  select(response = postdv, \n         treatment_indicator = treat) |&gt;  # 1 if \"welfare\"; 0 if \"assistance...\"\n  glimpse()\n\nRows: 447\nColumns: 2\n$ response            &lt;dbl&gt; 3, 3, 2, 1, 3, 2, 3, 3, 2, 2, 3, 2, 2, 3, 2, 2, 3,…\n$ treatment_indicator &lt;dbl&gt; 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,…\n\n# fit regression\nfit &lt;- lm(response ~ treatment_indicator, data = study1)\nvar_hat &lt;- vcovHC(fit, type = \"HC2\")\ncoeftest(fit, vcov. = var_hat)\n\n\nt test of coefficients:\n\n                     Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)          2.477612   0.048394 51.1962 &lt; 2.2e-16 ***\ntreatment_indicator -0.239907   0.068852 -3.4844 0.0005423 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating the Variance</span>"
    ]
  },
  {
    "objectID": "ch/var-est.html#key-terms",
    "href": "ch/var-est.html#key-terms",
    "title": "4  Estimating the Variance",
    "section": "4.7 Key Terms",
    "text": "4.7 Key Terms\n\nSample variance (\\(s_t^2\\), \\(s_c^2\\))\nNeyman’s variance estimator\nConservative variance estimation\nRelationship between vcovHC(fit, type = \"HC2\") and Neyman’s variance estimation\nStandard error (and relationship to variance)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating the Variance</span>"
    ]
  },
  {
    "objectID": "ch/var-est.html#exercises",
    "href": "ch/var-est.html#exercises",
    "title": "4  Estimating the Variance",
    "section": "4.8 Exercises",
    "text": "4.8 Exercises\n\n4.8.1 Conceptual Understanding\n\nObservable vs. Unobservable. Explain why we can estimate \\(S_t^2\\) and \\(S_c^2\\) from observed data, but we cannot estimate \\(S_{tc}^2\\). What fundamental feature of experiments makes \\(S_{tc}^2\\) unobservable?\n\n\n\nSolution\n\nWe can estimate \\(S_t^2\\) because random assignment ensures that the treated individuals are a representative sample of the full population. The observed outcomes \\(Y_i^{\\text{obs}}\\) for treated individuals are a random sample of all the potential outcomes \\(Y_i(1)\\). So the sample variance of observed outcomes in the treatment group is an unbiased estimate of the population variance of potential outcomes under treatment. The same logic applies to \\(S_c^2\\) and the control group.\nWe cannot estimate \\(S_{tc}^2\\) because it measures the variance of \\(\\tau_i = Y_i(1) - Y_i(0)\\), the individual-level treatment effect. To compute \\(\\tau_i\\) for any individual, we would need to observe both \\(Y_i(1)\\) and \\(Y_i(0)\\). But the fundamental problem of causal inference is that we can only observe one potential outcome per individual. Since we can never observe \\(\\tau_i\\) for any individual, we cannot compute its variance across individuals.\nThis is a fundamental limitation of experiments. We can learn about average effects, but the individual-level effects remain hidden.\n\n\nWhy Conservative? Explain in plain language why Neyman’s variance estimator is conservative (i.e., why it tends to overestimate the true variance). Under what conditions is it exactly unbiased?\n\n\n\nSolution\n\nThe true variance of \\(\\widehat{\\text{ATE}}\\) is\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} - \\frac{S_{tc}^2}{N}.\n\\]\nNeyman’s variance estimator only uses the first two terms. It ignores the third term, \\(-S_{tc}^2/N\\), which is negative (or zero). By ignoring a negative term, we end up with a larger estimate than the true value.\nIntuitively, the negative term reflects the fact that treatment and control assignments are negatively correlated. When an individual with a large \\(Y_i(1)\\) ends up in treatment, they’re not in control, which partially offsets the effect on the estimate. Neyman’s estimator ignores this offsetting effect, so it overestimates how much the estimate varies.\nNeyman’s estimator is exactly unbiased when \\(S_{tc}^2 = 0\\). This happens in two cases:\n\nSharp null. If the treatment has no effect on anyone (\\(\\tau_i = 0\\) for all \\(i\\)), then all treatment effects are zero, and their variance is zero.\nConstant effects. If everyone experiences the same treatment effect (\\(\\tau_i = \\tau\\) for all \\(i\\)), then there’s no variation in treatment effects, and their variance is zero.\n\nIn any other case, where treatment effects vary across individuals, Neyman’s estimator overestimates the true variance.\n\n\nConservative Inference. If you use a conservative variance estimator to construct a 95% confidence interval, will the actual coverage probability be greater than, less than, or equal to 95%? Explain.\n\n\n\nSolution\n\nThe actual coverage probability will be greater than 95%.\nA conservative variance estimator overestimates the variance, which means it also overestimates the standard error (the square root of the variance). When we construct a confidence interval, we compute\n\\[\n\\widehat{\\text{ATE}} \\pm 1.96 \\times \\widehat{\\text{SE}}.\n\\]\nIf \\(\\widehat{\\text{SE}}\\) is too large, the confidence interval will be wider than necessary. A wider interval is more likely to contain the true ATE, so the actual coverage probability exceeds the nominal 95%.\nThis is why we call it “conservative.” The inference errs on the side of caution. We’re more likely to say “we’re uncertain” than to make a confident but wrong claim.\n\n\nSharp Null and Constant Effects. The sharp null hypothesis states that \\(\\tau_i = 0\\) for all individuals, while constant effects means \\(\\tau_i = \\tau\\) for some constant \\(\\tau\\). Explain why both assumptions lead to \\(S_{tc}^2 = 0\\), even though they seem quite different.\n\n\n\nSolution\n\nBoth assumptions lead to \\(S_{tc}^2 = 0\\) because both eliminate variation in the treatment effects, even though they imply different average treatment effects.\n\\(S_{tc}^2\\) measures how much the individual treatment effects vary around their mean (the ATE). The formula is\n\\[\nS_{tc}^2 = \\frac{1}{N-1} \\sum_{i=1}^{N} (\\tau_i - \\text{ATE})^2.\n\\]\nUnder the sharp null, every \\(\\tau_i = 0\\), so the ATE is also 0. Every deviation \\(\\tau_i - \\text{ATE} = 0 - 0 = 0\\), so \\(S_{tc}^2 = 0\\).\nUnder constant effects, every \\(\\tau_i = \\tau\\), so the ATE is also \\(\\tau\\). Every deviation \\(\\tau_i - \\text{ATE} = \\tau - \\tau = 0\\), so \\(S_{tc}^2 = 0\\).\nThe key insight is that \\(S_{tc}^2\\) measures heterogeneity in treatment effects, not the level of the effect. Both the sharp null (zero effects for everyone) and constant effects (the same nonzero effect for everyone) eliminate heterogeneity, just in different ways.\n\n\n\n4.8.2 Computational Practice\n\nComputing Sample Variances. Consider an experiment with 6 individuals. After randomization, you observe the following.\n\n\n\nIndividual\n\\(D_i\\)\n\\(Y_i^{\\text{obs}}\\)\n\n\n\n\n1\n1\n8\n\n\n2\n0\n4\n\n\n3\n1\n6\n\n\n4\n0\n5\n\n\n5\n1\n10\n\n\n6\n0\n3\n\n\n\nUse R for these computations. Start by creating vectors D and Y_obs to hold the data, then use mean() and var() along with logical indexing (e.g., Y_obs[D == 1]) as needed.\n\nCompute the treatment group mean \\(\\overline{Y}^{\\text{obs}}_t\\) and control group mean \\(\\overline{Y}^{\\text{obs}}_c\\).\nCompute the sample variance in the treatment group, \\(s_t^2\\).\nCompute the sample variance in the control group, \\(s_c^2\\).\nCompute Neyman’s variance estimator \\(\\widehat{\\text{Var}}(\\widehat{\\text{ATE}})\\).\nCompute the estimated standard error of \\(\\widehat{\\text{ATE}}\\).\n\n\n\n\nSolution\n\nFirst, we create the data vectors.\n\n# create data vectors\nD &lt;- c(1, 0, 1, 0, 1, 0)\nY_obs &lt;- c(8, 4, 6, 5, 10, 3)\n\nPart a. The treatment group mean and control group mean are\n\n# treatment group mean\nY_bar_t &lt;- mean(Y_obs[D == 1])\nY_bar_t\n\n[1] 8\n\n# control group mean\nY_bar_c &lt;- mean(Y_obs[D == 0])\nY_bar_c\n\n[1] 4\n\n\nSo \\(\\overline{Y}^{\\text{obs}}_t = 8\\) and \\(\\overline{Y}^{\\text{obs}}_c = 4\\).\nPart b. The sample variance in the treatment group is\n\n# sample variance in treatment group\ns_t_sq &lt;- var(Y_obs[D == 1])\ns_t_sq\n\n[1] 4\n\n\nSo \\(s_t^2 = 4\\).\nPart c. The sample variance in the control group is\n\n# sample variance in control group\ns_c_sq &lt;- var(Y_obs[D == 0])\ns_c_sq\n\n[1] 1\n\n\nSo \\(s_c^2 = 1\\).\nPart d. With \\(N_t = 3\\) and \\(N_c = 3\\), Neyman’s variance estimator is\n\n# group sizes\nN_t &lt;- sum(D == 1)\nN_c &lt;- sum(D == 0)\n\n# Neyman's variance estimator\nvar_hat &lt;- s_t_sq / N_t + s_c_sq / N_c\nvar_hat\n\n[1] 1.666667\n\n\nSo \\(\\widehat{\\text{Var}}(\\widehat{\\text{ATE}}) \\approx 1.67\\).\nPart e. The estimated standard error is\n\n# standard error\nse_hat &lt;- sqrt(var_hat)\nse_hat\n\n[1] 1.290994\n\n\nSo \\(\\widehat{\\text{SE}}(\\widehat{\\text{ATE}}) \\approx 1.29\\).\n\n\nTrue vs. Estimated Variance. Suppose the full potential outcomes for the 6 individuals in Exercise 5 are as follows.\n\n\n\nIndividual\n\\(Y_i(0)\\)\n\\(Y_i(1)\\)\n\\(\\tau_i\\)\n\n\n\n\n1\n5\n8\n3\n\n\n2\n4\n7\n3\n\n\n3\n4\n6\n2\n\n\n4\n5\n9\n4\n\n\n5\n6\n10\n4\n\n\n6\n3\n5\n2\n\n\n\nUse R for these computations. Start by creating vectors Y0, Y1, and tau to hold the potential outcomes and treatment effects, then use var() as needed.\n\nCompute \\(S_t^2\\), \\(S_c^2\\), and \\(S_{tc}^2\\) using the full potential outcomes.\nCompute the true variance of \\(\\widehat{\\text{ATE}}\\) using the formula with \\(N_t = N_c = 3\\).\nCompare the true variance to Neyman’s estimate from Exercise 5. Is Neyman’s estimate conservative, as expected?\n\n\n\n\nSolution\n\nFirst, we create the data vectors.\n\n# create potential outcome vectors\nY0 &lt;- c(5, 4, 4, 5, 6, 3)\nY1 &lt;- c(8, 7, 6, 9, 10, 5)\ntau &lt;- Y1 - Y0\n\nPart a. The finite population variances are computed using var().\n\n# finite population variances\nS_t_sq &lt;- var(Y1)\nS_c_sq &lt;- var(Y0)\nS_tc_sq &lt;- var(tau)\n\nS_t_sq\n\n[1] 3.5\n\nS_c_sq\n\n[1] 1.1\n\nS_tc_sq\n\n[1] 0.8\n\n\nSo \\(S_t^2 = 3.5\\), \\(S_c^2 = 1.1\\), and \\(S_{tc}^2 = 0.8\\).\nPart b. The true variance is\n\n# group sizes\nN_t &lt;- 3\nN_c &lt;- 3\nN &lt;- 6\n\n# true variance formula\ntrue_var &lt;- S_t_sq / N_t + S_c_sq / N_c - S_tc_sq / N\ntrue_var\n\n[1] 1.4\n\n\nSo \\(\\text{Var}_D(\\widehat{\\text{ATE}}) = 1.4\\).\nPart c. Neyman’s estimate from Exercise 5 was approximately 1.67. The true variance is 1.4. Since 1.67 &gt; 1.4, Neyman’s estimate is indeed conservative, as expected. It overestimates the true variance by about 0.27 (or about 19%).\n\n# Neyman's estimate from Exercise 5\nneyman_est &lt;- 5/3  # approximately 1.67\n\n# difference\nneyman_est - true_var\n\n[1] 0.2666667\n\n\nThe difference is the dropped term \\(S_{tc}^2/N = 0.8/6 \\approx 0.133\\). Since we drop a positive quantity that’s being subtracted, we end up with a larger estimate.\n\n\n\n4.8.3 Critical Thinking\n\nHeterogeneous Effects and Standard Errors. Suppose you run an experiment and find that \\(\\widehat{\\text{ATE}} = 5\\) with Neyman’s standard error of 2. A colleague points out that treatment effects might be heterogeneous, meaning \\(S_{tc}^2 &gt; 0\\).\n\nDoes the possibility of heterogeneous effects change your point estimate of the ATE? Why or why not?\nThe standard error has a “give-or-take” interpretation: if we repeated the experiment many times, the estimates would typically fall within one or two standard errors of the true ATE. Does heterogeneity affect this interpretation?\nWhat would you say to your colleague about how heterogeneous effects impact the reliability of your findings?\n\n\n\n\nSolution\n\nPart a. No, the possibility of heterogeneous effects does not change the point estimate. The difference-in-means estimator \\(\\widehat{\\text{ATE}}\\) is unbiased regardless of whether treatment effects are homogeneous or heterogeneous. The estimate of 5 is our best guess of the average treatment effect either way.\nPart b. Heterogeneity affects the accuracy of the estimated standard error, but in a conservative direction. The true variance is\n\\[\n\\text{Var}_D(\\widehat{\\text{ATE}}) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} - \\frac{S_{tc}^2}{N}.\n\\]\nIf \\(S_{tc}^2 &gt; 0\\), then the true variance is smaller than what Neyman’s estimator suggests. Our standard error of 2 is an overestimate of the true standard deviation of \\(\\widehat{\\text{ATE}}\\). This means the “give-or-take” range is actually smaller than we think. Our estimates are more precise than the standard error suggests.\nPart c. I would tell my colleague the following. “Good point! If treatment effects are heterogeneous, then our standard error is conservative, meaning we’re overstating how much our estimate might vary across different randomizations. The true give-or-take range is actually smaller than \\(\\pm 2\\).\nThe key point is that heterogeneous effects don’t threaten the validity of our inference. They just make it more cautious. We can trust our estimate of 5, and we can trust that the true ATE is probably within a couple of standard errors of that estimate. If anything, the true uncertainty is smaller than what we’re reporting, not larger.”\n\n\n\n4.8.4 R Practice\n\nRasinski Data. In earlier chapters, we used mock data from Rasinski’s question-wording experiment. Here is the full dataset as a tribble().\nrasinski &lt;- tribble(\n  ~desc,                     ~response,\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"About right\",\n  \"welfare\",                 \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"About right\",\n  \"welfare\",                 \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"welfare\",                 \"Too much\",\n  \"welfare\",                 \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too much\",\n  \"welfare\",                 \"Too little\",\n  \"welfare\",                 \"About right\",\n  \"welfare\",                 \"About right\",\n  \"welfare\",                 \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\"\n)\n\nPrepare the data for analysis by creating a numeric outcome variable (1 = “Too little”, 2 = “About right”, 3 = “Too much”) and a treatment indicator (1 = “assistance to the poor”, 0 = “welfare”).\nUse lm() to regress the outcome on the treatment indicator.\nUse the sandwich and lmtest packages to compute HC2 standard errors.\nReport the estimated ATE, its standard error, and interpret the results in one sentence.\n\n\n\n\nSolution\n\nPart a. We create the numeric outcome and treatment indicator.\n\n# load packages\nlibrary(tidyverse)\nlibrary(sandwich)\nlibrary(lmtest)\n\n# create the data\nrasinski &lt;- tribble(\n  ~desc,                     ~response,\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"About right\",\n  \"welfare\",                 \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"About right\",\n  \"welfare\",                 \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"welfare\",                 \"Too much\",\n  \"welfare\",                 \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too much\",\n  \"welfare\",                 \"Too little\",\n  \"welfare\",                 \"About right\",\n  \"welfare\",                 \"About right\",\n  \"welfare\",                 \"About right\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\",\n  \"assistance to the poor\",  \"Too little\",\n  \"welfare\",                 \"Too little\"\n)\n\n# create numeric outcome (1 = Too little, 2 = About right, 3 = Too much)\nrasinski &lt;- rasinski |&gt;\n  mutate(\n    outcome = case_when(\n      response == \"Too little\" ~ 1,\n      response == \"About right\" ~ 2,\n      response == \"Too much\" ~ 3\n    ),\n    treatment = if_else(desc == \"assistance to the poor\", 1, 0)\n  )\n\n# check the data\nrasinski |&gt; glimpse()\n\nRows: 39\nColumns: 4\n$ desc      &lt;chr&gt; \"assistance to the poor\", \"welfare\", \"assistance to the poor…\n$ response  &lt;chr&gt; \"Too little\", \"Too little\", \"Too little\", \"Too little\", \"Too…\n$ outcome   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, …\n$ treatment &lt;dbl&gt; 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, …\n\n\nPart b. We fit the regression.\n\n# fit regression\nfit &lt;- lm(outcome ~ treatment, data = rasinski)\nsummary(fit)\n\n\nCall:\nlm(formula = outcome ~ treatment, data = rasinski)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.4210 -0.4210 -0.2000  0.1895  1.8000 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1.4211     0.1297   10.95 3.62e-13 ***\ntreatment    -0.2211     0.1812   -1.22     0.23    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5655 on 37 degrees of freedom\nMultiple R-squared:  0.03868,   Adjusted R-squared:  0.0127 \nF-statistic: 1.489 on 1 and 37 DF,  p-value: 0.2301\n\n\nPart c. We compute HC2 standard errors.\n\n# compute HC2 standard errors\ncoeftest(fit, vcov. = vcovHC(fit, type = \"HC2\"))\n\n\nt test of coefficients:\n\n            Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  1.42105    0.13925 10.2050 2.631e-12 ***\ntreatment   -0.22105    0.18186 -1.2155    0.2319    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nPart d. The estimated ATE is approximately \\(-0.22\\) with a standard error of approximately \\(0.18\\). Using the “give-or-take” interpretation, we might say that the estimate is \\(-0.22\\) give or take \\(0.18\\) or so. This means that describing government spending as “assistance to the poor” rather than “welfare” shifts responses by about 0.22 points toward more support for spending (since lower values indicate “too little” spending). However, the the standard error is almost as large as the estimate so we can’t be confident that this difference isn’t just noise. We’ll describe a formal hypothesis test in the next chapter.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimating the Variance</span>"
    ]
  },
  {
    "objectID": "appendices/var-proof.html",
    "href": "appendices/var-proof.html",
    "title": "5  Appendix A: Proof of the Variance Formula",
    "section": "",
    "text": "5.1 Setting Up the Problem\nThis appendix provides a complete proof of the variance formula for the difference-in-means estimator, stated in the chapter on the variance of \\(\\widehat{\\text{ATE}}\\). The proof involves only algebra, but there are many steps and some tricks are helpful.\nRecall from the previous chapter that we can write the difference-in-means estimator as\n\\[\n\\widehat{\\text{ATE}} = \\frac{1}{N_t} \\sum_{i=1}^{N} D_i \\cdot Y^{\\text{obs}}_i - \\frac{1}{N_c} \\sum_{i=1}^{N} (1 - D_i) \\cdot Y^{\\text{obs}}_i,\n\\]\nwhere \\(D_i\\) is the treatment assignment indicator for individual \\(i\\) (1 if treated, 0 if control).\nTo compute the variance, we need to understand how this estimator behaves across all possible randomizations. The subscript \\(D\\) in \\(\\text{Var}_D(\\cdot)\\) and \\(E_D[\\cdot]\\) reminds us that the randomness comes entirely from the treatment assignment \\(D_i\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Appendix A: Proof of the Variance Formula</span>"
    ]
  },
  {
    "objectID": "appendices/var-proof.html#the-variance-operator-textvarcdot",
    "href": "appendices/var-proof.html#the-variance-operator-textvarcdot",
    "title": "5  Appendix A: Proof of the Variance Formula",
    "section": "5.2 The Variance Operator \\(\\text{Var}[\\cdot]\\)",
    "text": "5.2 The Variance Operator \\(\\text{Var}[\\cdot]\\)\nThe variance operator \\(\\text{Var}[\\cdot]\\) is a way of measuring “how spread out” a random variable is around its average value. The variance of a random variable measures its typical squared distance from the mean. You can think of \\(\\text{Var}(X)\\) as asking: “If I could repeat this random process infinitely many times, how far would \\(X\\) typically be from its average?”\nFor our purposes, we need five rules about variance. These rules play the same role that the expectation rules played in the previous chapter. They tell us which algebraic moves are allowed.\nRule 1: Variance is defined as the expected squared deviation from the mean.\nIf \\(X\\) is random, then\n\\[\n\\text{Var}(X) = E\\left[(X - E[X])^2\\right].\n\\]\nWe square the deviation so that negative and positive deviations do not cancel out. If on average you earn $100 per day, but some days you earn $80 and some days you earn $120, the deviations are \\(-20\\) and \\(+20\\). Without squaring, they would cancel to zero, hiding the variability.\nRule 2: Adding a constant does not change variance.\nIf \\(c\\) is a constant, then \\(\\text{Var}(X + c) = \\text{Var}(X)\\).\nShifting a random variable up or down changes its average value, but does not change how spread out it is. If your daily earnings go from averaging $100 to averaging $200 (because of a $100 raise), the spread around that average stays the same.\nRule 3: Multiplying by a constant scales variance by the square.\nIf \\(c\\) is a constant, then \\(\\text{Var}(cX) = c^2 \\text{Var}(X)\\).\nThis rule often surprises people because it differs from expectation. For expectation, constants come out unchanged (\\(E[cX] = c \\cdot E[X]\\)). For variance, constants come out squared. If your earnings double, the spread of your earnings quadruples.\n\n\n\n\n\n\nUnderstanding This Rule\n\n\n\n\n\nWhy does the constant get squared? Variance measures squared deviations. If we double \\(X\\), the deviations from the mean also double. But since we square those deviations, doubling the deviation means quadrupling the squared deviation.\nExample. Suppose \\(X\\) can be either 1 or 3, each with probability 1/2. Then \\(E[X] = 2\\), and\n\\[\n\\text{Var}(X) = \\frac{1}{2}(1 - 2)^2 + \\frac{1}{2}(3 - 2)^2 = \\frac{1}{2}(1) + \\frac{1}{2}(1) = 1.\n\\]\nNow consider \\(2X\\), which can be either 2 or 6. Then \\(E[2X] = 4\\), and\n\\[\n\\text{Var}(2X) = \\frac{1}{2}(2 - 4)^2 + \\frac{1}{2}(6 - 4)^2 = \\frac{1}{2}(4) + \\frac{1}{2}(4) = 4.\n\\]\nThe variance is \\(4 = 2^2 \\times 1 = c^2 \\times \\text{Var}(X)\\).\n\n\n\nRule 4: The variance of a sum includes cross-terms.\nIf \\(X\\) and \\(Y\\) are random, then\n\\[\n\\text{Var}(X + Y) = \\text{Var}(X) + \\text{Var}(Y) + 2\\text{Cov}(X, Y),\n\\]\nwhere \\(\\text{Cov}(X, Y)\\) is the covariance between \\(X\\) and \\(Y\\). The covariance measures how \\(X\\) and \\(Y\\) move together. If \\(X\\) and \\(Y\\) tend to be high at the same time, their covariance is positive. If one tends to be high when the other is low, their covariance is negative.\nThis rule matters because our estimator is built from sums. When we take the variance of a sum, we do not simply get “variance of the first part plus variance of the second part.” We also get cross-terms.\nIn our setting, these cross-terms are especially important. Under completely randomized assignment, treatment indicators for different individuals are not independent. If one individual is assigned to treatment, that makes it slightly less likely that another individual is assigned to treatment (because there are only \\(N_t\\) slots). This creates negative covariance between treatment assignments.\n\n\n\n\n\n\nUnderstanding Where the Covariance Comes From\n\n\n\n\n\nThe covariance term appears because we square a sum. Think back to algebra: \\((a + b)^2 = a^2 + 2ab + b^2\\). The “cross-term” \\(2ab\\) is what becomes the covariance.\nStart from the definition, so that\n\\[\n\\text{Var}(X + Y) = E\\left[\\left((X + Y) - E[X + Y]\\right)^2\\right].\n\\]\nRewrite the mean as \\(E[X + Y] = E[X] + E[Y]\\), so that\n\\[\n\\text{Var}(X + Y) = E\\left[\\left((X - E[X]) + (Y - E[Y])\\right)^2\\right].\n\\]\nExpand the square, which gives\n\\[\n\\text{Var}(X + Y) =\nE\\left[(X - E[X])^2\\right]\n+ E\\left[(Y - E[Y])^2\\right]\n+ 2E\\left[(X - E[X])(Y - E[Y])\\right].\n\\]\nThe first term is \\(\\text{Var}(X)\\). The second term is \\(\\text{Var}(Y)\\). The last term is \\(2\\text{Cov}(X, Y)\\) by definition.\nSpecial case: independence. If \\(X\\) and \\(Y\\) are independent, their covariance is zero, and the variance of the sum is just the sum of the variances. But in our setting, treatment assignments are not independent, so we cannot ignore the covariance.\n\n\n\nRule 5: If the mean is zero, variance equals the expected square.\nIf \\(E[X] = 0\\), then\n\\[\n\\text{Var}(X) = E[X^2].\n\\]\nThis rule is a useful shortcut. By definition, \\(\\text{Var}(X) = E[X^2] - (E[X])^2\\). If \\(E[X] = 0\\), the second term vanishes, and we are left with just \\(E[X^2]\\).\nWe will use this simplification later by rewriting expressions so that they have mean zero.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Appendix A: Proof of the Variance Formula</span>"
    ]
  },
  {
    "objectID": "appendices/var-proof.html#some-preliminary-results",
    "href": "appendices/var-proof.html#some-preliminary-results",
    "title": "5  Appendix A: Proof of the Variance Formula",
    "section": "5.3 Some Preliminary Results",
    "text": "5.3 Some Preliminary Results\nBefore tackling the variance formula, we need to establish some basic facts about the treatment indicators \\(D_i\\) under completely randomized assignment.\n\n5.3.1 Facts About \\(D_i\\)\nIn a completely randomized experiment with \\(N\\) individuals where \\(N_t\\) are assigned to treatment, each individual has the same probability of being treated. We have\n\\[\nE_D[D_i] = \\Pr(D_i = 1) = \\frac{N_t}{N}.\n\\]\nSince \\(D_i\\) is binary (either 0 or 1), we also have \\(D_i^2 = D_i\\) (squaring a 0 or 1 gives you the same number). This means\n\\[\nE_D[D_i^2] = E_D[D_i] = \\frac{N_t}{N}.\n\\]\nFrom these facts, we can compute the variance of \\(D_i\\), so that\n\\[\n\\text{Var}_D(D_i) = E_D[D_i^2] - (E_D[D_i])^2 = \\frac{N_t}{N} - \\left(\\frac{N_t}{N}\\right)^2 = \\frac{N_t}{N} \\left( 1 - \\frac{N_t}{N} \\right) = \\frac{N_t \\cdot N_c}{N^2}.\n\\]\n\n\n\n\n\n\nUnderstanding This Calculation\n\n\n\n\n\nThe variance formula \\(\\text{Var}(X) = E[X^2] - (E[X])^2\\) is a standard result. Let’s verify it with a concrete example.\nSuppose \\(N = 10\\) and \\(N_t = 4\\). Then \\(E_D[D_i] = 4/10 = 0.4\\). The variance is\n\\[\n\\text{Var}_D(D_i) = \\frac{4}{10} \\left(1 - \\frac{4}{10}\\right) = 0.4 \\times 0.6 = 0.24.\n\\]\nThis is the variance of a Bernoulli random variable with probability \\(p = 0.4\\), which is \\(p(1-p) = 0.24\\).\n\n\n\n\n\n5.3.2 The Correlation Between Treatment Assignments\nHere’s where things get interesting. In a completely randomized experiment, the treatment assignments \\(D_i\\) and \\(D_j\\) for different individuals are not independent. If one individual is assigned to treatment, that makes it slightly less likely that another individual is assigned to treatment (because there are only \\(N_t\\) treatment slots to fill).\nFor \\(i \\neq j\\), we need to compute \\(E_D[D_i \\cdot D_j]\\). This equals the probability that both individuals \\(i\\) and \\(j\\) are assigned to treatment.\nWe can compute this using conditional probability, so that\n\\[\nE_D[D_i \\cdot D_j] = \\Pr(D_i = 1) \\cdot \\Pr(D_j = 1 \\mid D_i = 1) = \\frac{N_t}{N} \\cdot \\frac{N_t - 1}{N - 1}.\n\\]\n\n\n\n\n\n\nUnderstanding This Calculation\n\n\n\n\n\nThe probability that individual \\(i\\) is treated is \\(N_t/N\\). Given that individual \\(i\\) is treated, there are now \\(N_t - 1\\) remaining treatment slots and \\(N - 1\\) remaining individuals. So the probability that individual \\(j\\) is also treated is \\((N_t - 1)/(N - 1)\\).\nExample. Suppose \\(N = 5\\) and \\(N_t = 2\\). The probability both individuals 1 and 2 are treated is\n\\[\n\\frac{2}{5} \\cdot \\frac{1}{4} = \\frac{2}{20} = 0.1.\n\\]\nWe can verify this by counting. There are \\(\\binom{5}{2} = 10\\) ways to choose 2 individuals for treatment. Only 1 of these ways assigns both individuals 1 and 2 to treatment. So the probability is \\(1/10 = 0.1\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Appendix A: Proof of the Variance Formula</span>"
    ]
  },
  {
    "objectID": "appendices/var-proof.html#a-helpful-transformation",
    "href": "appendices/var-proof.html#a-helpful-transformation",
    "title": "5  Appendix A: Proof of the Variance Formula",
    "section": "5.4 A Helpful Transformation",
    "text": "5.4 A Helpful Transformation\nThe algebra becomes cleaner if we transform our treatment indicator. Instead of working directly with \\(D_i\\), we define a centered treatment indicator \\(\\tilde{D}_i\\), so that\n\\[\n\\tilde{D}_i = D_i - \\frac{N_t}{N}.\n\\]\nThis transformation shifts \\(D_i\\) so that its mean is zero. When \\(D_i = 1\\) (treated), we have \\(\\tilde{D}_i = 1 - N_t/N = N_c/N\\). When \\(D_i = 0\\) (control), we have \\(\\tilde{D}_i = 0 - N_t/N = -N_t/N\\).\nIn summary, the centered indicator is\n\\[\n\\tilde{D}_i = \\begin{cases}\n\\frac{N_c}{N} & \\text{if } D_i = 1 \\text{ (treatment)}, \\\\[6pt]\n-\\frac{N_t}{N} & \\text{if } D_i = 0 \\text{ (control)}.\n\\end{cases}\n\\]\n\n5.4.1 Properties of \\(\\tilde{D}_i\\)\nThe centered indicator \\(\\tilde{D}_i\\) has two key properties that make it useful.\nProperty 1: Zero mean. By construction, \\(E_D[\\tilde{D}_i] = E_D[D_i] - N_t/N = N_t/N - N_t/N = 0\\).\nProperty 2: Known variance. Since \\(\\tilde{D}_i\\) is just a shifted version of \\(D_i\\), its variance is the same, so that\n\\[\n\\text{Var}_D(\\tilde{D}_i) = \\text{Var}_D(D_i) = \\frac{N_t \\cdot N_c}{N^2}.\n\\]\nAnd because \\(E_D[\\tilde{D}_i] = 0\\), we have \\(E_D[\\tilde{D}_i^2] = \\text{Var}_D(\\tilde{D}_i) = \\frac{N_t \\cdot N_c}{N^2}\\).\n\n\n5.4.2 The Cross-Product \\(\\tilde{D}_i \\cdot \\tilde{D}_j\\)\nFor the variance calculation, we also need \\(E_D[\\tilde{D}_i \\cdot \\tilde{D}_j]\\) when \\(i \\neq j\\). The product \\(\\tilde{D}_i \\cdot \\tilde{D}_j\\) can take three possible values depending on whether both individuals are treated, both are in control, or one of each.\n\n\n\n\n\n\n\n\n\n\n\\(D_i\\)\n\\(D_j\\)\n\\(\\tilde{D}_i\\)\n\\(\\tilde{D}_j\\)\n\\(\\tilde{D}_i \\cdot \\tilde{D}_j\\)\n\n\n\n\n1\n1\n\\(N_c/N\\)\n\\(N_c/N\\)\n\\(N_c^2/N^2\\)\n\n\n1\n0\n\\(N_c/N\\)\n\\(-N_t/N\\)\n\\(-N_t N_c/N^2\\)\n\n\n0\n1\n\\(-N_t/N\\)\n\\(N_c/N\\)\n\\(-N_t N_c/N^2\\)\n\n\n0\n0\n\\(-N_t/N\\)\n\\(-N_t/N\\)\n\\(N_t^2/N^2\\)\n\n\n\nThe probabilities of each case are:\n\nBoth treated: \\(\\frac{N_t(N_t - 1)}{N(N-1)}\\)\nBoth control: \\(\\frac{N_c(N_c - 1)}{N(N-1)}\\)\nOne each: \\(\\frac{2 N_t N_c}{N(N-1)}\\)\n\nAfter computing the expected value (a homework exercise), we obtain\n\\[\nE_D[\\tilde{D}_i \\cdot \\tilde{D}_j] = -\\frac{N_t \\cdot N_c}{N^2 \\cdot (N - 1)} \\quad \\text{for } i \\neq j.\n\\]\nNotice this is negative. This reflects the negative correlation between treatment assignments: if individual \\(i\\) is more likely to be treated (higher \\(\\tilde{D}_i\\)), individual \\(j\\) is slightly less likely to be treated (lower \\(\\tilde{D}_j\\)).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Appendix A: Proof of the Variance Formula</span>"
    ]
  },
  {
    "objectID": "appendices/var-proof.html#rewriting-the-estimator",
    "href": "appendices/var-proof.html#rewriting-the-estimator",
    "title": "5  Appendix A: Proof of the Variance Formula",
    "section": "5.5 Rewriting the Estimator",
    "text": "5.5 Rewriting the Estimator\nUsing the centered indicator \\(\\tilde{D}_i\\), we can rewrite the estimator in a form that separates the fixed and random components. After algebraic manipulation (shown in the proof below), we obtain\n\\[\n\\widehat{\\text{ATE}} = \\underbrace{\\frac{1}{N} \\sum_{i=1}^{N} (Y_i(1) - Y_i(0))}_{\\text{fixed: the true ATE}} + \\underbrace{\\frac{1}{N} \\sum_{i=1}^{N} \\tilde{D}_i \\cdot Y_i^+}_{\\text{random: depends on } \\tilde{D}_i},\n\\]\nwhere we define\n\\[\nY_i^+ = \\frac{N}{N_t} Y_i(1) + \\frac{N}{N_c} Y_i(0).\n\\]\n\n\n\n\n\n\nUnderstanding This Decomposition\n\n\n\n\n\nThis decomposition is powerful. It says that our estimate equals the true ATE plus a “noise” term that depends on the randomization.\nThe first term, \\(\\frac{1}{N} \\sum_{i=1}^{N} (Y_i(1) - Y_i(0))\\), is the true ATE. It doesn’t depend on the randomization at all—it’s the same no matter which individuals we assign to treatment.\nThe second term, \\(\\frac{1}{N} \\sum_{i=1}^{N} \\tilde{D}_i \\cdot Y_i^+\\), is the deviation of our estimate from the truth. This term:\n\nHas expected value zero (because \\(E_D[\\tilde{D}_i] = 0\\))\nVaries depending on the randomization\nHas variance that we want to compute\n\nThe quantity \\(Y_i^+\\) is a weighted combination of individual \\(i\\)’s potential outcomes. It captures how much that individual’s outcomes contribute to the variability of the estimator.\n\n\n\nThis decomposition immediately shows that \\(\\widehat{\\text{ATE}}\\) is unbiased. Since \\(E_D[\\tilde{D}_i] = 0\\), we have\n\\[\nE_D[\\widehat{\\text{ATE}}] = \\frac{1}{N} \\sum_{i=1}^{N} (Y_i(1) - Y_i(0)) + 0 = \\text{ATE}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Appendix A: Proof of the Variance Formula</span>"
    ]
  },
  {
    "objectID": "appendices/var-proof.html#the-proof",
    "href": "appendices/var-proof.html#the-proof",
    "title": "5  Appendix A: Proof of the Variance Formula",
    "section": "5.6 The Proof",
    "text": "5.6 The Proof\nThe proof involves careful algebraic manipulation. We break it into labeled steps.\nStep 1: Start with the decomposition.\nWe established that\n\\[\n\\widehat{\\text{ATE}} = \\frac{1}{N} \\sum_{i=1}^{N} (Y_i(1) - Y_i(0)) + \\frac{1}{N} \\sum_{i=1}^{N} \\tilde{D}_i \\cdot Y_i^+.\n\\]\nSince the first term is constant (not random), the variance is\n\\[\n\\text{Var}_D \\left(\\widehat{\\text{ATE}}\\right) = \\text{Var}_D \\left( \\frac{1}{N} \\sum_{i=1}^{N} \\tilde{D}_i \\cdot Y_i^+ \\right) = \\frac{1}{N^2} \\text{Var}_D \\left( \\sum_{i=1}^{N} \\tilde{D}_i \\cdot Y_i^+ \\right).\n\\]\nStep 2: Use the variance-of-a-sum formula.\nSince \\(E_D\\left[\\sum_{i=1}^{N} \\tilde{D}_i \\cdot Y_i^+\\right] = 0\\), we have\n\\[\n\\text{Var}_D \\left( \\sum_{i=1}^{N} \\tilde{D}_i \\cdot Y_i^+ \\right) = E_D \\left[ \\left( \\sum_{i=1}^{N} \\tilde{D}_i \\cdot Y_i^+ \\right)^2 \\right].\n\\]\nStep 3: Expand the square.\nExpanding the squared sum gives\n\\[\nE_D \\left[ \\left( \\sum_{i=1}^{N} \\tilde{D}_i \\cdot Y_i^+ \\right)^2 \\right] = E_D \\left[ \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\tilde{D}_i \\tilde{D}_j Y_i^+ Y_j^+ \\right] = \\sum_{i=1}^{N} \\sum_{j=1}^{N} E_D[\\tilde{D}_i \\tilde{D}_j] \\cdot Y_i^+ \\cdot Y_j^+.\n\\]\nWe can separate this into diagonal terms (\\(i = j\\)) and off-diagonal terms (\\(i \\neq j\\)), so that\n\\[\n= \\sum_{i=1}^{N} E_D[\\tilde{D}_i^2] \\cdot (Y_i^+)^2 + \\sum_{i=1}^{N} \\sum_{j \\neq i} E_D[\\tilde{D}_i \\tilde{D}_j] \\cdot Y_i^+ \\cdot Y_j^+.\n\\]\nStep 4: Substitute the expectations.\nUsing our earlier results:\n\n\\(E_D[\\tilde{D}_i^2] = \\frac{N_t N_c}{N^2}\\)\n\\(E_D[\\tilde{D}_i \\tilde{D}_j] = -\\frac{N_t N_c}{N^2(N-1)}\\) for \\(i \\neq j\\)\n\nThis gives\n\\[\n= \\frac{N_t N_c}{N^2} \\sum_{i=1}^{N} (Y_i^+)^2 - \\frac{N_t N_c}{N^2(N-1)} \\sum_{i=1}^{N} \\sum_{j \\neq i} Y_i^+ Y_j^+.\n\\]\nStep 5: Simplify using a variance identity.\nThere’s a useful algebraic identity: for any values \\(z_1, \\ldots, z_N\\) with mean \\(\\bar{z}\\),\n\\[\n(N-1) \\sum_{i=1}^{N} (z_i - \\bar{z})^2 = N \\sum_{i=1}^{N} z_i^2 - \\sum_{i=1}^{N} \\sum_{j \\neq i} z_i z_j.\n\\]\nApplying this identity (with some additional algebra that we omit), we can show that\n\\[\n\\sum_{i=1}^{N} (Y_i^+)^2 - \\frac{1}{N-1} \\sum_{i=1}^{N} \\sum_{j \\neq i} Y_i^+ Y_j^+ = \\frac{N}{N-1} \\sum_{i=1}^{N} (Y_i^+ - \\overline{Y}^+)^2.\n\\]\nStep 6: Substitute the definition of \\(Y_i^+\\).\nAfter substitution and considerable algebraic manipulation, we can show that\n\\[\n\\frac{1}{N-1} \\sum_{i=1}^{N} (Y_i^+ - \\overline{Y}^+)^2 = \\frac{N^2}{N_t^2} S_t^2 + \\frac{N^2}{N_c^2} S_c^2 + \\frac{2N^2}{N_t N_c} \\text{Cov}(Y_i(1), Y_i(0)),\n\\]\nwhere \\(\\text{Cov}(Y_i(1), Y_i(0))\\) is the covariance between the potential outcomes.\nStep 7: Relate to \\(S_{tc}^2\\).\nThe variance of treatment effects can be written as\n\\[\nS_{tc}^2 = S_t^2 + S_c^2 - 2 \\text{Cov}(Y_i(1), Y_i(0)).\n\\]\nThis allows us to substitute for the covariance term.\nStep 8: Combine and simplify.\nPutting everything together and simplifying (which involves careful bookkeeping of the various terms), we arrive at\n\\[\n\\text{Var}_D \\left(\\widehat{\\text{ATE}}\\right) = \\frac{S_t^2}{N_t} + \\frac{S_c^2}{N_c} - \\frac{S_{tc}^2}{N}.\n\\]\nThis completes the proof. \\(\\square\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Appendix A: Proof of the Variance Formula</span>"
    ]
  }
]